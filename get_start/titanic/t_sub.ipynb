{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "import xgboost as xg\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Initial']=0\n",
    "for i in data:\n",
    "    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.')\n",
    "data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Mr'),'Age']=33\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Mrs'),'Age']=36\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age']=5\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Miss'),'Age']=22\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Other'),'Age']=46\n",
    "\n",
    "data['Embarked'].fillna('S',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Age_band</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked Initial  Age_band  \n",
       "0      0  A/5 21171   7.2500   NaN        S      Mr         1  \n",
       "1      0   PC 17599  71.2833   C85        C     Mrs         2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age_band']=0\n",
    "data.loc[data['Age']<=16,'Age_band']=0\n",
    "data.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\n",
    "data.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\n",
    "data.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\n",
    "data.loc[data['Age']>64,'Age_band']=4\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family_Size']=0\n",
    "data['Family_Size']=data['Parch']+data['SibSp']#family size\n",
    "data['Alone']=0\n",
    "data.loc[data.Family_Size==0,'Alone']=1#Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare_Range']=pd.qcut(data['Fare'],4)\n",
    "\n",
    "data['Fare_cat']=0\n",
    "data.loc[data['Fare']<=7.91,'Fare_cat']=0\n",
    "data.loc[(data['Fare']>7.91)&(data['Fare']<=14.454),'Fare_cat']=1\n",
    "data.loc[(data['Fare']>14.454)&(data['Fare']<=31),'Fare_cat']=2\n",
    "data.loc[(data['Fare']>31)&(data['Fare']<=513),'Fare_cat']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "data['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)\n",
    "data.drop(['Name','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)\n",
    "#sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\n",
    "#fig=plt.gcf()\n",
    "#fig.set_size_inches(18,15)\n",
    "#plt.xticks(fontsize=14)\n",
    "#plt.yticks(fontsize=14)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 268 entries, 421 to 607\n",
      "Data columns (total 11 columns):\n",
      "Pclass         268 non-null int64\n",
      "Sex            268 non-null int64\n",
      "Age            268 non-null float64\n",
      "SibSp          268 non-null int64\n",
      "Parch          268 non-null int64\n",
      "Embarked       268 non-null int64\n",
      "Initial        268 non-null int64\n",
      "Age_band       268 non-null int64\n",
      "Family_Size    268 non-null int64\n",
      "Alone          268 non-null int64\n",
      "Fare_cat       268 non-null int64\n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 25.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Age_band</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Fare_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch  Embarked  Initial  Age_band  \\\n",
       "421       3    0  21.0      0      0         2        0         1   \n",
       "618       2    1   4.0      2      1         0        2         0   \n",
       "116       3    0  70.5      0      0         2        0         4   \n",
       "310       1    1  24.0      0      0         1        2         1   \n",
       "57        3    0  28.5      0      0         1        0         1   \n",
       "\n",
       "     Family_Size  Alone  Fare_cat  \n",
       "421            0      1         0  \n",
       "618            3      0         3  \n",
       "116            0      1         0  \n",
       "310            0      1         3  \n",
       "57             0      1         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\n",
    "train_X=train[train.columns[1:]]\n",
    "train_Y=train[train.columns[:1]]\n",
    "test_X=test[test.columns[1:]]\n",
    "test_Y=test[test.columns[:1]]\n",
    "X=data[data.columns[1:]]\n",
    "Y=data['Survived']\n",
    "\n",
    "test_X.info()\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "#model.fit(train_X,train_Y.values.ravel())\n",
    "#prediction1=model.predict(test_X)\n",
    "\n",
    "\n",
    "#print('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        241\n",
       "Miss       79\n",
       "Mrs        72\n",
       "Master     21\n",
       "Other       4\n",
       "Dona        1\n",
       "Name: Initial, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/test.csv')\n",
    "data['Initial']=0\n",
    "for i in data:\n",
    "    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.')\n",
    "data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Mr'),'Age']=33\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Mrs'),'Age']=36\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age']=5\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Miss'),'Age']=22\n",
    "data.loc[(data.Age.isnull())&(data.Initial=='Other'),'Age']=46\n",
    "data['Initial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 17 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null int64\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null int64\n",
      "Initial        418 non-null object\n",
      "Age_band       418 non-null int64\n",
      "Family_Size    418 non-null int64\n",
      "Alone          418 non-null int64\n",
      "Fare_Range     417 non-null category\n",
      "Fare_cat       418 non-null int64\n",
      "dtypes: category(1), float64(2), int64(10), object(4)\n",
      "memory usage: 52.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data['Embarked'].fillna('S',inplace=True)\n",
    "\n",
    "data['Age_band']=0\n",
    "data.loc[data['Age']<=16,'Age_band']=0\n",
    "data.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\n",
    "data.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\n",
    "data.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\n",
    "data.loc[data['Age']>64,'Age_band']=4\n",
    "\n",
    "\n",
    "data['Family_Size']=0\n",
    "data['Family_Size']=data['Parch']+data['SibSp']#family size\n",
    "data['Alone']=0\n",
    "data.loc[data.Family_Size==0,'Alone']=1#Alone\n",
    "\n",
    "data['Fare_Range']=pd.qcut(data['Fare'],4)\n",
    "\n",
    "data['Fare_cat']=0\n",
    "data.loc[data['Fare']<=7.91,'Fare_cat']=0\n",
    "data.loc[(data['Fare']>7.91)&(data['Fare']<=14.454),'Fare_cat']=1\n",
    "data.loc[(data['Fare']>14.454)&(data['Fare']<=31),'Fare_cat']=2\n",
    "data.loc[(data['Fare']>31)&(data['Fare']<=513),'Fare_cat']=3\n",
    "\n",
    "data['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 17 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null int64\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null int64\n",
      "Initial        418 non-null int64\n",
      "Age_band       418 non-null int64\n",
      "Family_Size    418 non-null int64\n",
      "Alone          418 non-null int64\n",
      "Fare_Range     417 non-null category\n",
      "Fare_cat       418 non-null int64\n",
      "dtypes: category(1), float64(2), int64(11), object(3)\n",
      "memory usage: 52.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Age_band</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Fare_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch  Embarked  Initial  Age_band  Family_Size  \\\n",
       "0       3    0  34.5      0      0         2        0         2            0   \n",
       "1       3    1  47.0      1      0         0        1         2            1   \n",
       "2       2    0  62.0      0      0         2        0         3            0   \n",
       "3       3    0  27.0      0      0         0        0         1            0   \n",
       "4       3    1  22.0      1      1         0        1         1            2   \n",
       "\n",
       "   Alone  Fare_cat  \n",
       "0      1         0  \n",
       "1      0         0  \n",
       "2      1         1  \n",
       "3      1         1  \n",
       "4      0         1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Initial'].replace(['Mr','Mrs','Miss','Master','Other','Dona'],[0,1,2,3,4,4],inplace=True)\n",
    "data.info()\n",
    "# data_x=data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1)\n",
    "data_x=data.drop(['Name','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1)\n",
    "\n",
    "#sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\n",
    "#fig=plt.gcf()\n",
    "#fig.set_size_inches(18,15)\n",
    "#plt.xticks(fontsize=14)\n",
    "#plt.yticks(fontsize=14)\n",
    "#plt.show()\n",
    "data_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction2=model.predict(data_x)\n",
    "# submission = pd.DataFrame({\n",
    "#         \"PassengerId\": data[\"PassengerId\"],\n",
    "#         \"Survived\": prediction2\n",
    "#     })\n",
    "# submission.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/2000\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 1.9918 - acc: 0.3836 - val_loss: 1.7046 - val_acc: 0.3843\n",
      "Epoch 2/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 1.6901 - acc: 0.3836 - val_loss: 1.4930 - val_acc: 0.3918\n",
      "Epoch 3/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 1.4857 - acc: 0.3852 - val_loss: 1.3299 - val_acc: 0.3955\n",
      "Epoch 4/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 1.3281 - acc: 0.3820 - val_loss: 1.1989 - val_acc: 0.3955\n",
      "Epoch 5/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 1.2017 - acc: 0.3836 - val_loss: 1.0927 - val_acc: 0.3955\n",
      "Epoch 6/2000\n",
      "623/623 [==============================] - 0s 16us/step - loss: 1.0991 - acc: 0.3884 - val_loss: 1.0067 - val_acc: 0.3955\n",
      "Epoch 7/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 1.0161 - acc: 0.3836 - val_loss: 0.9377 - val_acc: 0.3955\n",
      "Epoch 8/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.9495 - acc: 0.3852 - val_loss: 0.8833 - val_acc: 0.3769\n",
      "Epoch 9/2000\n",
      "623/623 [==============================] - 0s 14us/step - loss: 0.8971 - acc: 0.3692 - val_loss: 0.8410 - val_acc: 0.3545\n",
      "Epoch 10/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.8562 - acc: 0.3499 - val_loss: 0.8085 - val_acc: 0.3619\n",
      "Epoch 11/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.8248 - acc: 0.3596 - val_loss: 0.7837 - val_acc: 0.3582\n",
      "Epoch 12/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.8008 - acc: 0.3435 - val_loss: 0.7649 - val_acc: 0.4104\n",
      "Epoch 13/2000\n",
      "623/623 [==============================] - 0s 16us/step - loss: 0.7825 - acc: 0.3579 - val_loss: 0.7507 - val_acc: 0.4366\n",
      "Epoch 14/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.7686 - acc: 0.3836 - val_loss: 0.7401 - val_acc: 0.4403\n",
      "Epoch 15/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.7582 - acc: 0.4125 - val_loss: 0.7322 - val_acc: 0.4813\n",
      "Epoch 16/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.7503 - acc: 0.4559 - val_loss: 0.7262 - val_acc: 0.4925\n",
      "Epoch 17/2000\n",
      "623/623 [==============================] - 0s 19us/step - loss: 0.7443 - acc: 0.4591 - val_loss: 0.7216 - val_acc: 0.4963\n",
      "Epoch 18/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.7396 - acc: 0.4575 - val_loss: 0.7180 - val_acc: 0.5187\n",
      "Epoch 19/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.7359 - acc: 0.4735 - val_loss: 0.7152 - val_acc: 0.5224\n",
      "Epoch 20/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.7329 - acc: 0.4751 - val_loss: 0.7128 - val_acc: 0.5336\n",
      "Epoch 21/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.7303 - acc: 0.4767 - val_loss: 0.7107 - val_acc: 0.5410\n",
      "Epoch 22/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.7281 - acc: 0.4864 - val_loss: 0.7089 - val_acc: 0.5410\n",
      "Epoch 23/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.7261 - acc: 0.4928 - val_loss: 0.7072 - val_acc: 0.5373\n",
      "Epoch 24/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.7243 - acc: 0.4992 - val_loss: 0.7057 - val_acc: 0.5373\n",
      "Epoch 25/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.7225 - acc: 0.5088 - val_loss: 0.7042 - val_acc: 0.5485\n",
      "Epoch 26/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.7208 - acc: 0.5169 - val_loss: 0.7028 - val_acc: 0.5485\n",
      "Epoch 27/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.7192 - acc: 0.5217 - val_loss: 0.7014 - val_acc: 0.5634\n",
      "Epoch 28/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.7176 - acc: 0.5297 - val_loss: 0.7000 - val_acc: 0.5672\n",
      "Epoch 29/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.7160 - acc: 0.5409 - val_loss: 0.6986 - val_acc: 0.5709\n",
      "Epoch 30/2000\n",
      "623/623 [==============================] - 0s 14us/step - loss: 0.7144 - acc: 0.5457 - val_loss: 0.6973 - val_acc: 0.5746\n",
      "Epoch 31/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.7128 - acc: 0.5490 - val_loss: 0.6960 - val_acc: 0.5784\n",
      "Epoch 32/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.7113 - acc: 0.5570 - val_loss: 0.6946 - val_acc: 0.5821\n",
      "Epoch 33/2000\n",
      "623/623 [==============================] - 0s 16us/step - loss: 0.7097 - acc: 0.5618 - val_loss: 0.6933 - val_acc: 0.5821\n",
      "Epoch 34/2000\n",
      "623/623 [==============================] - 0s 18us/step - loss: 0.7081 - acc: 0.5634 - val_loss: 0.6920 - val_acc: 0.5821\n",
      "Epoch 35/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.7065 - acc: 0.5634 - val_loss: 0.6906 - val_acc: 0.5784\n",
      "Epoch 36/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.7050 - acc: 0.5634 - val_loss: 0.6893 - val_acc: 0.5821\n",
      "Epoch 37/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.7034 - acc: 0.5682 - val_loss: 0.6879 - val_acc: 0.5858\n",
      "Epoch 38/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.7018 - acc: 0.5682 - val_loss: 0.6866 - val_acc: 0.5858\n",
      "Epoch 39/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.7003 - acc: 0.5714 - val_loss: 0.6853 - val_acc: 0.5896\n",
      "Epoch 40/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.6987 - acc: 0.5714 - val_loss: 0.6839 - val_acc: 0.5970\n",
      "Epoch 41/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.6971 - acc: 0.5730 - val_loss: 0.6826 - val_acc: 0.6045\n",
      "Epoch 42/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6955 - acc: 0.5762 - val_loss: 0.6812 - val_acc: 0.6082\n",
      "Epoch 43/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.6938 - acc: 0.5778 - val_loss: 0.6798 - val_acc: 0.6045\n",
      "Epoch 44/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6921 - acc: 0.5811 - val_loss: 0.6783 - val_acc: 0.6045\n",
      "Epoch 45/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6905 - acc: 0.5843 - val_loss: 0.6769 - val_acc: 0.6007\n",
      "Epoch 46/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6887 - acc: 0.5875 - val_loss: 0.6754 - val_acc: 0.6007\n",
      "Epoch 47/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6870 - acc: 0.5923 - val_loss: 0.6738 - val_acc: 0.6007\n",
      "Epoch 48/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6851 - acc: 0.5923 - val_loss: 0.6722 - val_acc: 0.6082\n",
      "Epoch 49/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6833 - acc: 0.5939 - val_loss: 0.6706 - val_acc: 0.6119\n",
      "Epoch 50/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6813 - acc: 0.5955 - val_loss: 0.6689 - val_acc: 0.6157\n",
      "Epoch 51/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6794 - acc: 0.6019 - val_loss: 0.6673 - val_acc: 0.6157\n",
      "Epoch 52/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6775 - acc: 0.6035 - val_loss: 0.6655 - val_acc: 0.6157\n",
      "Epoch 53/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6755 - acc: 0.6051 - val_loss: 0.6637 - val_acc: 0.6194\n",
      "Epoch 54/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6735 - acc: 0.6083 - val_loss: 0.6619 - val_acc: 0.6269\n",
      "Epoch 55/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.6715 - acc: 0.6132 - val_loss: 0.6601 - val_acc: 0.6306\n",
      "Epoch 56/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6696 - acc: 0.6180 - val_loss: 0.6584 - val_acc: 0.6343\n",
      "Epoch 57/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6676 - acc: 0.6260 - val_loss: 0.6566 - val_acc: 0.6493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6657 - acc: 0.6453 - val_loss: 0.6549 - val_acc: 0.6604\n",
      "Epoch 59/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6638 - acc: 0.6453 - val_loss: 0.6531 - val_acc: 0.6567\n",
      "Epoch 60/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6618 - acc: 0.6453 - val_loss: 0.6514 - val_acc: 0.6567\n",
      "Epoch 61/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6599 - acc: 0.6453 - val_loss: 0.6498 - val_acc: 0.6604\n",
      "Epoch 62/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6580 - acc: 0.6421 - val_loss: 0.6481 - val_acc: 0.6604\n",
      "Epoch 63/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.6561 - acc: 0.6421 - val_loss: 0.6464 - val_acc: 0.6604\n",
      "Epoch 64/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6542 - acc: 0.6404 - val_loss: 0.6448 - val_acc: 0.6604\n",
      "Epoch 65/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6524 - acc: 0.6421 - val_loss: 0.6432 - val_acc: 0.6604\n",
      "Epoch 66/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6505 - acc: 0.6421 - val_loss: 0.6415 - val_acc: 0.6642\n",
      "Epoch 67/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6487 - acc: 0.6421 - val_loss: 0.6399 - val_acc: 0.6642\n",
      "Epoch 68/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6468 - acc: 0.6421 - val_loss: 0.6383 - val_acc: 0.6642\n",
      "Epoch 69/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6450 - acc: 0.6453 - val_loss: 0.6368 - val_acc: 0.6679\n",
      "Epoch 70/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6432 - acc: 0.6485 - val_loss: 0.6351 - val_acc: 0.6642\n",
      "Epoch 71/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6414 - acc: 0.6469 - val_loss: 0.6337 - val_acc: 0.6679\n",
      "Epoch 72/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6396 - acc: 0.6517 - val_loss: 0.6321 - val_acc: 0.6642\n",
      "Epoch 73/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6380 - acc: 0.6517 - val_loss: 0.6317 - val_acc: 0.6642\n",
      "Epoch 74/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6370 - acc: 0.6565 - val_loss: 0.6319 - val_acc: 0.6679\n",
      "Epoch 75/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6377 - acc: 0.6597 - val_loss: 0.6330 - val_acc: 0.6493\n",
      "Epoch 76/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6375 - acc: 0.6421 - val_loss: 0.6292 - val_acc: 0.6679\n",
      "Epoch 77/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6346 - acc: 0.6613 - val_loss: 0.6265 - val_acc: 0.6754\n",
      "Epoch 78/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6311 - acc: 0.6645 - val_loss: 0.6240 - val_acc: 0.6679\n",
      "Epoch 79/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6289 - acc: 0.6565 - val_loss: 0.6227 - val_acc: 0.6604\n",
      "Epoch 80/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6271 - acc: 0.6549 - val_loss: 0.6211 - val_acc: 0.6716\n",
      "Epoch 81/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6254 - acc: 0.6581 - val_loss: 0.6199 - val_acc: 0.6754\n",
      "Epoch 82/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6238 - acc: 0.6581 - val_loss: 0.6183 - val_acc: 0.6754\n",
      "Epoch 83/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6223 - acc: 0.6597 - val_loss: 0.6172 - val_acc: 0.6754\n",
      "Epoch 84/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6208 - acc: 0.6597 - val_loss: 0.6157 - val_acc: 0.6791\n",
      "Epoch 85/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.6193 - acc: 0.6645 - val_loss: 0.6146 - val_acc: 0.6716\n",
      "Epoch 86/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6178 - acc: 0.6693 - val_loss: 0.6132 - val_acc: 0.6754\n",
      "Epoch 87/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6164 - acc: 0.6661 - val_loss: 0.6124 - val_acc: 0.6716\n",
      "Epoch 88/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6152 - acc: 0.6677 - val_loss: 0.6113 - val_acc: 0.6754\n",
      "Epoch 89/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6142 - acc: 0.6677 - val_loss: 0.6111 - val_acc: 0.6791\n",
      "Epoch 90/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6134 - acc: 0.6758 - val_loss: 0.6097 - val_acc: 0.6754\n",
      "Epoch 91/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6124 - acc: 0.6693 - val_loss: 0.6086 - val_acc: 0.6828\n",
      "Epoch 92/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6106 - acc: 0.6774 - val_loss: 0.6063 - val_acc: 0.6791\n",
      "Epoch 93/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6087 - acc: 0.6693 - val_loss: 0.6049 - val_acc: 0.6791\n",
      "Epoch 94/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6067 - acc: 0.6726 - val_loss: 0.6031 - val_acc: 0.6791\n",
      "Epoch 95/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.6050 - acc: 0.6693 - val_loss: 0.6018 - val_acc: 0.6791\n",
      "Epoch 96/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.6034 - acc: 0.6742 - val_loss: 0.6002 - val_acc: 0.6791\n",
      "Epoch 97/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6019 - acc: 0.6790 - val_loss: 0.5991 - val_acc: 0.6791\n",
      "Epoch 98/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.6004 - acc: 0.6742 - val_loss: 0.5977 - val_acc: 0.6866\n",
      "Epoch 99/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5991 - acc: 0.6822 - val_loss: 0.5967 - val_acc: 0.6828\n",
      "Epoch 100/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5977 - acc: 0.6790 - val_loss: 0.5954 - val_acc: 0.6903\n",
      "Epoch 101/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5965 - acc: 0.6838 - val_loss: 0.5946 - val_acc: 0.6866\n",
      "Epoch 102/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5953 - acc: 0.6870 - val_loss: 0.5933 - val_acc: 0.6903\n",
      "Epoch 103/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5942 - acc: 0.6870 - val_loss: 0.5927 - val_acc: 0.6978\n",
      "Epoch 104/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.5930 - acc: 0.6966 - val_loss: 0.5913 - val_acc: 0.6903\n",
      "Epoch 105/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5918 - acc: 0.6886 - val_loss: 0.5904 - val_acc: 0.7015\n",
      "Epoch 106/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5904 - acc: 0.7030 - val_loss: 0.5887 - val_acc: 0.6940\n",
      "Epoch 107/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5889 - acc: 0.6886 - val_loss: 0.5875 - val_acc: 0.6978\n",
      "Epoch 108/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5873 - acc: 0.7047 - val_loss: 0.5859 - val_acc: 0.6940\n",
      "Epoch 109/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5858 - acc: 0.6918 - val_loss: 0.5848 - val_acc: 0.6978\n",
      "Epoch 110/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5843 - acc: 0.7030 - val_loss: 0.5833 - val_acc: 0.6978\n",
      "Epoch 111/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5829 - acc: 0.6966 - val_loss: 0.5823 - val_acc: 0.6978\n",
      "Epoch 112/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5815 - acc: 0.7047 - val_loss: 0.5809 - val_acc: 0.6978\n",
      "Epoch 113/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5802 - acc: 0.6966 - val_loss: 0.5800 - val_acc: 0.7052\n",
      "Epoch 114/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5788 - acc: 0.7063 - val_loss: 0.5786 - val_acc: 0.6978\n",
      "Epoch 115/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5776 - acc: 0.6998 - val_loss: 0.5777 - val_acc: 0.7090\n",
      "Epoch 116/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5764 - acc: 0.7127 - val_loss: 0.5763 - val_acc: 0.6978\n",
      "Epoch 117/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5752 - acc: 0.7014 - val_loss: 0.5754 - val_acc: 0.7090\n",
      "Epoch 118/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5739 - acc: 0.7127 - val_loss: 0.5738 - val_acc: 0.7015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5725 - acc: 0.7014 - val_loss: 0.5728 - val_acc: 0.7239\n",
      "Epoch 120/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5710 - acc: 0.7175 - val_loss: 0.5710 - val_acc: 0.7015\n",
      "Epoch 121/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5694 - acc: 0.7063 - val_loss: 0.5696 - val_acc: 0.7276\n",
      "Epoch 122/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5675 - acc: 0.7175 - val_loss: 0.5677 - val_acc: 0.7052\n",
      "Epoch 123/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5659 - acc: 0.7095 - val_loss: 0.5661 - val_acc: 0.7239\n",
      "Epoch 124/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5639 - acc: 0.7207 - val_loss: 0.5637 - val_acc: 0.7052\n",
      "Epoch 125/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.5619 - acc: 0.7111 - val_loss: 0.5620 - val_acc: 0.7276\n",
      "Epoch 126/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5598 - acc: 0.7319 - val_loss: 0.5598 - val_acc: 0.7052\n",
      "Epoch 127/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5576 - acc: 0.7143 - val_loss: 0.5580 - val_acc: 0.7313\n",
      "Epoch 128/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5555 - acc: 0.7400 - val_loss: 0.5561 - val_acc: 0.7090\n",
      "Epoch 129/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.5540 - acc: 0.7175 - val_loss: 0.5551 - val_acc: 0.7201\n",
      "Epoch 130/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5526 - acc: 0.7528 - val_loss: 0.5535 - val_acc: 0.7090\n",
      "Epoch 131/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5513 - acc: 0.7143 - val_loss: 0.5524 - val_acc: 0.7201\n",
      "Epoch 132/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5498 - acc: 0.7544 - val_loss: 0.5510 - val_acc: 0.7127\n",
      "Epoch 133/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5485 - acc: 0.7175 - val_loss: 0.5500 - val_acc: 0.7276\n",
      "Epoch 134/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.5472 - acc: 0.7560 - val_loss: 0.5487 - val_acc: 0.7127\n",
      "Epoch 135/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5460 - acc: 0.7191 - val_loss: 0.5478 - val_acc: 0.7276\n",
      "Epoch 136/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5447 - acc: 0.7576 - val_loss: 0.5464 - val_acc: 0.7164\n",
      "Epoch 137/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5435 - acc: 0.7207 - val_loss: 0.5456 - val_acc: 0.7276\n",
      "Epoch 138/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5423 - acc: 0.7544 - val_loss: 0.5443 - val_acc: 0.7239\n",
      "Epoch 139/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5411 - acc: 0.7175 - val_loss: 0.5435 - val_acc: 0.7276\n",
      "Epoch 140/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5399 - acc: 0.7560 - val_loss: 0.5422 - val_acc: 0.7276\n",
      "Epoch 141/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5389 - acc: 0.7223 - val_loss: 0.5415 - val_acc: 0.7276\n",
      "Epoch 142/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5377 - acc: 0.7624 - val_loss: 0.5402 - val_acc: 0.7276\n",
      "Epoch 143/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5367 - acc: 0.7287 - val_loss: 0.5396 - val_acc: 0.7276\n",
      "Epoch 144/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.5355 - acc: 0.7592 - val_loss: 0.5383 - val_acc: 0.7313\n",
      "Epoch 145/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5345 - acc: 0.7303 - val_loss: 0.5378 - val_acc: 0.7276\n",
      "Epoch 146/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5334 - acc: 0.7576 - val_loss: 0.5365 - val_acc: 0.7313\n",
      "Epoch 147/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5324 - acc: 0.7335 - val_loss: 0.5360 - val_acc: 0.7276\n",
      "Epoch 148/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5314 - acc: 0.7544 - val_loss: 0.5347 - val_acc: 0.7351\n",
      "Epoch 149/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5304 - acc: 0.7352 - val_loss: 0.5341 - val_acc: 0.7276\n",
      "Epoch 150/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5293 - acc: 0.7544 - val_loss: 0.5329 - val_acc: 0.7351\n",
      "Epoch 151/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5284 - acc: 0.7352 - val_loss: 0.5321 - val_acc: 0.7313\n",
      "Epoch 152/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5273 - acc: 0.7576 - val_loss: 0.5311 - val_acc: 0.7351\n",
      "Epoch 153/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5263 - acc: 0.7432 - val_loss: 0.5303 - val_acc: 0.7351\n",
      "Epoch 154/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5253 - acc: 0.7576 - val_loss: 0.5292 - val_acc: 0.7425\n",
      "Epoch 155/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5244 - acc: 0.7496 - val_loss: 0.5284 - val_acc: 0.7388\n",
      "Epoch 156/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5233 - acc: 0.7624 - val_loss: 0.5275 - val_acc: 0.7388\n",
      "Epoch 157/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5224 - acc: 0.7464 - val_loss: 0.5267 - val_acc: 0.7388\n",
      "Epoch 158/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5214 - acc: 0.7624 - val_loss: 0.5257 - val_acc: 0.7425\n",
      "Epoch 159/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5205 - acc: 0.7480 - val_loss: 0.5249 - val_acc: 0.7425\n",
      "Epoch 160/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5196 - acc: 0.7624 - val_loss: 0.5240 - val_acc: 0.7425\n",
      "Epoch 161/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5187 - acc: 0.7512 - val_loss: 0.5230 - val_acc: 0.7425\n",
      "Epoch 162/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5178 - acc: 0.7624 - val_loss: 0.5222 - val_acc: 0.7425\n",
      "Epoch 163/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5169 - acc: 0.7512 - val_loss: 0.5213 - val_acc: 0.7463\n",
      "Epoch 164/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.5159 - acc: 0.7624 - val_loss: 0.5205 - val_acc: 0.7425\n",
      "Epoch 165/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5151 - acc: 0.7512 - val_loss: 0.5197 - val_acc: 0.7463\n",
      "Epoch 166/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5141 - acc: 0.7640 - val_loss: 0.5188 - val_acc: 0.7425\n",
      "Epoch 167/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5133 - acc: 0.7544 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 168/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5124 - acc: 0.7640 - val_loss: 0.5171 - val_acc: 0.7425\n",
      "Epoch 169/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5116 - acc: 0.7528 - val_loss: 0.5163 - val_acc: 0.7537\n",
      "Epoch 170/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5107 - acc: 0.7624 - val_loss: 0.5155 - val_acc: 0.7425\n",
      "Epoch 171/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5099 - acc: 0.7496 - val_loss: 0.5146 - val_acc: 0.7575\n",
      "Epoch 172/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5090 - acc: 0.7673 - val_loss: 0.5140 - val_acc: 0.7463\n",
      "Epoch 173/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.5083 - acc: 0.7512 - val_loss: 0.5129 - val_acc: 0.7537\n",
      "Epoch 174/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5074 - acc: 0.7673 - val_loss: 0.5122 - val_acc: 0.7463\n",
      "Epoch 175/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5066 - acc: 0.7528 - val_loss: 0.5112 - val_acc: 0.7537\n",
      "Epoch 176/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5058 - acc: 0.7689 - val_loss: 0.5105 - val_acc: 0.7463\n",
      "Epoch 177/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5050 - acc: 0.7560 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 178/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.5042 - acc: 0.7673 - val_loss: 0.5090 - val_acc: 0.7463\n",
      "Epoch 179/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.5034 - acc: 0.7576 - val_loss: 0.5079 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.5026 - acc: 0.7657 - val_loss: 0.5075 - val_acc: 0.7463\n",
      "Epoch 181/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5018 - acc: 0.7592 - val_loss: 0.5064 - val_acc: 0.7500\n",
      "Epoch 182/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.5010 - acc: 0.7673 - val_loss: 0.5058 - val_acc: 0.7500\n",
      "Epoch 183/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.5003 - acc: 0.7608 - val_loss: 0.5048 - val_acc: 0.7537\n",
      "Epoch 184/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4995 - acc: 0.7657 - val_loss: 0.5043 - val_acc: 0.7500\n",
      "Epoch 185/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4988 - acc: 0.7657 - val_loss: 0.5032 - val_acc: 0.7537\n",
      "Epoch 186/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4981 - acc: 0.7657 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 187/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4973 - acc: 0.7657 - val_loss: 0.5017 - val_acc: 0.7575\n",
      "Epoch 188/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4966 - acc: 0.7657 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 189/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4959 - acc: 0.7673 - val_loss: 0.5001 - val_acc: 0.7575\n",
      "Epoch 190/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4951 - acc: 0.7705 - val_loss: 0.4998 - val_acc: 0.7537\n",
      "Epoch 191/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4945 - acc: 0.7673 - val_loss: 0.4987 - val_acc: 0.7575\n",
      "Epoch 192/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4937 - acc: 0.7657 - val_loss: 0.4983 - val_acc: 0.7537\n",
      "Epoch 193/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4931 - acc: 0.7721 - val_loss: 0.4971 - val_acc: 0.7575\n",
      "Epoch 194/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4923 - acc: 0.7657 - val_loss: 0.4969 - val_acc: 0.7537\n",
      "Epoch 195/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4917 - acc: 0.7721 - val_loss: 0.4957 - val_acc: 0.7575\n",
      "Epoch 196/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4910 - acc: 0.7689 - val_loss: 0.4955 - val_acc: 0.7575\n",
      "Epoch 197/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4903 - acc: 0.7705 - val_loss: 0.4943 - val_acc: 0.7575\n",
      "Epoch 198/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4896 - acc: 0.7657 - val_loss: 0.4940 - val_acc: 0.7537\n",
      "Epoch 199/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4890 - acc: 0.7737 - val_loss: 0.4929 - val_acc: 0.7575\n",
      "Epoch 200/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4883 - acc: 0.7657 - val_loss: 0.4928 - val_acc: 0.7537\n",
      "Epoch 201/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4877 - acc: 0.7753 - val_loss: 0.4916 - val_acc: 0.7575\n",
      "Epoch 202/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4870 - acc: 0.7657 - val_loss: 0.4914 - val_acc: 0.7575\n",
      "Epoch 203/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4864 - acc: 0.7753 - val_loss: 0.4902 - val_acc: 0.7612\n",
      "Epoch 204/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4857 - acc: 0.7657 - val_loss: 0.4900 - val_acc: 0.7575\n",
      "Epoch 205/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4851 - acc: 0.7769 - val_loss: 0.4887 - val_acc: 0.7575\n",
      "Epoch 206/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4845 - acc: 0.7689 - val_loss: 0.4886 - val_acc: 0.7649\n",
      "Epoch 207/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4839 - acc: 0.7785 - val_loss: 0.4873 - val_acc: 0.7612\n",
      "Epoch 208/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4832 - acc: 0.7689 - val_loss: 0.4874 - val_acc: 0.7687\n",
      "Epoch 209/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4827 - acc: 0.7785 - val_loss: 0.4860 - val_acc: 0.7612\n",
      "Epoch 210/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4821 - acc: 0.7705 - val_loss: 0.4861 - val_acc: 0.7687\n",
      "Epoch 211/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4815 - acc: 0.7817 - val_loss: 0.4847 - val_acc: 0.7649\n",
      "Epoch 212/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4809 - acc: 0.7705 - val_loss: 0.4847 - val_acc: 0.7724\n",
      "Epoch 213/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4804 - acc: 0.7833 - val_loss: 0.4834 - val_acc: 0.7612\n",
      "Epoch 214/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4798 - acc: 0.7689 - val_loss: 0.4835 - val_acc: 0.7724\n",
      "Epoch 215/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4792 - acc: 0.7849 - val_loss: 0.4822 - val_acc: 0.7612\n",
      "Epoch 216/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4787 - acc: 0.7689 - val_loss: 0.4823 - val_acc: 0.7724\n",
      "Epoch 217/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4781 - acc: 0.7849 - val_loss: 0.4808 - val_acc: 0.7612\n",
      "Epoch 218/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4775 - acc: 0.7689 - val_loss: 0.4811 - val_acc: 0.7724\n",
      "Epoch 219/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4771 - acc: 0.7849 - val_loss: 0.4796 - val_acc: 0.7612\n",
      "Epoch 220/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4765 - acc: 0.7673 - val_loss: 0.4800 - val_acc: 0.7761\n",
      "Epoch 221/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4761 - acc: 0.7817 - val_loss: 0.4784 - val_acc: 0.7575\n",
      "Epoch 222/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4755 - acc: 0.7673 - val_loss: 0.4787 - val_acc: 0.7799\n",
      "Epoch 223/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4750 - acc: 0.7801 - val_loss: 0.4772 - val_acc: 0.7575\n",
      "Epoch 224/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4745 - acc: 0.7673 - val_loss: 0.4776 - val_acc: 0.7836\n",
      "Epoch 225/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4740 - acc: 0.7817 - val_loss: 0.4760 - val_acc: 0.7612\n",
      "Epoch 226/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4734 - acc: 0.7689 - val_loss: 0.4764 - val_acc: 0.7836\n",
      "Epoch 227/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4730 - acc: 0.7801 - val_loss: 0.4748 - val_acc: 0.7612\n",
      "Epoch 228/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4725 - acc: 0.7705 - val_loss: 0.4753 - val_acc: 0.7836\n",
      "Epoch 229/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4720 - acc: 0.7817 - val_loss: 0.4736 - val_acc: 0.7612\n",
      "Epoch 230/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4716 - acc: 0.7705 - val_loss: 0.4742 - val_acc: 0.7836\n",
      "Epoch 231/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4711 - acc: 0.7833 - val_loss: 0.4725 - val_acc: 0.7612\n",
      "Epoch 232/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4706 - acc: 0.7705 - val_loss: 0.4731 - val_acc: 0.7836\n",
      "Epoch 233/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4702 - acc: 0.7833 - val_loss: 0.4713 - val_acc: 0.7612\n",
      "Epoch 234/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4697 - acc: 0.7721 - val_loss: 0.4722 - val_acc: 0.7799\n",
      "Epoch 235/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4694 - acc: 0.7849 - val_loss: 0.4703 - val_acc: 0.7575\n",
      "Epoch 236/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4689 - acc: 0.7705 - val_loss: 0.4710 - val_acc: 0.7836\n",
      "Epoch 237/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4685 - acc: 0.7865 - val_loss: 0.4692 - val_acc: 0.7575\n",
      "Epoch 238/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4680 - acc: 0.7705 - val_loss: 0.4700 - val_acc: 0.7836\n",
      "Epoch 239/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4676 - acc: 0.7865 - val_loss: 0.4682 - val_acc: 0.7537\n",
      "Epoch 240/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4672 - acc: 0.7705 - val_loss: 0.4690 - val_acc: 0.7836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4668 - acc: 0.7865 - val_loss: 0.4671 - val_acc: 0.7575\n",
      "Epoch 242/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4663 - acc: 0.7721 - val_loss: 0.4680 - val_acc: 0.7836\n",
      "Epoch 243/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4659 - acc: 0.7881 - val_loss: 0.4660 - val_acc: 0.7649\n",
      "Epoch 244/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4655 - acc: 0.7721 - val_loss: 0.4670 - val_acc: 0.7799\n",
      "Epoch 245/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4651 - acc: 0.7881 - val_loss: 0.4650 - val_acc: 0.7649\n",
      "Epoch 246/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4647 - acc: 0.7705 - val_loss: 0.4660 - val_acc: 0.7836\n",
      "Epoch 247/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4644 - acc: 0.7897 - val_loss: 0.4641 - val_acc: 0.7649\n",
      "Epoch 248/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4640 - acc: 0.7705 - val_loss: 0.4651 - val_acc: 0.7836\n",
      "Epoch 249/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4636 - acc: 0.7897 - val_loss: 0.4631 - val_acc: 0.7687\n",
      "Epoch 250/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4632 - acc: 0.7689 - val_loss: 0.4643 - val_acc: 0.7836\n",
      "Epoch 251/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4629 - acc: 0.7897 - val_loss: 0.4622 - val_acc: 0.7687\n",
      "Epoch 252/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4625 - acc: 0.7689 - val_loss: 0.4633 - val_acc: 0.7836\n",
      "Epoch 253/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4622 - acc: 0.7881 - val_loss: 0.4612 - val_acc: 0.7687\n",
      "Epoch 254/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4618 - acc: 0.7673 - val_loss: 0.4624 - val_acc: 0.7799\n",
      "Epoch 255/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4614 - acc: 0.7897 - val_loss: 0.4604 - val_acc: 0.7687\n",
      "Epoch 256/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4610 - acc: 0.7689 - val_loss: 0.4616 - val_acc: 0.7799\n",
      "Epoch 257/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4607 - acc: 0.7881 - val_loss: 0.4596 - val_acc: 0.7910\n",
      "Epoch 258/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4603 - acc: 0.7801 - val_loss: 0.4608 - val_acc: 0.7761\n",
      "Epoch 259/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4600 - acc: 0.7849 - val_loss: 0.4586 - val_acc: 0.7910\n",
      "Epoch 260/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4596 - acc: 0.7801 - val_loss: 0.4600 - val_acc: 0.7761\n",
      "Epoch 261/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4594 - acc: 0.7849 - val_loss: 0.4578 - val_acc: 0.7948\n",
      "Epoch 262/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4590 - acc: 0.7801 - val_loss: 0.4592 - val_acc: 0.7761\n",
      "Epoch 263/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4587 - acc: 0.7865 - val_loss: 0.4570 - val_acc: 0.7985\n",
      "Epoch 264/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4584 - acc: 0.7769 - val_loss: 0.4585 - val_acc: 0.7761\n",
      "Epoch 265/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4581 - acc: 0.7865 - val_loss: 0.4562 - val_acc: 0.7985\n",
      "Epoch 266/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4578 - acc: 0.7769 - val_loss: 0.4577 - val_acc: 0.7761\n",
      "Epoch 267/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4575 - acc: 0.7881 - val_loss: 0.4555 - val_acc: 0.8022\n",
      "Epoch 268/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4571 - acc: 0.7817 - val_loss: 0.4570 - val_acc: 0.7761\n",
      "Epoch 269/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4569 - acc: 0.7881 - val_loss: 0.4547 - val_acc: 0.8022\n",
      "Epoch 270/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4565 - acc: 0.7817 - val_loss: 0.4564 - val_acc: 0.7799\n",
      "Epoch 271/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4563 - acc: 0.7881 - val_loss: 0.4539 - val_acc: 0.8022\n",
      "Epoch 272/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4560 - acc: 0.7801 - val_loss: 0.4556 - val_acc: 0.7799\n",
      "Epoch 273/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4557 - acc: 0.7881 - val_loss: 0.4533 - val_acc: 0.8022\n",
      "Epoch 274/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4554 - acc: 0.7817 - val_loss: 0.4550 - val_acc: 0.7799\n",
      "Epoch 275/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4552 - acc: 0.7881 - val_loss: 0.4526 - val_acc: 0.8060\n",
      "Epoch 276/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4549 - acc: 0.7833 - val_loss: 0.4544 - val_acc: 0.7761\n",
      "Epoch 277/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4546 - acc: 0.7865 - val_loss: 0.4519 - val_acc: 0.8060\n",
      "Epoch 278/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4543 - acc: 0.7833 - val_loss: 0.4538 - val_acc: 0.7761\n",
      "Epoch 279/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4541 - acc: 0.7881 - val_loss: 0.4513 - val_acc: 0.8060\n",
      "Epoch 280/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4538 - acc: 0.7833 - val_loss: 0.4533 - val_acc: 0.7761\n",
      "Epoch 281/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4536 - acc: 0.7865 - val_loss: 0.4507 - val_acc: 0.8060\n",
      "Epoch 282/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4534 - acc: 0.7833 - val_loss: 0.4527 - val_acc: 0.7799\n",
      "Epoch 283/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4532 - acc: 0.7865 - val_loss: 0.4502 - val_acc: 0.8060\n",
      "Epoch 284/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4529 - acc: 0.7833 - val_loss: 0.4522 - val_acc: 0.7799\n",
      "Epoch 285/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4527 - acc: 0.7865 - val_loss: 0.4496 - val_acc: 0.8060\n",
      "Epoch 286/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4524 - acc: 0.7833 - val_loss: 0.4517 - val_acc: 0.8022\n",
      "Epoch 287/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4522 - acc: 0.7978 - val_loss: 0.4490 - val_acc: 0.8060\n",
      "Epoch 288/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4519 - acc: 0.7833 - val_loss: 0.4511 - val_acc: 0.8022\n",
      "Epoch 289/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4518 - acc: 0.7994 - val_loss: 0.4485 - val_acc: 0.8097\n",
      "Epoch 290/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4515 - acc: 0.7833 - val_loss: 0.4506 - val_acc: 0.8022\n",
      "Epoch 291/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4513 - acc: 0.7994 - val_loss: 0.4480 - val_acc: 0.8097\n",
      "Epoch 292/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4510 - acc: 0.7865 - val_loss: 0.4502 - val_acc: 0.8022\n",
      "Epoch 293/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4509 - acc: 0.7994 - val_loss: 0.4475 - val_acc: 0.8097\n",
      "Epoch 294/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4506 - acc: 0.7865 - val_loss: 0.4497 - val_acc: 0.8022\n",
      "Epoch 295/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4505 - acc: 0.7994 - val_loss: 0.4470 - val_acc: 0.8097\n",
      "Epoch 296/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4502 - acc: 0.7865 - val_loss: 0.4493 - val_acc: 0.8022\n",
      "Epoch 297/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4501 - acc: 0.7994 - val_loss: 0.4466 - val_acc: 0.8097\n",
      "Epoch 298/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4499 - acc: 0.7865 - val_loss: 0.4489 - val_acc: 0.8022\n",
      "Epoch 299/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4497 - acc: 0.7994 - val_loss: 0.4461 - val_acc: 0.8097\n",
      "Epoch 300/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4495 - acc: 0.7881 - val_loss: 0.4485 - val_acc: 0.8022\n",
      "Epoch 301/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4493 - acc: 0.7994 - val_loss: 0.4457 - val_acc: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4491 - acc: 0.7865 - val_loss: 0.4481 - val_acc: 0.8022\n",
      "Epoch 303/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4489 - acc: 0.7994 - val_loss: 0.4453 - val_acc: 0.8097\n",
      "Epoch 304/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4487 - acc: 0.7865 - val_loss: 0.4477 - val_acc: 0.8022\n",
      "Epoch 305/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4485 - acc: 0.8010 - val_loss: 0.4450 - val_acc: 0.8097\n",
      "Epoch 306/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4483 - acc: 0.7865 - val_loss: 0.4475 - val_acc: 0.8022\n",
      "Epoch 307/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4481 - acc: 0.8010 - val_loss: 0.4447 - val_acc: 0.8097\n",
      "Epoch 308/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4479 - acc: 0.7865 - val_loss: 0.4471 - val_acc: 0.8022\n",
      "Epoch 309/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4478 - acc: 0.8026 - val_loss: 0.4444 - val_acc: 0.8097\n",
      "Epoch 310/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4475 - acc: 0.7849 - val_loss: 0.4469 - val_acc: 0.8022\n",
      "Epoch 311/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4474 - acc: 0.8026 - val_loss: 0.4440 - val_acc: 0.8097\n",
      "Epoch 312/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4472 - acc: 0.7865 - val_loss: 0.4466 - val_acc: 0.8022\n",
      "Epoch 313/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4471 - acc: 0.8026 - val_loss: 0.4437 - val_acc: 0.8097\n",
      "Epoch 314/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4468 - acc: 0.7865 - val_loss: 0.4462 - val_acc: 0.8022\n",
      "Epoch 315/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4467 - acc: 0.8026 - val_loss: 0.4434 - val_acc: 0.8097\n",
      "Epoch 316/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4465 - acc: 0.7865 - val_loss: 0.4459 - val_acc: 0.8022\n",
      "Epoch 317/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4464 - acc: 0.8026 - val_loss: 0.4430 - val_acc: 0.8097\n",
      "Epoch 318/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4462 - acc: 0.7865 - val_loss: 0.4456 - val_acc: 0.8022\n",
      "Epoch 319/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4461 - acc: 0.8026 - val_loss: 0.4427 - val_acc: 0.8060\n",
      "Epoch 320/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4459 - acc: 0.7865 - val_loss: 0.4454 - val_acc: 0.8022\n",
      "Epoch 321/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4458 - acc: 0.8010 - val_loss: 0.4423 - val_acc: 0.8060\n",
      "Epoch 322/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4456 - acc: 0.7849 - val_loss: 0.4451 - val_acc: 0.8022\n",
      "Epoch 323/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4455 - acc: 0.8010 - val_loss: 0.4420 - val_acc: 0.8022\n",
      "Epoch 324/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4453 - acc: 0.7849 - val_loss: 0.4448 - val_acc: 0.8022\n",
      "Epoch 325/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4452 - acc: 0.8010 - val_loss: 0.4417 - val_acc: 0.8022\n",
      "Epoch 326/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4450 - acc: 0.7849 - val_loss: 0.4446 - val_acc: 0.8022\n",
      "Epoch 327/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4449 - acc: 0.7994 - val_loss: 0.4414 - val_acc: 0.7985\n",
      "Epoch 328/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4447 - acc: 0.7849 - val_loss: 0.4442 - val_acc: 0.8022\n",
      "Epoch 329/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4446 - acc: 0.7978 - val_loss: 0.4411 - val_acc: 0.7985\n",
      "Epoch 330/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4444 - acc: 0.7849 - val_loss: 0.4440 - val_acc: 0.8022\n",
      "Epoch 331/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4443 - acc: 0.7994 - val_loss: 0.4408 - val_acc: 0.7985\n",
      "Epoch 332/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4441 - acc: 0.7849 - val_loss: 0.4437 - val_acc: 0.8022\n",
      "Epoch 333/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4440 - acc: 0.7994 - val_loss: 0.4406 - val_acc: 0.7985\n",
      "Epoch 334/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4438 - acc: 0.7865 - val_loss: 0.4435 - val_acc: 0.8022\n",
      "Epoch 335/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4437 - acc: 0.7994 - val_loss: 0.4403 - val_acc: 0.7985\n",
      "Epoch 336/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4435 - acc: 0.7881 - val_loss: 0.4431 - val_acc: 0.8022\n",
      "Epoch 337/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4434 - acc: 0.7994 - val_loss: 0.4401 - val_acc: 0.7985\n",
      "Epoch 338/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4432 - acc: 0.7881 - val_loss: 0.4430 - val_acc: 0.8022\n",
      "Epoch 339/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4432 - acc: 0.7994 - val_loss: 0.4398 - val_acc: 0.7985\n",
      "Epoch 340/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4430 - acc: 0.7881 - val_loss: 0.4428 - val_acc: 0.8022\n",
      "Epoch 341/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4429 - acc: 0.7994 - val_loss: 0.4395 - val_acc: 0.7985\n",
      "Epoch 342/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4427 - acc: 0.7881 - val_loss: 0.4426 - val_acc: 0.8022\n",
      "Epoch 343/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4427 - acc: 0.7994 - val_loss: 0.4393 - val_acc: 0.7985\n",
      "Epoch 344/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4425 - acc: 0.7881 - val_loss: 0.4423 - val_acc: 0.8022\n",
      "Epoch 345/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4424 - acc: 0.7978 - val_loss: 0.4391 - val_acc: 0.7985\n",
      "Epoch 346/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4422 - acc: 0.7897 - val_loss: 0.4420 - val_acc: 0.8060\n",
      "Epoch 347/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4421 - acc: 0.7978 - val_loss: 0.4388 - val_acc: 0.7985\n",
      "Epoch 348/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4419 - acc: 0.7897 - val_loss: 0.4419 - val_acc: 0.8060\n",
      "Epoch 349/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4418 - acc: 0.7994 - val_loss: 0.4386 - val_acc: 0.7985\n",
      "Epoch 350/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4417 - acc: 0.7897 - val_loss: 0.4416 - val_acc: 0.8022\n",
      "Epoch 351/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4416 - acc: 0.7994 - val_loss: 0.4384 - val_acc: 0.7985\n",
      "Epoch 352/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4414 - acc: 0.7929 - val_loss: 0.4414 - val_acc: 0.8022\n",
      "Epoch 353/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4413 - acc: 0.7994 - val_loss: 0.4382 - val_acc: 0.7985\n",
      "Epoch 354/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.4412 - acc: 0.7929 - val_loss: 0.4412 - val_acc: 0.8022\n",
      "Epoch 355/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4411 - acc: 0.7994 - val_loss: 0.4379 - val_acc: 0.7985\n",
      "Epoch 356/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4409 - acc: 0.7945 - val_loss: 0.4410 - val_acc: 0.8022\n",
      "Epoch 357/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4408 - acc: 0.7994 - val_loss: 0.4377 - val_acc: 0.7985\n",
      "Epoch 358/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4407 - acc: 0.7945 - val_loss: 0.4409 - val_acc: 0.8022\n",
      "Epoch 359/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4406 - acc: 0.7994 - val_loss: 0.4375 - val_acc: 0.7985\n",
      "Epoch 360/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4404 - acc: 0.7945 - val_loss: 0.4406 - val_acc: 0.8022\n",
      "Epoch 361/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4404 - acc: 0.7994 - val_loss: 0.4372 - val_acc: 0.8022\n",
      "Epoch 362/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4402 - acc: 0.7961 - val_loss: 0.4404 - val_acc: 0.8022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4401 - acc: 0.7994 - val_loss: 0.4371 - val_acc: 0.8022\n",
      "Epoch 364/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4399 - acc: 0.7961 - val_loss: 0.4401 - val_acc: 0.8022\n",
      "Epoch 365/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4398 - acc: 0.7994 - val_loss: 0.4369 - val_acc: 0.8022\n",
      "Epoch 366/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4397 - acc: 0.7961 - val_loss: 0.4400 - val_acc: 0.8022\n",
      "Epoch 367/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4396 - acc: 0.7994 - val_loss: 0.4366 - val_acc: 0.8022\n",
      "Epoch 368/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4394 - acc: 0.7961 - val_loss: 0.4398 - val_acc: 0.8022\n",
      "Epoch 369/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4394 - acc: 0.7994 - val_loss: 0.4365 - val_acc: 0.8022\n",
      "Epoch 370/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4392 - acc: 0.7961 - val_loss: 0.4397 - val_acc: 0.8022\n",
      "Epoch 371/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4391 - acc: 0.7994 - val_loss: 0.4362 - val_acc: 0.8022\n",
      "Epoch 372/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4390 - acc: 0.7961 - val_loss: 0.4395 - val_acc: 0.8022\n",
      "Epoch 373/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4389 - acc: 0.7994 - val_loss: 0.4361 - val_acc: 0.8022\n",
      "Epoch 374/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4387 - acc: 0.7978 - val_loss: 0.4393 - val_acc: 0.8022\n",
      "Epoch 375/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4386 - acc: 0.7994 - val_loss: 0.4358 - val_acc: 0.8022\n",
      "Epoch 376/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4385 - acc: 0.7978 - val_loss: 0.4391 - val_acc: 0.8022\n",
      "Epoch 377/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4384 - acc: 0.7994 - val_loss: 0.4356 - val_acc: 0.8022\n",
      "Epoch 378/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4382 - acc: 0.7978 - val_loss: 0.4389 - val_acc: 0.8022\n",
      "Epoch 379/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4382 - acc: 0.8010 - val_loss: 0.4355 - val_acc: 0.8022\n",
      "Epoch 380/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4380 - acc: 0.7978 - val_loss: 0.4387 - val_acc: 0.8022\n",
      "Epoch 381/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4379 - acc: 0.8010 - val_loss: 0.4352 - val_acc: 0.8022\n",
      "Epoch 382/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4378 - acc: 0.7978 - val_loss: 0.4385 - val_acc: 0.8022\n",
      "Epoch 383/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4377 - acc: 0.8010 - val_loss: 0.4350 - val_acc: 0.8022\n",
      "Epoch 384/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4375 - acc: 0.7978 - val_loss: 0.4383 - val_acc: 0.8022\n",
      "Epoch 385/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4374 - acc: 0.8026 - val_loss: 0.4349 - val_acc: 0.8022\n",
      "Epoch 386/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4373 - acc: 0.7978 - val_loss: 0.4382 - val_acc: 0.8022\n",
      "Epoch 387/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4373 - acc: 0.8026 - val_loss: 0.4346 - val_acc: 0.8022\n",
      "Epoch 388/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4371 - acc: 0.7994 - val_loss: 0.4380 - val_acc: 0.8022\n",
      "Epoch 389/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4370 - acc: 0.8026 - val_loss: 0.4345 - val_acc: 0.8022\n",
      "Epoch 390/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4369 - acc: 0.7994 - val_loss: 0.4378 - val_acc: 0.8022\n",
      "Epoch 391/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4368 - acc: 0.8026 - val_loss: 0.4342 - val_acc: 0.8022\n",
      "Epoch 392/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4366 - acc: 0.7994 - val_loss: 0.4375 - val_acc: 0.8022\n",
      "Epoch 393/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4365 - acc: 0.8026 - val_loss: 0.4342 - val_acc: 0.8022\n",
      "Epoch 394/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4364 - acc: 0.7994 - val_loss: 0.4374 - val_acc: 0.8022\n",
      "Epoch 395/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4363 - acc: 0.8026 - val_loss: 0.4339 - val_acc: 0.8022\n",
      "Epoch 396/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4362 - acc: 0.7978 - val_loss: 0.4372 - val_acc: 0.8022\n",
      "Epoch 397/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4361 - acc: 0.8026 - val_loss: 0.4337 - val_acc: 0.8022\n",
      "Epoch 398/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4360 - acc: 0.7978 - val_loss: 0.4371 - val_acc: 0.8022\n",
      "Epoch 399/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4359 - acc: 0.8026 - val_loss: 0.4335 - val_acc: 0.8022\n",
      "Epoch 400/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4358 - acc: 0.7978 - val_loss: 0.4369 - val_acc: 0.8060\n",
      "Epoch 401/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4357 - acc: 0.8026 - val_loss: 0.4334 - val_acc: 0.8022\n",
      "Epoch 402/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4355 - acc: 0.7978 - val_loss: 0.4367 - val_acc: 0.8060\n",
      "Epoch 403/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4355 - acc: 0.8026 - val_loss: 0.4331 - val_acc: 0.8022\n",
      "Epoch 404/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4353 - acc: 0.7994 - val_loss: 0.4365 - val_acc: 0.8060\n",
      "Epoch 405/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4352 - acc: 0.8042 - val_loss: 0.4329 - val_acc: 0.8022\n",
      "Epoch 406/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4351 - acc: 0.8010 - val_loss: 0.4363 - val_acc: 0.8060\n",
      "Epoch 407/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4350 - acc: 0.8026 - val_loss: 0.4327 - val_acc: 0.8022\n",
      "Epoch 408/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4348 - acc: 0.8010 - val_loss: 0.4361 - val_acc: 0.8060\n",
      "Epoch 409/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4348 - acc: 0.8026 - val_loss: 0.4325 - val_acc: 0.8022\n",
      "Epoch 410/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4346 - acc: 0.8010 - val_loss: 0.4359 - val_acc: 0.8060\n",
      "Epoch 411/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4345 - acc: 0.8042 - val_loss: 0.4323 - val_acc: 0.8060\n",
      "Epoch 412/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4344 - acc: 0.8010 - val_loss: 0.4358 - val_acc: 0.8060\n",
      "Epoch 413/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4343 - acc: 0.8042 - val_loss: 0.4322 - val_acc: 0.8060\n",
      "Epoch 414/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4342 - acc: 0.8010 - val_loss: 0.4356 - val_acc: 0.8060\n",
      "Epoch 415/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4341 - acc: 0.8042 - val_loss: 0.4320 - val_acc: 0.8060\n",
      "Epoch 416/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4340 - acc: 0.8010 - val_loss: 0.4354 - val_acc: 0.8060\n",
      "Epoch 417/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4339 - acc: 0.8042 - val_loss: 0.4319 - val_acc: 0.8060\n",
      "Epoch 418/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4338 - acc: 0.8010 - val_loss: 0.4353 - val_acc: 0.8060\n",
      "Epoch 419/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4336 - acc: 0.8026 - val_loss: 0.4316 - val_acc: 0.8060\n",
      "Epoch 420/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4335 - acc: 0.8010 - val_loss: 0.4351 - val_acc: 0.8022\n",
      "Epoch 421/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4334 - acc: 0.8042 - val_loss: 0.4315 - val_acc: 0.8060\n",
      "Epoch 422/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4333 - acc: 0.8010 - val_loss: 0.4349 - val_acc: 0.8022\n",
      "Epoch 423/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4332 - acc: 0.8042 - val_loss: 0.4313 - val_acc: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4331 - acc: 0.8010 - val_loss: 0.4349 - val_acc: 0.8022\n",
      "Epoch 425/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4330 - acc: 0.8042 - val_loss: 0.4312 - val_acc: 0.8060\n",
      "Epoch 426/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4329 - acc: 0.8010 - val_loss: 0.4347 - val_acc: 0.8022\n",
      "Epoch 427/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4328 - acc: 0.8042 - val_loss: 0.4309 - val_acc: 0.8060\n",
      "Epoch 428/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4327 - acc: 0.8010 - val_loss: 0.4345 - val_acc: 0.8022\n",
      "Epoch 429/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4326 - acc: 0.8042 - val_loss: 0.4308 - val_acc: 0.8060\n",
      "Epoch 430/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4324 - acc: 0.8010 - val_loss: 0.4343 - val_acc: 0.8022\n",
      "Epoch 431/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4323 - acc: 0.8042 - val_loss: 0.4306 - val_acc: 0.8060\n",
      "Epoch 432/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4322 - acc: 0.8010 - val_loss: 0.4342 - val_acc: 0.8022\n",
      "Epoch 433/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4321 - acc: 0.8026 - val_loss: 0.4305 - val_acc: 0.8060\n",
      "Epoch 434/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4320 - acc: 0.8010 - val_loss: 0.4340 - val_acc: 0.8022\n",
      "Epoch 435/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4319 - acc: 0.8026 - val_loss: 0.4303 - val_acc: 0.8060\n",
      "Epoch 436/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4318 - acc: 0.8010 - val_loss: 0.4338 - val_acc: 0.8022\n",
      "Epoch 437/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4317 - acc: 0.8026 - val_loss: 0.4302 - val_acc: 0.8060\n",
      "Epoch 438/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4316 - acc: 0.8010 - val_loss: 0.4337 - val_acc: 0.8022\n",
      "Epoch 439/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4315 - acc: 0.8026 - val_loss: 0.4299 - val_acc: 0.8060\n",
      "Epoch 440/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4314 - acc: 0.8010 - val_loss: 0.4335 - val_acc: 0.8022\n",
      "Epoch 441/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4313 - acc: 0.8026 - val_loss: 0.4298 - val_acc: 0.8060\n",
      "Epoch 442/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4311 - acc: 0.8010 - val_loss: 0.4333 - val_acc: 0.8022\n",
      "Epoch 443/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4311 - acc: 0.8026 - val_loss: 0.4296 - val_acc: 0.8060\n",
      "Epoch 444/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4310 - acc: 0.8010 - val_loss: 0.4332 - val_acc: 0.8022\n",
      "Epoch 445/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4309 - acc: 0.8026 - val_loss: 0.4294 - val_acc: 0.8060\n",
      "Epoch 446/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4307 - acc: 0.8026 - val_loss: 0.4330 - val_acc: 0.8022\n",
      "Epoch 447/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4306 - acc: 0.8042 - val_loss: 0.4292 - val_acc: 0.8060\n",
      "Epoch 448/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4305 - acc: 0.8026 - val_loss: 0.4328 - val_acc: 0.8022\n",
      "Epoch 449/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4304 - acc: 0.8042 - val_loss: 0.4291 - val_acc: 0.8060\n",
      "Epoch 450/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4303 - acc: 0.8026 - val_loss: 0.4327 - val_acc: 0.8022\n",
      "Epoch 451/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4302 - acc: 0.8042 - val_loss: 0.4289 - val_acc: 0.8060\n",
      "Epoch 452/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4301 - acc: 0.8026 - val_loss: 0.4325 - val_acc: 0.8022\n",
      "Epoch 453/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4300 - acc: 0.8042 - val_loss: 0.4287 - val_acc: 0.8060\n",
      "Epoch 454/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4299 - acc: 0.8026 - val_loss: 0.4324 - val_acc: 0.8022\n",
      "Epoch 455/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4299 - acc: 0.8042 - val_loss: 0.4286 - val_acc: 0.8060\n",
      "Epoch 456/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4297 - acc: 0.8026 - val_loss: 0.4323 - val_acc: 0.8022\n",
      "Epoch 457/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4296 - acc: 0.8042 - val_loss: 0.4283 - val_acc: 0.8060\n",
      "Epoch 458/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4295 - acc: 0.8058 - val_loss: 0.4320 - val_acc: 0.8022\n",
      "Epoch 459/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4294 - acc: 0.8026 - val_loss: 0.4282 - val_acc: 0.8060\n",
      "Epoch 460/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4292 - acc: 0.8042 - val_loss: 0.4318 - val_acc: 0.8022\n",
      "Epoch 461/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4292 - acc: 0.8026 - val_loss: 0.4280 - val_acc: 0.8060\n",
      "Epoch 462/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4291 - acc: 0.8042 - val_loss: 0.4318 - val_acc: 0.8022\n",
      "Epoch 463/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4290 - acc: 0.8026 - val_loss: 0.4279 - val_acc: 0.8060\n",
      "Epoch 464/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4289 - acc: 0.8042 - val_loss: 0.4316 - val_acc: 0.8022\n",
      "Epoch 465/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4288 - acc: 0.8026 - val_loss: 0.4276 - val_acc: 0.8060\n",
      "Epoch 466/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4287 - acc: 0.8042 - val_loss: 0.4314 - val_acc: 0.8022\n",
      "Epoch 467/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4286 - acc: 0.8026 - val_loss: 0.4275 - val_acc: 0.8060\n",
      "Epoch 468/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4285 - acc: 0.8042 - val_loss: 0.4313 - val_acc: 0.8022\n",
      "Epoch 469/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4285 - acc: 0.8058 - val_loss: 0.4274 - val_acc: 0.8060\n",
      "Epoch 470/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4283 - acc: 0.8042 - val_loss: 0.4312 - val_acc: 0.8060\n",
      "Epoch 471/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4282 - acc: 0.8058 - val_loss: 0.4272 - val_acc: 0.8060\n",
      "Epoch 472/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4281 - acc: 0.8042 - val_loss: 0.4309 - val_acc: 0.8060\n",
      "Epoch 473/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4279 - acc: 0.8058 - val_loss: 0.4270 - val_acc: 0.8060\n",
      "Epoch 474/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4278 - acc: 0.8042 - val_loss: 0.4307 - val_acc: 0.8060\n",
      "Epoch 475/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4277 - acc: 0.8058 - val_loss: 0.4268 - val_acc: 0.8060\n",
      "Epoch 476/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4276 - acc: 0.8042 - val_loss: 0.4306 - val_acc: 0.8060\n",
      "Epoch 477/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4276 - acc: 0.8058 - val_loss: 0.4268 - val_acc: 0.8060\n",
      "Epoch 478/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4275 - acc: 0.8058 - val_loss: 0.4305 - val_acc: 0.8060\n",
      "Epoch 479/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4275 - acc: 0.8058 - val_loss: 0.4267 - val_acc: 0.8060\n",
      "Epoch 480/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4273 - acc: 0.8058 - val_loss: 0.4305 - val_acc: 0.8060\n",
      "Epoch 481/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4273 - acc: 0.8058 - val_loss: 0.4265 - val_acc: 0.8060\n",
      "Epoch 482/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4271 - acc: 0.8058 - val_loss: 0.4303 - val_acc: 0.8060\n",
      "Epoch 483/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4271 - acc: 0.8058 - val_loss: 0.4263 - val_acc: 0.8060\n",
      "Epoch 484/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4269 - acc: 0.8058 - val_loss: 0.4300 - val_acc: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4268 - acc: 0.8090 - val_loss: 0.4261 - val_acc: 0.8060\n",
      "Epoch 486/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4267 - acc: 0.8058 - val_loss: 0.4299 - val_acc: 0.8022\n",
      "Epoch 487/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4266 - acc: 0.8090 - val_loss: 0.4261 - val_acc: 0.8060\n",
      "Epoch 488/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4265 - acc: 0.8058 - val_loss: 0.4298 - val_acc: 0.8022\n",
      "Epoch 489/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4265 - acc: 0.8090 - val_loss: 0.4259 - val_acc: 0.8060\n",
      "Epoch 490/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4263 - acc: 0.8058 - val_loss: 0.4297 - val_acc: 0.8022\n",
      "Epoch 491/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4263 - acc: 0.8090 - val_loss: 0.4257 - val_acc: 0.8060\n",
      "Epoch 492/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4262 - acc: 0.8058 - val_loss: 0.4296 - val_acc: 0.8022\n",
      "Epoch 493/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4262 - acc: 0.8090 - val_loss: 0.4256 - val_acc: 0.8060\n",
      "Epoch 494/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4260 - acc: 0.8058 - val_loss: 0.4295 - val_acc: 0.8022\n",
      "Epoch 495/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4259 - acc: 0.8090 - val_loss: 0.4255 - val_acc: 0.8060\n",
      "Epoch 496/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4258 - acc: 0.8058 - val_loss: 0.4293 - val_acc: 0.8022\n",
      "Epoch 497/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4257 - acc: 0.8090 - val_loss: 0.4253 - val_acc: 0.8060\n",
      "Epoch 498/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4256 - acc: 0.8058 - val_loss: 0.4291 - val_acc: 0.8022\n",
      "Epoch 499/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4255 - acc: 0.8090 - val_loss: 0.4252 - val_acc: 0.8060\n",
      "Epoch 500/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4253 - acc: 0.8058 - val_loss: 0.4290 - val_acc: 0.8022\n",
      "Epoch 501/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4253 - acc: 0.8090 - val_loss: 0.4250 - val_acc: 0.8060\n",
      "Epoch 502/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4251 - acc: 0.8058 - val_loss: 0.4288 - val_acc: 0.8022\n",
      "Epoch 503/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4251 - acc: 0.8090 - val_loss: 0.4248 - val_acc: 0.8060\n",
      "Epoch 504/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4250 - acc: 0.8058 - val_loss: 0.4288 - val_acc: 0.8022\n",
      "Epoch 505/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4250 - acc: 0.8090 - val_loss: 0.4248 - val_acc: 0.8060\n",
      "Epoch 506/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4248 - acc: 0.8058 - val_loss: 0.4287 - val_acc: 0.8022\n",
      "Epoch 507/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4249 - acc: 0.8090 - val_loss: 0.4247 - val_acc: 0.8060\n",
      "Epoch 508/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4247 - acc: 0.8058 - val_loss: 0.4287 - val_acc: 0.8022\n",
      "Epoch 509/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4247 - acc: 0.8138 - val_loss: 0.4245 - val_acc: 0.8060\n",
      "Epoch 510/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4245 - acc: 0.8058 - val_loss: 0.4284 - val_acc: 0.8022\n",
      "Epoch 511/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4244 - acc: 0.8138 - val_loss: 0.4244 - val_acc: 0.8060\n",
      "Epoch 512/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4243 - acc: 0.8058 - val_loss: 0.4283 - val_acc: 0.8022\n",
      "Epoch 513/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4242 - acc: 0.8106 - val_loss: 0.4243 - val_acc: 0.8060\n",
      "Epoch 514/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.4240 - acc: 0.8058 - val_loss: 0.4281 - val_acc: 0.8022\n",
      "Epoch 515/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4240 - acc: 0.8106 - val_loss: 0.4241 - val_acc: 0.8060\n",
      "Epoch 516/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4238 - acc: 0.8058 - val_loss: 0.4279 - val_acc: 0.8022\n",
      "Epoch 517/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4238 - acc: 0.8106 - val_loss: 0.4240 - val_acc: 0.8060\n",
      "Epoch 518/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4237 - acc: 0.8058 - val_loss: 0.4279 - val_acc: 0.8022\n",
      "Epoch 519/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4237 - acc: 0.8154 - val_loss: 0.4239 - val_acc: 0.8060\n",
      "Epoch 520/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4236 - acc: 0.8058 - val_loss: 0.4280 - val_acc: 0.8060\n",
      "Epoch 521/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4236 - acc: 0.8154 - val_loss: 0.4238 - val_acc: 0.8060\n",
      "Epoch 522/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4234 - acc: 0.8058 - val_loss: 0.4277 - val_acc: 0.8060\n",
      "Epoch 523/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4233 - acc: 0.8154 - val_loss: 0.4237 - val_acc: 0.8060\n",
      "Epoch 524/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4232 - acc: 0.8058 - val_loss: 0.4276 - val_acc: 0.8060\n",
      "Epoch 525/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4231 - acc: 0.8154 - val_loss: 0.4235 - val_acc: 0.8060\n",
      "Epoch 526/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4230 - acc: 0.8058 - val_loss: 0.4274 - val_acc: 0.8060\n",
      "Epoch 527/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4229 - acc: 0.8154 - val_loss: 0.4234 - val_acc: 0.8060\n",
      "Epoch 528/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4228 - acc: 0.8042 - val_loss: 0.4273 - val_acc: 0.8060\n",
      "Epoch 529/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4228 - acc: 0.8154 - val_loss: 0.4233 - val_acc: 0.8097\n",
      "Epoch 530/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4227 - acc: 0.8058 - val_loss: 0.4272 - val_acc: 0.8097\n",
      "Epoch 531/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4227 - acc: 0.8154 - val_loss: 0.4231 - val_acc: 0.8097\n",
      "Epoch 532/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4225 - acc: 0.8058 - val_loss: 0.4271 - val_acc: 0.8097\n",
      "Epoch 533/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4225 - acc: 0.8170 - val_loss: 0.4230 - val_acc: 0.8097\n",
      "Epoch 534/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4223 - acc: 0.8058 - val_loss: 0.4270 - val_acc: 0.8097\n",
      "Epoch 535/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4223 - acc: 0.8170 - val_loss: 0.4229 - val_acc: 0.8097\n",
      "Epoch 536/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4222 - acc: 0.8058 - val_loss: 0.4269 - val_acc: 0.8097\n",
      "Epoch 537/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4222 - acc: 0.8170 - val_loss: 0.4227 - val_acc: 0.8097\n",
      "Epoch 538/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4219 - acc: 0.8042 - val_loss: 0.4266 - val_acc: 0.8060\n",
      "Epoch 539/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4219 - acc: 0.8186 - val_loss: 0.4226 - val_acc: 0.8097\n",
      "Epoch 540/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4217 - acc: 0.8042 - val_loss: 0.4264 - val_acc: 0.8060\n",
      "Epoch 541/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4217 - acc: 0.8186 - val_loss: 0.4225 - val_acc: 0.8097\n",
      "Epoch 542/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4215 - acc: 0.8042 - val_loss: 0.4265 - val_acc: 0.8060\n",
      "Epoch 543/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4215 - acc: 0.8186 - val_loss: 0.4223 - val_acc: 0.8097\n",
      "Epoch 544/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4214 - acc: 0.8042 - val_loss: 0.4264 - val_acc: 0.8060\n",
      "Epoch 545/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4214 - acc: 0.8186 - val_loss: 0.4222 - val_acc: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4213 - acc: 0.8042 - val_loss: 0.4263 - val_acc: 0.8060\n",
      "Epoch 547/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4213 - acc: 0.8186 - val_loss: 0.4221 - val_acc: 0.8097\n",
      "Epoch 548/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4211 - acc: 0.8042 - val_loss: 0.4262 - val_acc: 0.8060\n",
      "Epoch 549/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4211 - acc: 0.8202 - val_loss: 0.4219 - val_acc: 0.8097\n",
      "Epoch 550/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4210 - acc: 0.8042 - val_loss: 0.4261 - val_acc: 0.8060\n",
      "Epoch 551/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4209 - acc: 0.8202 - val_loss: 0.4219 - val_acc: 0.8097\n",
      "Epoch 552/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4207 - acc: 0.8042 - val_loss: 0.4259 - val_acc: 0.8060\n",
      "Epoch 553/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4206 - acc: 0.8202 - val_loss: 0.4218 - val_acc: 0.8097\n",
      "Epoch 554/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4205 - acc: 0.8042 - val_loss: 0.4258 - val_acc: 0.8060\n",
      "Epoch 555/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4205 - acc: 0.8186 - val_loss: 0.4217 - val_acc: 0.8097\n",
      "Epoch 556/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4203 - acc: 0.8042 - val_loss: 0.4257 - val_acc: 0.8097\n",
      "Epoch 557/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4203 - acc: 0.8186 - val_loss: 0.4217 - val_acc: 0.8097\n",
      "Epoch 558/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4201 - acc: 0.8058 - val_loss: 0.4257 - val_acc: 0.8134\n",
      "Epoch 559/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4202 - acc: 0.8186 - val_loss: 0.4215 - val_acc: 0.8097\n",
      "Epoch 560/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4200 - acc: 0.8058 - val_loss: 0.4256 - val_acc: 0.8134\n",
      "Epoch 561/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4200 - acc: 0.8186 - val_loss: 0.4214 - val_acc: 0.8097\n",
      "Epoch 562/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4198 - acc: 0.8058 - val_loss: 0.4256 - val_acc: 0.8134\n",
      "Epoch 563/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4197 - acc: 0.8186 - val_loss: 0.4213 - val_acc: 0.8097\n",
      "Epoch 564/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4196 - acc: 0.8058 - val_loss: 0.4254 - val_acc: 0.8134\n",
      "Epoch 565/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4195 - acc: 0.8186 - val_loss: 0.4213 - val_acc: 0.8097\n",
      "Epoch 566/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4194 - acc: 0.8058 - val_loss: 0.4253 - val_acc: 0.8134\n",
      "Epoch 567/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4193 - acc: 0.8170 - val_loss: 0.4211 - val_acc: 0.8097\n",
      "Epoch 568/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4192 - acc: 0.8058 - val_loss: 0.4252 - val_acc: 0.8134\n",
      "Epoch 569/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4191 - acc: 0.8186 - val_loss: 0.4210 - val_acc: 0.8097\n",
      "Epoch 570/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4190 - acc: 0.8058 - val_loss: 0.4251 - val_acc: 0.8134\n",
      "Epoch 571/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4190 - acc: 0.8186 - val_loss: 0.4209 - val_acc: 0.8097\n",
      "Epoch 572/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4189 - acc: 0.8058 - val_loss: 0.4251 - val_acc: 0.8134\n",
      "Epoch 573/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4189 - acc: 0.8186 - val_loss: 0.4207 - val_acc: 0.8097\n",
      "Epoch 574/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4187 - acc: 0.8058 - val_loss: 0.4250 - val_acc: 0.8134\n",
      "Epoch 575/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4187 - acc: 0.8186 - val_loss: 0.4206 - val_acc: 0.8134\n",
      "Epoch 576/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4185 - acc: 0.8090 - val_loss: 0.4247 - val_acc: 0.8134\n",
      "Epoch 577/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4185 - acc: 0.8186 - val_loss: 0.4204 - val_acc: 0.8134\n",
      "Epoch 578/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4183 - acc: 0.8090 - val_loss: 0.4245 - val_acc: 0.8134\n",
      "Epoch 579/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4182 - acc: 0.8170 - val_loss: 0.4202 - val_acc: 0.8134\n",
      "Epoch 580/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4181 - acc: 0.8090 - val_loss: 0.4243 - val_acc: 0.8134\n",
      "Epoch 581/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4180 - acc: 0.8170 - val_loss: 0.4201 - val_acc: 0.8134\n",
      "Epoch 582/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4179 - acc: 0.8090 - val_loss: 0.4242 - val_acc: 0.8134\n",
      "Epoch 583/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4179 - acc: 0.8186 - val_loss: 0.4199 - val_acc: 0.8134\n",
      "Epoch 584/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4178 - acc: 0.8090 - val_loss: 0.4243 - val_acc: 0.8134\n",
      "Epoch 585/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4178 - acc: 0.8186 - val_loss: 0.4199 - val_acc: 0.8134\n",
      "Epoch 586/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4177 - acc: 0.8090 - val_loss: 0.4242 - val_acc: 0.8134\n",
      "Epoch 587/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4177 - acc: 0.8186 - val_loss: 0.4198 - val_acc: 0.8134\n",
      "Epoch 588/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4176 - acc: 0.8090 - val_loss: 0.4240 - val_acc: 0.8134\n",
      "Epoch 589/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4175 - acc: 0.8186 - val_loss: 0.4196 - val_acc: 0.8134\n",
      "Epoch 590/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4173 - acc: 0.8090 - val_loss: 0.4238 - val_acc: 0.8134\n",
      "Epoch 591/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4173 - acc: 0.8186 - val_loss: 0.4194 - val_acc: 0.8134\n",
      "Epoch 592/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4171 - acc: 0.8106 - val_loss: 0.4235 - val_acc: 0.8134\n",
      "Epoch 593/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4170 - acc: 0.8186 - val_loss: 0.4192 - val_acc: 0.8134\n",
      "Epoch 594/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4169 - acc: 0.8090 - val_loss: 0.4233 - val_acc: 0.8134\n",
      "Epoch 595/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4169 - acc: 0.8186 - val_loss: 0.4191 - val_acc: 0.8134\n",
      "Epoch 596/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4167 - acc: 0.8090 - val_loss: 0.4232 - val_acc: 0.8134\n",
      "Epoch 597/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4167 - acc: 0.8186 - val_loss: 0.4190 - val_acc: 0.8134\n",
      "Epoch 598/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4166 - acc: 0.8074 - val_loss: 0.4232 - val_acc: 0.8134\n",
      "Epoch 599/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4166 - acc: 0.8186 - val_loss: 0.4189 - val_acc: 0.8134\n",
      "Epoch 600/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4165 - acc: 0.8074 - val_loss: 0.4231 - val_acc: 0.8134\n",
      "Epoch 601/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4165 - acc: 0.8186 - val_loss: 0.4187 - val_acc: 0.8134\n",
      "Epoch 602/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4163 - acc: 0.8074 - val_loss: 0.4230 - val_acc: 0.8134\n",
      "Epoch 603/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4163 - acc: 0.8202 - val_loss: 0.4186 - val_acc: 0.8134\n",
      "Epoch 604/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4162 - acc: 0.8074 - val_loss: 0.4227 - val_acc: 0.8134\n",
      "Epoch 605/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4161 - acc: 0.8202 - val_loss: 0.4184 - val_acc: 0.8134\n",
      "Epoch 606/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4159 - acc: 0.8074 - val_loss: 0.4226 - val_acc: 0.8134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4159 - acc: 0.8202 - val_loss: 0.4182 - val_acc: 0.8134\n",
      "Epoch 608/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4157 - acc: 0.8074 - val_loss: 0.4225 - val_acc: 0.8134\n",
      "Epoch 609/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4158 - acc: 0.8202 - val_loss: 0.4181 - val_acc: 0.8134\n",
      "Epoch 610/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4156 - acc: 0.8074 - val_loss: 0.4224 - val_acc: 0.8134\n",
      "Epoch 611/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4156 - acc: 0.8202 - val_loss: 0.4180 - val_acc: 0.8134\n",
      "Epoch 612/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4155 - acc: 0.8090 - val_loss: 0.4223 - val_acc: 0.8134\n",
      "Epoch 613/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4155 - acc: 0.8202 - val_loss: 0.4179 - val_acc: 0.8134\n",
      "Epoch 614/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4154 - acc: 0.8090 - val_loss: 0.4222 - val_acc: 0.8172\n",
      "Epoch 615/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4153 - acc: 0.8218 - val_loss: 0.4177 - val_acc: 0.8134\n",
      "Epoch 616/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4152 - acc: 0.8090 - val_loss: 0.4219 - val_acc: 0.8134\n",
      "Epoch 617/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4152 - acc: 0.8218 - val_loss: 0.4176 - val_acc: 0.8134\n",
      "Epoch 618/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4150 - acc: 0.8074 - val_loss: 0.4218 - val_acc: 0.8134\n",
      "Epoch 619/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4150 - acc: 0.8218 - val_loss: 0.4175 - val_acc: 0.8134\n",
      "Epoch 620/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4148 - acc: 0.8074 - val_loss: 0.4217 - val_acc: 0.8134\n",
      "Epoch 621/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4148 - acc: 0.8218 - val_loss: 0.4173 - val_acc: 0.8134\n",
      "Epoch 622/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4147 - acc: 0.8074 - val_loss: 0.4216 - val_acc: 0.8172\n",
      "Epoch 623/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4146 - acc: 0.8218 - val_loss: 0.4172 - val_acc: 0.8134\n",
      "Epoch 624/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4145 - acc: 0.8074 - val_loss: 0.4215 - val_acc: 0.8172\n",
      "Epoch 625/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4145 - acc: 0.8234 - val_loss: 0.4171 - val_acc: 0.8134\n",
      "Epoch 626/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4144 - acc: 0.8074 - val_loss: 0.4215 - val_acc: 0.8172\n",
      "Epoch 627/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4144 - acc: 0.8234 - val_loss: 0.4170 - val_acc: 0.8172\n",
      "Epoch 628/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4142 - acc: 0.8074 - val_loss: 0.4213 - val_acc: 0.8172\n",
      "Epoch 629/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4143 - acc: 0.8234 - val_loss: 0.4169 - val_acc: 0.8209\n",
      "Epoch 630/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4141 - acc: 0.8074 - val_loss: 0.4211 - val_acc: 0.8172\n",
      "Epoch 631/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4140 - acc: 0.8234 - val_loss: 0.4167 - val_acc: 0.8209\n",
      "Epoch 632/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4139 - acc: 0.8074 - val_loss: 0.4210 - val_acc: 0.8172\n",
      "Epoch 633/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4138 - acc: 0.8234 - val_loss: 0.4166 - val_acc: 0.8209\n",
      "Epoch 634/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4137 - acc: 0.8106 - val_loss: 0.4208 - val_acc: 0.8172\n",
      "Epoch 635/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4137 - acc: 0.8234 - val_loss: 0.4165 - val_acc: 0.8209\n",
      "Epoch 636/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4136 - acc: 0.8106 - val_loss: 0.4208 - val_acc: 0.8172\n",
      "Epoch 637/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4136 - acc: 0.8234 - val_loss: 0.4163 - val_acc: 0.8209\n",
      "Epoch 638/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4135 - acc: 0.8074 - val_loss: 0.4208 - val_acc: 0.8172\n",
      "Epoch 639/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4135 - acc: 0.8234 - val_loss: 0.4163 - val_acc: 0.8209\n",
      "Epoch 640/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4133 - acc: 0.8106 - val_loss: 0.4206 - val_acc: 0.8172\n",
      "Epoch 641/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4133 - acc: 0.8218 - val_loss: 0.4161 - val_acc: 0.8209\n",
      "Epoch 642/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4131 - acc: 0.8106 - val_loss: 0.4204 - val_acc: 0.8172\n",
      "Epoch 643/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4131 - acc: 0.8218 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 644/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4130 - acc: 0.8106 - val_loss: 0.4203 - val_acc: 0.8209\n",
      "Epoch 645/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4129 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8246\n",
      "Epoch 646/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4128 - acc: 0.8106 - val_loss: 0.4202 - val_acc: 0.8172\n",
      "Epoch 647/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4128 - acc: 0.8202 - val_loss: 0.4157 - val_acc: 0.8246\n",
      "Epoch 648/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4127 - acc: 0.8106 - val_loss: 0.4201 - val_acc: 0.8209\n",
      "Epoch 649/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4127 - acc: 0.8202 - val_loss: 0.4156 - val_acc: 0.8246\n",
      "Epoch 650/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4125 - acc: 0.8106 - val_loss: 0.4200 - val_acc: 0.8172\n",
      "Epoch 651/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4126 - acc: 0.8202 - val_loss: 0.4155 - val_acc: 0.8246\n",
      "Epoch 652/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4124 - acc: 0.8106 - val_loss: 0.4198 - val_acc: 0.8172\n",
      "Epoch 653/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4124 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 654/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4122 - acc: 0.8106 - val_loss: 0.4197 - val_acc: 0.8209\n",
      "Epoch 655/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4122 - acc: 0.8202 - val_loss: 0.4153 - val_acc: 0.8284\n",
      "Epoch 656/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4121 - acc: 0.8122 - val_loss: 0.4196 - val_acc: 0.8172\n",
      "Epoch 657/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4120 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 658/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4119 - acc: 0.8122 - val_loss: 0.4195 - val_acc: 0.8172\n",
      "Epoch 659/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4119 - acc: 0.8202 - val_loss: 0.4150 - val_acc: 0.8284\n",
      "Epoch 660/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4118 - acc: 0.8122 - val_loss: 0.4194 - val_acc: 0.8172\n",
      "Epoch 661/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4117 - acc: 0.8202 - val_loss: 0.4149 - val_acc: 0.8284\n",
      "Epoch 662/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4117 - acc: 0.8122 - val_loss: 0.4193 - val_acc: 0.8172\n",
      "Epoch 663/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4116 - acc: 0.8202 - val_loss: 0.4148 - val_acc: 0.8284\n",
      "Epoch 664/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4115 - acc: 0.8122 - val_loss: 0.4192 - val_acc: 0.8172\n",
      "Epoch 665/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4115 - acc: 0.8202 - val_loss: 0.4147 - val_acc: 0.8284\n",
      "Epoch 666/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4114 - acc: 0.8138 - val_loss: 0.4191 - val_acc: 0.8172\n",
      "Epoch 667/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4113 - acc: 0.8202 - val_loss: 0.4145 - val_acc: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4112 - acc: 0.8138 - val_loss: 0.4191 - val_acc: 0.8172\n",
      "Epoch 669/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4112 - acc: 0.8202 - val_loss: 0.4145 - val_acc: 0.8284\n",
      "Epoch 670/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4110 - acc: 0.8138 - val_loss: 0.4189 - val_acc: 0.8172\n",
      "Epoch 671/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4110 - acc: 0.8202 - val_loss: 0.4143 - val_acc: 0.8284\n",
      "Epoch 672/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4109 - acc: 0.8138 - val_loss: 0.4186 - val_acc: 0.8209\n",
      "Epoch 673/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4109 - acc: 0.8202 - val_loss: 0.4141 - val_acc: 0.8284\n",
      "Epoch 674/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4107 - acc: 0.8138 - val_loss: 0.4186 - val_acc: 0.8172\n",
      "Epoch 675/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4107 - acc: 0.8202 - val_loss: 0.4140 - val_acc: 0.8284\n",
      "Epoch 676/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4106 - acc: 0.8138 - val_loss: 0.4185 - val_acc: 0.8172\n",
      "Epoch 677/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4106 - acc: 0.8170 - val_loss: 0.4139 - val_acc: 0.8284\n",
      "Epoch 678/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4105 - acc: 0.8138 - val_loss: 0.4184 - val_acc: 0.8172\n",
      "Epoch 679/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4105 - acc: 0.8170 - val_loss: 0.4138 - val_acc: 0.8284\n",
      "Epoch 680/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4104 - acc: 0.8138 - val_loss: 0.4184 - val_acc: 0.8172\n",
      "Epoch 681/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4103 - acc: 0.8170 - val_loss: 0.4137 - val_acc: 0.8284\n",
      "Epoch 682/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4102 - acc: 0.8138 - val_loss: 0.4183 - val_acc: 0.8172\n",
      "Epoch 683/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4102 - acc: 0.8170 - val_loss: 0.4136 - val_acc: 0.8284\n",
      "Epoch 684/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4100 - acc: 0.8122 - val_loss: 0.4180 - val_acc: 0.8172\n",
      "Epoch 685/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4100 - acc: 0.8154 - val_loss: 0.4135 - val_acc: 0.8284\n",
      "Epoch 686/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4099 - acc: 0.8122 - val_loss: 0.4181 - val_acc: 0.8172\n",
      "Epoch 687/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4099 - acc: 0.8154 - val_loss: 0.4134 - val_acc: 0.8284\n",
      "Epoch 688/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4098 - acc: 0.8122 - val_loss: 0.4179 - val_acc: 0.8172\n",
      "Epoch 689/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4097 - acc: 0.8154 - val_loss: 0.4133 - val_acc: 0.8284\n",
      "Epoch 690/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4096 - acc: 0.8122 - val_loss: 0.4178 - val_acc: 0.8172\n",
      "Epoch 691/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4096 - acc: 0.8154 - val_loss: 0.4133 - val_acc: 0.8284\n",
      "Epoch 692/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4095 - acc: 0.8122 - val_loss: 0.4176 - val_acc: 0.8172\n",
      "Epoch 693/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4095 - acc: 0.8154 - val_loss: 0.4131 - val_acc: 0.8284\n",
      "Epoch 694/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4093 - acc: 0.8138 - val_loss: 0.4177 - val_acc: 0.8172\n",
      "Epoch 695/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4093 - acc: 0.8154 - val_loss: 0.4128 - val_acc: 0.8284\n",
      "Epoch 696/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4092 - acc: 0.8138 - val_loss: 0.4175 - val_acc: 0.8172\n",
      "Epoch 697/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4092 - acc: 0.8154 - val_loss: 0.4128 - val_acc: 0.8284\n",
      "Epoch 698/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4091 - acc: 0.8138 - val_loss: 0.4176 - val_acc: 0.8172\n",
      "Epoch 699/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4091 - acc: 0.8154 - val_loss: 0.4127 - val_acc: 0.8284\n",
      "Epoch 700/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4090 - acc: 0.8138 - val_loss: 0.4174 - val_acc: 0.8172\n",
      "Epoch 701/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4089 - acc: 0.8170 - val_loss: 0.4127 - val_acc: 0.8246\n",
      "Epoch 702/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4088 - acc: 0.8138 - val_loss: 0.4171 - val_acc: 0.8172\n",
      "Epoch 703/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4087 - acc: 0.8170 - val_loss: 0.4126 - val_acc: 0.8246\n",
      "Epoch 704/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4086 - acc: 0.8138 - val_loss: 0.4170 - val_acc: 0.8172\n",
      "Epoch 705/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4086 - acc: 0.8170 - val_loss: 0.4125 - val_acc: 0.8246\n",
      "Epoch 706/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4084 - acc: 0.8138 - val_loss: 0.4171 - val_acc: 0.8172\n",
      "Epoch 707/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4085 - acc: 0.8170 - val_loss: 0.4123 - val_acc: 0.8246\n",
      "Epoch 708/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4084 - acc: 0.8170 - val_loss: 0.4170 - val_acc: 0.8172\n",
      "Epoch 709/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4084 - acc: 0.8170 - val_loss: 0.4121 - val_acc: 0.8246\n",
      "Epoch 710/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4083 - acc: 0.8170 - val_loss: 0.4169 - val_acc: 0.8172\n",
      "Epoch 711/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4083 - acc: 0.8170 - val_loss: 0.4122 - val_acc: 0.8246\n",
      "Epoch 712/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4081 - acc: 0.8170 - val_loss: 0.4168 - val_acc: 0.8172\n",
      "Epoch 713/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4081 - acc: 0.8170 - val_loss: 0.4122 - val_acc: 0.8246\n",
      "Epoch 714/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4080 - acc: 0.8170 - val_loss: 0.4165 - val_acc: 0.8172\n",
      "Epoch 715/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4079 - acc: 0.8170 - val_loss: 0.4120 - val_acc: 0.8246\n",
      "Epoch 716/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4078 - acc: 0.8170 - val_loss: 0.4166 - val_acc: 0.8172\n",
      "Epoch 717/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4078 - acc: 0.8170 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 718/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4077 - acc: 0.8170 - val_loss: 0.4164 - val_acc: 0.8172\n",
      "Epoch 719/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4077 - acc: 0.8170 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 720/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4076 - acc: 0.8154 - val_loss: 0.4165 - val_acc: 0.8172\n",
      "Epoch 721/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4076 - acc: 0.8170 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 722/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4075 - acc: 0.8154 - val_loss: 0.4164 - val_acc: 0.8172\n",
      "Epoch 723/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4075 - acc: 0.8170 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 724/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4073 - acc: 0.8154 - val_loss: 0.4163 - val_acc: 0.8172\n",
      "Epoch 725/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4073 - acc: 0.8170 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 726/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4072 - acc: 0.8154 - val_loss: 0.4159 - val_acc: 0.8172\n",
      "Epoch 727/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4072 - acc: 0.8154 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 728/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4070 - acc: 0.8154 - val_loss: 0.4160 - val_acc: 0.8172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4070 - acc: 0.8154 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 730/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4069 - acc: 0.8154 - val_loss: 0.4159 - val_acc: 0.8172\n",
      "Epoch 731/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4069 - acc: 0.8154 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 732/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4068 - acc: 0.8154 - val_loss: 0.4159 - val_acc: 0.8172\n",
      "Epoch 733/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4068 - acc: 0.8154 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 734/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4067 - acc: 0.8154 - val_loss: 0.4158 - val_acc: 0.8172\n",
      "Epoch 735/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4067 - acc: 0.8154 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 736/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4065 - acc: 0.8154 - val_loss: 0.4159 - val_acc: 0.8172\n",
      "Epoch 737/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4066 - acc: 0.8154 - val_loss: 0.4109 - val_acc: 0.8246\n",
      "Epoch 738/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4064 - acc: 0.8154 - val_loss: 0.4156 - val_acc: 0.8172\n",
      "Epoch 739/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4064 - acc: 0.8154 - val_loss: 0.4110 - val_acc: 0.8209\n",
      "Epoch 740/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4062 - acc: 0.8154 - val_loss: 0.4154 - val_acc: 0.8172\n",
      "Epoch 741/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4062 - acc: 0.8154 - val_loss: 0.4109 - val_acc: 0.8209\n",
      "Epoch 742/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4060 - acc: 0.8154 - val_loss: 0.4155 - val_acc: 0.8172\n",
      "Epoch 743/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4061 - acc: 0.8154 - val_loss: 0.4106 - val_acc: 0.8246\n",
      "Epoch 744/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4060 - acc: 0.8154 - val_loss: 0.4154 - val_acc: 0.8172\n",
      "Epoch 745/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4060 - acc: 0.8154 - val_loss: 0.4107 - val_acc: 0.8246\n",
      "Epoch 746/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4059 - acc: 0.8154 - val_loss: 0.4155 - val_acc: 0.8172\n",
      "Epoch 747/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4059 - acc: 0.8154 - val_loss: 0.4106 - val_acc: 0.8246\n",
      "Epoch 748/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4058 - acc: 0.8154 - val_loss: 0.4154 - val_acc: 0.8172\n",
      "Epoch 749/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4058 - acc: 0.8154 - val_loss: 0.4106 - val_acc: 0.8209\n",
      "Epoch 750/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4056 - acc: 0.8154 - val_loss: 0.4151 - val_acc: 0.8172\n",
      "Epoch 751/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4056 - acc: 0.8154 - val_loss: 0.4105 - val_acc: 0.8209\n",
      "Epoch 752/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4054 - acc: 0.8154 - val_loss: 0.4151 - val_acc: 0.8172\n",
      "Epoch 753/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4055 - acc: 0.8154 - val_loss: 0.4101 - val_acc: 0.8246\n",
      "Epoch 754/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4053 - acc: 0.8154 - val_loss: 0.4149 - val_acc: 0.8172\n",
      "Epoch 755/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4053 - acc: 0.8154 - val_loss: 0.4102 - val_acc: 0.8209\n",
      "Epoch 756/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4052 - acc: 0.8154 - val_loss: 0.4147 - val_acc: 0.8172\n",
      "Epoch 757/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4053 - acc: 0.8154 - val_loss: 0.4102 - val_acc: 0.8209\n",
      "Epoch 758/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4051 - acc: 0.8170 - val_loss: 0.4151 - val_acc: 0.8172\n",
      "Epoch 759/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4052 - acc: 0.8170 - val_loss: 0.4099 - val_acc: 0.8246\n",
      "Epoch 760/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4051 - acc: 0.8170 - val_loss: 0.4148 - val_acc: 0.8172\n",
      "Epoch 761/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.4051 - acc: 0.8186 - val_loss: 0.4100 - val_acc: 0.8209\n",
      "Epoch 762/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4049 - acc: 0.8170 - val_loss: 0.4146 - val_acc: 0.8172\n",
      "Epoch 763/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4049 - acc: 0.8170 - val_loss: 0.4100 - val_acc: 0.8209\n",
      "Epoch 764/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4047 - acc: 0.8170 - val_loss: 0.4146 - val_acc: 0.8172\n",
      "Epoch 765/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4048 - acc: 0.8218 - val_loss: 0.4096 - val_acc: 0.8209\n",
      "Epoch 766/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4046 - acc: 0.8170 - val_loss: 0.4144 - val_acc: 0.8172\n",
      "Epoch 767/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4046 - acc: 0.8218 - val_loss: 0.4097 - val_acc: 0.8209\n",
      "Epoch 768/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4045 - acc: 0.8186 - val_loss: 0.4144 - val_acc: 0.8172\n",
      "Epoch 769/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4045 - acc: 0.8218 - val_loss: 0.4094 - val_acc: 0.8209\n",
      "Epoch 770/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4045 - acc: 0.8186 - val_loss: 0.4144 - val_acc: 0.8172\n",
      "Epoch 771/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4044 - acc: 0.8218 - val_loss: 0.4097 - val_acc: 0.8209\n",
      "Epoch 772/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4043 - acc: 0.8186 - val_loss: 0.4142 - val_acc: 0.8172\n",
      "Epoch 773/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4043 - acc: 0.8218 - val_loss: 0.4095 - val_acc: 0.8209\n",
      "Epoch 774/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4041 - acc: 0.8186 - val_loss: 0.4143 - val_acc: 0.8172\n",
      "Epoch 775/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4042 - acc: 0.8202 - val_loss: 0.4092 - val_acc: 0.8209\n",
      "Epoch 776/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4041 - acc: 0.8186 - val_loss: 0.4142 - val_acc: 0.8172\n",
      "Epoch 777/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4041 - acc: 0.8202 - val_loss: 0.4094 - val_acc: 0.8209\n",
      "Epoch 778/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4039 - acc: 0.8186 - val_loss: 0.4141 - val_acc: 0.8172\n",
      "Epoch 779/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4040 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8209\n",
      "Epoch 780/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4038 - acc: 0.8186 - val_loss: 0.4138 - val_acc: 0.8172\n",
      "Epoch 781/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4038 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8209\n",
      "Epoch 782/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4036 - acc: 0.8202 - val_loss: 0.4138 - val_acc: 0.8246\n",
      "Epoch 783/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4037 - acc: 0.8234 - val_loss: 0.4089 - val_acc: 0.8209\n",
      "Epoch 784/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4035 - acc: 0.8202 - val_loss: 0.4137 - val_acc: 0.8246\n",
      "Epoch 785/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4036 - acc: 0.8234 - val_loss: 0.4089 - val_acc: 0.8209\n",
      "Epoch 786/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4034 - acc: 0.8202 - val_loss: 0.4138 - val_acc: 0.8246\n",
      "Epoch 787/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4035 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8209\n",
      "Epoch 788/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4034 - acc: 0.8202 - val_loss: 0.4137 - val_acc: 0.8246\n",
      "Epoch 789/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4034 - acc: 0.8202 - val_loss: 0.4088 - val_acc: 0.8209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4033 - acc: 0.8202 - val_loss: 0.4136 - val_acc: 0.8246\n",
      "Epoch 791/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4033 - acc: 0.8202 - val_loss: 0.4084 - val_acc: 0.8209\n",
      "Epoch 792/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4032 - acc: 0.8202 - val_loss: 0.4136 - val_acc: 0.8246\n",
      "Epoch 793/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4032 - acc: 0.8202 - val_loss: 0.4087 - val_acc: 0.8209\n",
      "Epoch 794/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4030 - acc: 0.8202 - val_loss: 0.4134 - val_acc: 0.8246\n",
      "Epoch 795/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4030 - acc: 0.8170 - val_loss: 0.4084 - val_acc: 0.8209\n",
      "Epoch 796/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4029 - acc: 0.8202 - val_loss: 0.4133 - val_acc: 0.8246\n",
      "Epoch 797/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4029 - acc: 0.8170 - val_loss: 0.4085 - val_acc: 0.8209\n",
      "Epoch 798/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4027 - acc: 0.8202 - val_loss: 0.4133 - val_acc: 0.8246\n",
      "Epoch 799/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4028 - acc: 0.8170 - val_loss: 0.4081 - val_acc: 0.8209\n",
      "Epoch 800/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4027 - acc: 0.8202 - val_loss: 0.4132 - val_acc: 0.8246\n",
      "Epoch 801/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4027 - acc: 0.8170 - val_loss: 0.4083 - val_acc: 0.8209\n",
      "Epoch 802/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.4026 - acc: 0.8202 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 803/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4026 - acc: 0.8170 - val_loss: 0.4081 - val_acc: 0.8209\n",
      "Epoch 804/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4025 - acc: 0.8202 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 805/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4025 - acc: 0.8170 - val_loss: 0.4082 - val_acc: 0.8209\n",
      "Epoch 806/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4024 - acc: 0.8218 - val_loss: 0.4130 - val_acc: 0.8246\n",
      "Epoch 807/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4024 - acc: 0.8170 - val_loss: 0.4078 - val_acc: 0.8209\n",
      "Epoch 808/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4023 - acc: 0.8202 - val_loss: 0.4128 - val_acc: 0.8246\n",
      "Epoch 809/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4022 - acc: 0.8170 - val_loss: 0.4080 - val_acc: 0.8246\n",
      "Epoch 810/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4021 - acc: 0.8218 - val_loss: 0.4128 - val_acc: 0.8246\n",
      "Epoch 811/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4021 - acc: 0.8170 - val_loss: 0.4077 - val_acc: 0.8246\n",
      "Epoch 812/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4020 - acc: 0.8202 - val_loss: 0.4127 - val_acc: 0.8246\n",
      "Epoch 813/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4021 - acc: 0.8170 - val_loss: 0.4079 - val_acc: 0.8246\n",
      "Epoch 814/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4019 - acc: 0.8218 - val_loss: 0.4127 - val_acc: 0.8246\n",
      "Epoch 815/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4019 - acc: 0.8170 - val_loss: 0.4077 - val_acc: 0.8246\n",
      "Epoch 816/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4018 - acc: 0.8218 - val_loss: 0.4125 - val_acc: 0.8246\n",
      "Epoch 817/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4018 - acc: 0.8170 - val_loss: 0.4077 - val_acc: 0.8246\n",
      "Epoch 818/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4017 - acc: 0.8218 - val_loss: 0.4124 - val_acc: 0.8246\n",
      "Epoch 819/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4017 - acc: 0.8170 - val_loss: 0.4076 - val_acc: 0.8246\n",
      "Epoch 820/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4016 - acc: 0.8218 - val_loss: 0.4125 - val_acc: 0.8246\n",
      "Epoch 821/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4016 - acc: 0.8170 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 822/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4016 - acc: 0.8202 - val_loss: 0.4124 - val_acc: 0.8246\n",
      "Epoch 823/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4016 - acc: 0.8186 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 824/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4014 - acc: 0.8218 - val_loss: 0.4123 - val_acc: 0.8246\n",
      "Epoch 825/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.4014 - acc: 0.8186 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 826/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4013 - acc: 0.8218 - val_loss: 0.4121 - val_acc: 0.8246\n",
      "Epoch 827/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4013 - acc: 0.8186 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 828/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4011 - acc: 0.8218 - val_loss: 0.4122 - val_acc: 0.8246\n",
      "Epoch 829/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4012 - acc: 0.8186 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 830/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4011 - acc: 0.8218 - val_loss: 0.4120 - val_acc: 0.8246\n",
      "Epoch 831/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4011 - acc: 0.8186 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 832/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4009 - acc: 0.8218 - val_loss: 0.4120 - val_acc: 0.8246\n",
      "Epoch 833/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4010 - acc: 0.8186 - val_loss: 0.4071 - val_acc: 0.8246\n",
      "Epoch 834/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4009 - acc: 0.8218 - val_loss: 0.4119 - val_acc: 0.8246\n",
      "Epoch 835/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4009 - acc: 0.8186 - val_loss: 0.4067 - val_acc: 0.8246\n",
      "Epoch 836/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4008 - acc: 0.8218 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 837/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4008 - acc: 0.8186 - val_loss: 0.4069 - val_acc: 0.8246\n",
      "Epoch 838/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4007 - acc: 0.8218 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 839/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4007 - acc: 0.8186 - val_loss: 0.4068 - val_acc: 0.8246\n",
      "Epoch 840/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4006 - acc: 0.8218 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 841/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.4006 - acc: 0.8186 - val_loss: 0.4066 - val_acc: 0.8246\n",
      "Epoch 842/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4005 - acc: 0.8218 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 843/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4005 - acc: 0.8202 - val_loss: 0.4067 - val_acc: 0.8246\n",
      "Epoch 844/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4004 - acc: 0.8218 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 845/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4004 - acc: 0.8202 - val_loss: 0.4064 - val_acc: 0.8246\n",
      "Epoch 846/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4004 - acc: 0.8218 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 847/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.4004 - acc: 0.8202 - val_loss: 0.4065 - val_acc: 0.8246\n",
      "Epoch 848/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4002 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 849/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4001 - acc: 0.8202 - val_loss: 0.4065 - val_acc: 0.8246\n",
      "Epoch 850/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4000 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4001 - acc: 0.8202 - val_loss: 0.4062 - val_acc: 0.8246\n",
      "Epoch 852/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4000 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 853/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.4000 - acc: 0.8202 - val_loss: 0.4062 - val_acc: 0.8246\n",
      "Epoch 854/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3999 - acc: 0.8202 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 855/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.4000 - acc: 0.8202 - val_loss: 0.4062 - val_acc: 0.8246\n",
      "Epoch 856/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3999 - acc: 0.8170 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 857/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3999 - acc: 0.8202 - val_loss: 0.4062 - val_acc: 0.8246\n",
      "Epoch 858/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3998 - acc: 0.8170 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 859/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3998 - acc: 0.8202 - val_loss: 0.4059 - val_acc: 0.8284\n",
      "Epoch 860/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3997 - acc: 0.8202 - val_loss: 0.4108 - val_acc: 0.8246\n",
      "Epoch 861/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3996 - acc: 0.8234 - val_loss: 0.4061 - val_acc: 0.8284\n",
      "Epoch 862/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3995 - acc: 0.8202 - val_loss: 0.4109 - val_acc: 0.8246\n",
      "Epoch 863/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3995 - acc: 0.8234 - val_loss: 0.4057 - val_acc: 0.8284\n",
      "Epoch 864/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3995 - acc: 0.8202 - val_loss: 0.4109 - val_acc: 0.8246\n",
      "Epoch 865/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3995 - acc: 0.8234 - val_loss: 0.4059 - val_acc: 0.8321\n",
      "Epoch 866/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3994 - acc: 0.8202 - val_loss: 0.4108 - val_acc: 0.8246\n",
      "Epoch 867/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3994 - acc: 0.8234 - val_loss: 0.4058 - val_acc: 0.8358\n",
      "Epoch 868/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3992 - acc: 0.8202 - val_loss: 0.4107 - val_acc: 0.8246\n",
      "Epoch 869/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3993 - acc: 0.8234 - val_loss: 0.4058 - val_acc: 0.8358\n",
      "Epoch 870/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3992 - acc: 0.8170 - val_loss: 0.4109 - val_acc: 0.8246\n",
      "Epoch 871/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3993 - acc: 0.8250 - val_loss: 0.4056 - val_acc: 0.8358\n",
      "Epoch 872/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3991 - acc: 0.8170 - val_loss: 0.4107 - val_acc: 0.8246\n",
      "Epoch 873/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3991 - acc: 0.8234 - val_loss: 0.4057 - val_acc: 0.8358\n",
      "Epoch 874/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3990 - acc: 0.8170 - val_loss: 0.4105 - val_acc: 0.8246\n",
      "Epoch 875/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3990 - acc: 0.8234 - val_loss: 0.4053 - val_acc: 0.8358\n",
      "Epoch 876/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3989 - acc: 0.8186 - val_loss: 0.4103 - val_acc: 0.8246\n",
      "Epoch 877/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3989 - acc: 0.8234 - val_loss: 0.4055 - val_acc: 0.8358\n",
      "Epoch 878/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3988 - acc: 0.8170 - val_loss: 0.4105 - val_acc: 0.8246\n",
      "Epoch 879/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3989 - acc: 0.8250 - val_loss: 0.4053 - val_acc: 0.8358\n",
      "Epoch 880/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3988 - acc: 0.8170 - val_loss: 0.4103 - val_acc: 0.8246\n",
      "Epoch 881/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3988 - acc: 0.8250 - val_loss: 0.4053 - val_acc: 0.8358\n",
      "Epoch 882/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3987 - acc: 0.8170 - val_loss: 0.4104 - val_acc: 0.8246\n",
      "Epoch 883/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3987 - acc: 0.8250 - val_loss: 0.4051 - val_acc: 0.8358\n",
      "Epoch 884/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3986 - acc: 0.8154 - val_loss: 0.4103 - val_acc: 0.8246\n",
      "Epoch 885/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3986 - acc: 0.8250 - val_loss: 0.4053 - val_acc: 0.8358\n",
      "Epoch 886/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3985 - acc: 0.8154 - val_loss: 0.4101 - val_acc: 0.8246\n",
      "Epoch 887/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3985 - acc: 0.8250 - val_loss: 0.4051 - val_acc: 0.8358\n",
      "Epoch 888/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3983 - acc: 0.8154 - val_loss: 0.4100 - val_acc: 0.8246\n",
      "Epoch 889/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3984 - acc: 0.8250 - val_loss: 0.4049 - val_acc: 0.8358\n",
      "Epoch 890/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3983 - acc: 0.8154 - val_loss: 0.4100 - val_acc: 0.8246\n",
      "Epoch 891/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3984 - acc: 0.8266 - val_loss: 0.4050 - val_acc: 0.8358\n",
      "Epoch 892/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3983 - acc: 0.8154 - val_loss: 0.4101 - val_acc: 0.8246\n",
      "Epoch 893/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3983 - acc: 0.8266 - val_loss: 0.4050 - val_acc: 0.8358\n",
      "Epoch 894/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3982 - acc: 0.8154 - val_loss: 0.4099 - val_acc: 0.8246\n",
      "Epoch 895/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3982 - acc: 0.8266 - val_loss: 0.4049 - val_acc: 0.8358\n",
      "Epoch 896/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3980 - acc: 0.8154 - val_loss: 0.4098 - val_acc: 0.8284\n",
      "Epoch 897/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3980 - acc: 0.8266 - val_loss: 0.4047 - val_acc: 0.8358\n",
      "Epoch 898/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3980 - acc: 0.8154 - val_loss: 0.4100 - val_acc: 0.8284\n",
      "Epoch 899/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3980 - acc: 0.8266 - val_loss: 0.4049 - val_acc: 0.8358\n",
      "Epoch 900/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3979 - acc: 0.8154 - val_loss: 0.4098 - val_acc: 0.8284\n",
      "Epoch 901/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3979 - acc: 0.8266 - val_loss: 0.4048 - val_acc: 0.8358\n",
      "Epoch 902/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3978 - acc: 0.8154 - val_loss: 0.4100 - val_acc: 0.8284\n",
      "Epoch 903/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3979 - acc: 0.8250 - val_loss: 0.4046 - val_acc: 0.8358\n",
      "Epoch 904/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3978 - acc: 0.8170 - val_loss: 0.4097 - val_acc: 0.8284\n",
      "Epoch 905/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3978 - acc: 0.8250 - val_loss: 0.4046 - val_acc: 0.8358\n",
      "Epoch 906/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3977 - acc: 0.8170 - val_loss: 0.4097 - val_acc: 0.8284\n",
      "Epoch 907/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3977 - acc: 0.8250 - val_loss: 0.4046 - val_acc: 0.8358\n",
      "Epoch 908/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3975 - acc: 0.8154 - val_loss: 0.4094 - val_acc: 0.8358\n",
      "Epoch 909/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3975 - acc: 0.8266 - val_loss: 0.4045 - val_acc: 0.8358\n",
      "Epoch 910/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3974 - acc: 0.8154 - val_loss: 0.4095 - val_acc: 0.8358\n",
      "Epoch 911/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3974 - acc: 0.8266 - val_loss: 0.4042 - val_acc: 0.8358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3974 - acc: 0.8170 - val_loss: 0.4095 - val_acc: 0.8321\n",
      "Epoch 913/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3974 - acc: 0.8250 - val_loss: 0.4044 - val_acc: 0.8358\n",
      "Epoch 914/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3973 - acc: 0.8170 - val_loss: 0.4094 - val_acc: 0.8321\n",
      "Epoch 915/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3973 - acc: 0.8250 - val_loss: 0.4044 - val_acc: 0.8358\n",
      "Epoch 916/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3972 - acc: 0.8170 - val_loss: 0.4095 - val_acc: 0.8321\n",
      "Epoch 917/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3973 - acc: 0.8250 - val_loss: 0.4044 - val_acc: 0.8358\n",
      "Epoch 918/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3972 - acc: 0.8170 - val_loss: 0.4095 - val_acc: 0.8358\n",
      "Epoch 919/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3972 - acc: 0.8250 - val_loss: 0.4041 - val_acc: 0.8358\n",
      "Epoch 920/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3971 - acc: 0.8186 - val_loss: 0.4093 - val_acc: 0.8321\n",
      "Epoch 921/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3971 - acc: 0.8250 - val_loss: 0.4042 - val_acc: 0.8358\n",
      "Epoch 922/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3970 - acc: 0.8186 - val_loss: 0.4093 - val_acc: 0.8358\n",
      "Epoch 923/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3970 - acc: 0.8250 - val_loss: 0.4041 - val_acc: 0.8358\n",
      "Epoch 924/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3969 - acc: 0.8186 - val_loss: 0.4092 - val_acc: 0.8358\n",
      "Epoch 925/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3969 - acc: 0.8250 - val_loss: 0.4041 - val_acc: 0.8358\n",
      "Epoch 926/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3968 - acc: 0.8186 - val_loss: 0.4093 - val_acc: 0.8358\n",
      "Epoch 927/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3968 - acc: 0.8250 - val_loss: 0.4039 - val_acc: 0.8358\n",
      "Epoch 928/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3967 - acc: 0.8186 - val_loss: 0.4091 - val_acc: 0.8358\n",
      "Epoch 929/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3968 - acc: 0.8250 - val_loss: 0.4040 - val_acc: 0.8358\n",
      "Epoch 930/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3966 - acc: 0.8186 - val_loss: 0.4091 - val_acc: 0.8358\n",
      "Epoch 931/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3967 - acc: 0.8250 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 932/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3966 - acc: 0.8186 - val_loss: 0.4092 - val_acc: 0.8358\n",
      "Epoch 933/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3966 - acc: 0.8250 - val_loss: 0.4039 - val_acc: 0.8358\n",
      "Epoch 934/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3965 - acc: 0.8186 - val_loss: 0.4091 - val_acc: 0.8358\n",
      "Epoch 935/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3965 - acc: 0.8250 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 936/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3964 - acc: 0.8186 - val_loss: 0.4092 - val_acc: 0.8358\n",
      "Epoch 937/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3965 - acc: 0.8234 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 938/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3963 - acc: 0.8186 - val_loss: 0.4089 - val_acc: 0.8358\n",
      "Epoch 939/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3963 - acc: 0.8234 - val_loss: 0.4039 - val_acc: 0.8358\n",
      "Epoch 940/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3962 - acc: 0.8186 - val_loss: 0.4091 - val_acc: 0.8358\n",
      "Epoch 941/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3962 - acc: 0.8234 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 942/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3961 - acc: 0.8186 - val_loss: 0.4090 - val_acc: 0.8358\n",
      "Epoch 943/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3962 - acc: 0.8234 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 944/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3961 - acc: 0.8186 - val_loss: 0.4092 - val_acc: 0.8358\n",
      "Epoch 945/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3961 - acc: 0.8234 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 946/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3960 - acc: 0.8186 - val_loss: 0.4090 - val_acc: 0.8358\n",
      "Epoch 947/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3960 - acc: 0.8234 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 948/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3959 - acc: 0.8186 - val_loss: 0.4090 - val_acc: 0.8358\n",
      "Epoch 949/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3959 - acc: 0.8234 - val_loss: 0.4037 - val_acc: 0.8358\n",
      "Epoch 950/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3958 - acc: 0.8186 - val_loss: 0.4091 - val_acc: 0.8358\n",
      "Epoch 951/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3959 - acc: 0.8234 - val_loss: 0.4038 - val_acc: 0.8358\n",
      "Epoch 952/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3957 - acc: 0.8186 - val_loss: 0.4088 - val_acc: 0.8358\n",
      "Epoch 953/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3958 - acc: 0.8234 - val_loss: 0.4036 - val_acc: 0.8358\n",
      "Epoch 954/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3957 - acc: 0.8186 - val_loss: 0.4089 - val_acc: 0.8358\n",
      "Epoch 955/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3957 - acc: 0.8234 - val_loss: 0.4036 - val_acc: 0.8358\n",
      "Epoch 956/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3956 - acc: 0.8186 - val_loss: 0.4089 - val_acc: 0.8358\n",
      "Epoch 957/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3956 - acc: 0.8234 - val_loss: 0.4036 - val_acc: 0.8358\n",
      "Epoch 958/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3955 - acc: 0.8186 - val_loss: 0.4086 - val_acc: 0.8358\n",
      "Epoch 959/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3955 - acc: 0.8234 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 960/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3954 - acc: 0.8186 - val_loss: 0.4088 - val_acc: 0.8358\n",
      "Epoch 961/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3954 - acc: 0.8234 - val_loss: 0.4035 - val_acc: 0.8358\n",
      "Epoch 962/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3953 - acc: 0.8186 - val_loss: 0.4090 - val_acc: 0.8358\n",
      "Epoch 963/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3955 - acc: 0.8234 - val_loss: 0.4036 - val_acc: 0.8358\n",
      "Epoch 964/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3953 - acc: 0.8170 - val_loss: 0.4090 - val_acc: 0.8358\n",
      "Epoch 965/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3954 - acc: 0.8234 - val_loss: 0.4037 - val_acc: 0.8358\n",
      "Epoch 966/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3952 - acc: 0.8170 - val_loss: 0.4087 - val_acc: 0.8358\n",
      "Epoch 967/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3952 - acc: 0.8234 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 968/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3951 - acc: 0.8186 - val_loss: 0.4087 - val_acc: 0.8358\n",
      "Epoch 969/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3951 - acc: 0.8234 - val_loss: 0.4035 - val_acc: 0.8358\n",
      "Epoch 970/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3950 - acc: 0.8186 - val_loss: 0.4085 - val_acc: 0.8358\n",
      "Epoch 971/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3950 - acc: 0.8234 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 972/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3949 - acc: 0.8186 - val_loss: 0.4088 - val_acc: 0.8358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3950 - acc: 0.8234 - val_loss: 0.4035 - val_acc: 0.8358\n",
      "Epoch 974/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3949 - acc: 0.8170 - val_loss: 0.4087 - val_acc: 0.8358\n",
      "Epoch 975/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3949 - acc: 0.8234 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 976/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3948 - acc: 0.8170 - val_loss: 0.4088 - val_acc: 0.8358\n",
      "Epoch 977/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3949 - acc: 0.8250 - val_loss: 0.4035 - val_acc: 0.8358\n",
      "Epoch 978/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3947 - acc: 0.8170 - val_loss: 0.4086 - val_acc: 0.8358\n",
      "Epoch 979/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3947 - acc: 0.8250 - val_loss: 0.4033 - val_acc: 0.8358\n",
      "Epoch 980/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3946 - acc: 0.8186 - val_loss: 0.4087 - val_acc: 0.8358\n",
      "Epoch 981/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3947 - acc: 0.8250 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 982/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3945 - acc: 0.8186 - val_loss: 0.4086 - val_acc: 0.8358\n",
      "Epoch 983/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3946 - acc: 0.8283 - val_loss: 0.4035 - val_acc: 0.8358\n",
      "Epoch 984/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3945 - acc: 0.8170 - val_loss: 0.4087 - val_acc: 0.8358\n",
      "Epoch 985/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3945 - acc: 0.8283 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 986/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3944 - acc: 0.8154 - val_loss: 0.4085 - val_acc: 0.8358\n",
      "Epoch 987/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3944 - acc: 0.8283 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 988/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3943 - acc: 0.8170 - val_loss: 0.4085 - val_acc: 0.8358\n",
      "Epoch 989/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3943 - acc: 0.8283 - val_loss: 0.4032 - val_acc: 0.8358\n",
      "Epoch 990/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3942 - acc: 0.8186 - val_loss: 0.4087 - val_acc: 0.8358\n",
      "Epoch 991/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3943 - acc: 0.8299 - val_loss: 0.4033 - val_acc: 0.8358\n",
      "Epoch 992/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3941 - acc: 0.8186 - val_loss: 0.4085 - val_acc: 0.8358\n",
      "Epoch 993/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3942 - acc: 0.8299 - val_loss: 0.4034 - val_acc: 0.8358\n",
      "Epoch 994/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3940 - acc: 0.8186 - val_loss: 0.4085 - val_acc: 0.8358\n",
      "Epoch 995/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3941 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8358\n",
      "Epoch 996/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3940 - acc: 0.8186 - val_loss: 0.4084 - val_acc: 0.8358\n",
      "Epoch 997/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3940 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 998/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3938 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8358\n",
      "Epoch 999/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3939 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8358\n",
      "Epoch 1000/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3938 - acc: 0.8186 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1001/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3938 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1002/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3937 - acc: 0.8186 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1003/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3938 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 1004/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3937 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1005/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3937 - acc: 0.8299 - val_loss: 0.4033 - val_acc: 0.8358\n",
      "Epoch 1006/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3936 - acc: 0.8186 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1007/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3936 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 1008/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3934 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1009/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3935 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1010/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3934 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1011/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3934 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1012/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3933 - acc: 0.8186 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1013/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3934 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1014/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3932 - acc: 0.8186 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1015/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3934 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 1016/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3932 - acc: 0.8186 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1017/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3933 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1018/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3931 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1019/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3931 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1020/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3930 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1021/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3930 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1022/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3929 - acc: 0.8186 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1023/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3930 - acc: 0.8283 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1024/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3929 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1025/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3929 - acc: 0.8283 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1026/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3928 - acc: 0.8186 - val_loss: 0.4081 - val_acc: 0.8321\n",
      "Epoch 1027/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3928 - acc: 0.8283 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1028/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3927 - acc: 0.8186 - val_loss: 0.4081 - val_acc: 0.8321\n",
      "Epoch 1029/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3928 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1030/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3926 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1031/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3927 - acc: 0.8283 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1032/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3926 - acc: 0.8186 - val_loss: 0.4086 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1033/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3927 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1034/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3925 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1035/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3926 - acc: 0.8283 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1036/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3924 - acc: 0.8186 - val_loss: 0.4085 - val_acc: 0.8321\n",
      "Epoch 1037/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3925 - acc: 0.8283 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 1038/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3924 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1039/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3924 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1040/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3923 - acc: 0.8186 - val_loss: 0.4081 - val_acc: 0.8321\n",
      "Epoch 1041/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3923 - acc: 0.8283 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1042/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3922 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1043/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3923 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1044/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3922 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1045/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3922 - acc: 0.8283 - val_loss: 0.4027 - val_acc: 0.8358\n",
      "Epoch 1046/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3921 - acc: 0.8186 - val_loss: 0.4085 - val_acc: 0.8321\n",
      "Epoch 1047/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3922 - acc: 0.8283 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 1048/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3920 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1049/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3921 - acc: 0.8283 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1050/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3919 - acc: 0.8186 - val_loss: 0.4081 - val_acc: 0.8321\n",
      "Epoch 1051/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3920 - acc: 0.8283 - val_loss: 0.4027 - val_acc: 0.8358\n",
      "Epoch 1052/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3919 - acc: 0.8186 - val_loss: 0.4081 - val_acc: 0.8321\n",
      "Epoch 1053/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3919 - acc: 0.8283 - val_loss: 0.4027 - val_acc: 0.8358\n",
      "Epoch 1054/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3918 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1055/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3919 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1056/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3918 - acc: 0.8186 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1057/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3918 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1058/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3917 - acc: 0.8186 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1059/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3917 - acc: 0.8283 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1060/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3916 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1061/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3917 - acc: 0.8283 - val_loss: 0.4031 - val_acc: 0.8358\n",
      "Epoch 1062/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3915 - acc: 0.8202 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1063/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3916 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1064/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3915 - acc: 0.8202 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1065/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3915 - acc: 0.8283 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1066/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3914 - acc: 0.8202 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1067/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3914 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1068/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3913 - acc: 0.8218 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1069/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3914 - acc: 0.8283 - val_loss: 0.4030 - val_acc: 0.8358\n",
      "Epoch 1070/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3913 - acc: 0.8218 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1071/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3913 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1072/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3912 - acc: 0.8218 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1073/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3912 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1074/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3911 - acc: 0.8218 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1075/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3912 - acc: 0.8283 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1076/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3910 - acc: 0.8218 - val_loss: 0.4082 - val_acc: 0.8321\n",
      "Epoch 1077/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3911 - acc: 0.8283 - val_loss: 0.4027 - val_acc: 0.8358\n",
      "Epoch 1078/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3910 - acc: 0.8218 - val_loss: 0.4087 - val_acc: 0.8321\n",
      "Epoch 1079/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3911 - acc: 0.8283 - val_loss: 0.4032 - val_acc: 0.8358\n",
      "Epoch 1080/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3909 - acc: 0.8218 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1081/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3910 - acc: 0.8299 - val_loss: 0.4028 - val_acc: 0.8358\n",
      "Epoch 1082/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3908 - acc: 0.8218 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1083/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3909 - acc: 0.8299 - val_loss: 0.4029 - val_acc: 0.8358\n",
      "Epoch 1084/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3907 - acc: 0.8218 - val_loss: 0.4083 - val_acc: 0.8321\n",
      "Epoch 1085/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3908 - acc: 0.8299 - val_loss: 0.4028 - val_acc: 0.8321\n",
      "Epoch 1086/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3907 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1087/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3907 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8321\n",
      "Epoch 1088/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3906 - acc: 0.8202 - val_loss: 0.4084 - val_acc: 0.8321\n",
      "Epoch 1089/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3906 - acc: 0.8299 - val_loss: 0.4029 - val_acc: 0.8321\n",
      "Epoch 1090/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3905 - acc: 0.8202 - val_loss: 0.4087 - val_acc: 0.8321\n",
      "Epoch 1091/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3906 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8321\n",
      "Epoch 1092/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3905 - acc: 0.8202 - val_loss: 0.4084 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1093/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3905 - acc: 0.8299 - val_loss: 0.4029 - val_acc: 0.8321\n",
      "Epoch 1094/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3904 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8321\n",
      "Epoch 1095/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3905 - acc: 0.8299 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1096/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3904 - acc: 0.8202 - val_loss: 0.4087 - val_acc: 0.8321\n",
      "Epoch 1097/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3904 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8321\n",
      "Epoch 1098/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3903 - acc: 0.8202 - val_loss: 0.4085 - val_acc: 0.8321\n",
      "Epoch 1099/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3903 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8321\n",
      "Epoch 1100/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3902 - acc: 0.8202 - val_loss: 0.4088 - val_acc: 0.8321\n",
      "Epoch 1101/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3903 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8321\n",
      "Epoch 1102/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3901 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1103/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3902 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8321\n",
      "Epoch 1104/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3901 - acc: 0.8202 - val_loss: 0.4088 - val_acc: 0.8321\n",
      "Epoch 1105/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3902 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8321\n",
      "Epoch 1106/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3901 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1107/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3901 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8321\n",
      "Epoch 1108/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3900 - acc: 0.8202 - val_loss: 0.4085 - val_acc: 0.8321\n",
      "Epoch 1109/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3900 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8321\n",
      "Epoch 1110/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3899 - acc: 0.8202 - val_loss: 0.4088 - val_acc: 0.8321\n",
      "Epoch 1111/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3899 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8321\n",
      "Epoch 1112/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3898 - acc: 0.8202 - val_loss: 0.4085 - val_acc: 0.8321\n",
      "Epoch 1113/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3898 - acc: 0.8299 - val_loss: 0.4030 - val_acc: 0.8321\n",
      "Epoch 1114/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3898 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1115/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3899 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8321\n",
      "Epoch 1116/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3898 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1117/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3898 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8321\n",
      "Epoch 1118/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3897 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1119/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3897 - acc: 0.8299 - val_loss: 0.4031 - val_acc: 0.8321\n",
      "Epoch 1120/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3896 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1121/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3897 - acc: 0.8283 - val_loss: 0.4033 - val_acc: 0.8321\n",
      "Epoch 1122/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3896 - acc: 0.8202 - val_loss: 0.4087 - val_acc: 0.8321\n",
      "Epoch 1123/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3896 - acc: 0.8283 - val_loss: 0.4032 - val_acc: 0.8321\n",
      "Epoch 1124/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3895 - acc: 0.8202 - val_loss: 0.4086 - val_acc: 0.8321\n",
      "Epoch 1125/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3895 - acc: 0.8283 - val_loss: 0.4031 - val_acc: 0.8321\n",
      "Epoch 1126/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3894 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1127/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3895 - acc: 0.8283 - val_loss: 0.4032 - val_acc: 0.8321\n",
      "Epoch 1128/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3894 - acc: 0.8202 - val_loss: 0.4091 - val_acc: 0.8321\n",
      "Epoch 1129/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3894 - acc: 0.8283 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1130/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3893 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1131/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3893 - acc: 0.8283 - val_loss: 0.4033 - val_acc: 0.8321\n",
      "Epoch 1132/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3892 - acc: 0.8202 - val_loss: 0.4091 - val_acc: 0.8321\n",
      "Epoch 1133/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3893 - acc: 0.8283 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1134/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3892 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1135/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3893 - acc: 0.8283 - val_loss: 0.4035 - val_acc: 0.8321\n",
      "Epoch 1136/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3891 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1137/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3892 - acc: 0.8283 - val_loss: 0.4033 - val_acc: 0.8321\n",
      "Epoch 1138/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3891 - acc: 0.8202 - val_loss: 0.4092 - val_acc: 0.8321\n",
      "Epoch 1139/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3891 - acc: 0.8299 - val_loss: 0.4035 - val_acc: 0.8321\n",
      "Epoch 1140/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3890 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1141/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3890 - acc: 0.8299 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1142/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3890 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8321\n",
      "Epoch 1143/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3890 - acc: 0.8315 - val_loss: 0.4033 - val_acc: 0.8321\n",
      "Epoch 1144/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3889 - acc: 0.8202 - val_loss: 0.4094 - val_acc: 0.8321\n",
      "Epoch 1145/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3890 - acc: 0.8315 - val_loss: 0.4036 - val_acc: 0.8321\n",
      "Epoch 1146/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3888 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8321\n",
      "Epoch 1147/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3889 - acc: 0.8315 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1148/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3888 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8321\n",
      "Epoch 1149/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3889 - acc: 0.8315 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1150/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3888 - acc: 0.8202 - val_loss: 0.4094 - val_acc: 0.8321\n",
      "Epoch 1151/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3888 - acc: 0.8315 - val_loss: 0.4036 - val_acc: 0.8321\n",
      "Epoch 1152/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3887 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1153/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3887 - acc: 0.8315 - val_loss: 0.4035 - val_acc: 0.8321\n",
      "Epoch 1154/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3886 - acc: 0.8202 - val_loss: 0.4093 - val_acc: 0.8321\n",
      "Epoch 1155/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3887 - acc: 0.8315 - val_loss: 0.4035 - val_acc: 0.8321\n",
      "Epoch 1156/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3886 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8321\n",
      "Epoch 1157/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3886 - acc: 0.8315 - val_loss: 0.4034 - val_acc: 0.8321\n",
      "Epoch 1158/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3885 - acc: 0.8202 - val_loss: 0.4093 - val_acc: 0.8321\n",
      "Epoch 1159/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3886 - acc: 0.8315 - val_loss: 0.4037 - val_acc: 0.8321\n",
      "Epoch 1160/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3885 - acc: 0.8202 - val_loss: 0.4090 - val_acc: 0.8321\n",
      "Epoch 1161/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3885 - acc: 0.8315 - val_loss: 0.4036 - val_acc: 0.8321\n",
      "Epoch 1162/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3884 - acc: 0.8202 - val_loss: 0.4091 - val_acc: 0.8321\n",
      "Epoch 1163/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3884 - acc: 0.8315 - val_loss: 0.4036 - val_acc: 0.8321\n",
      "Epoch 1164/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3883 - acc: 0.8218 - val_loss: 0.4097 - val_acc: 0.8321\n",
      "Epoch 1165/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3883 - acc: 0.8315 - val_loss: 0.4039 - val_acc: 0.8321\n",
      "Epoch 1166/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3882 - acc: 0.8218 - val_loss: 0.4095 - val_acc: 0.8321\n",
      "Epoch 1167/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3882 - acc: 0.8315 - val_loss: 0.4039 - val_acc: 0.8321\n",
      "Epoch 1168/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3880 - acc: 0.8218 - val_loss: 0.4095 - val_acc: 0.8321\n",
      "Epoch 1169/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3881 - acc: 0.8315 - val_loss: 0.4039 - val_acc: 0.8321\n",
      "Epoch 1170/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3879 - acc: 0.8218 - val_loss: 0.4096 - val_acc: 0.8284\n",
      "Epoch 1171/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3880 - acc: 0.8315 - val_loss: 0.4040 - val_acc: 0.8321\n",
      "Epoch 1172/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3878 - acc: 0.8218 - val_loss: 0.4098 - val_acc: 0.8284\n",
      "Epoch 1173/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3879 - acc: 0.8315 - val_loss: 0.4038 - val_acc: 0.8321\n",
      "Epoch 1174/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3878 - acc: 0.8218 - val_loss: 0.4098 - val_acc: 0.8284\n",
      "Epoch 1175/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3879 - acc: 0.8315 - val_loss: 0.4041 - val_acc: 0.8321\n",
      "Epoch 1176/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3877 - acc: 0.8218 - val_loss: 0.4100 - val_acc: 0.8284\n",
      "Epoch 1177/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3878 - acc: 0.8315 - val_loss: 0.4042 - val_acc: 0.8321\n",
      "Epoch 1178/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3876 - acc: 0.8218 - val_loss: 0.4101 - val_acc: 0.8284\n",
      "Epoch 1179/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3877 - acc: 0.8315 - val_loss: 0.4040 - val_acc: 0.8321\n",
      "Epoch 1180/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3875 - acc: 0.8218 - val_loss: 0.4099 - val_acc: 0.8284\n",
      "Epoch 1181/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3876 - acc: 0.8315 - val_loss: 0.4043 - val_acc: 0.8321\n",
      "Epoch 1182/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3874 - acc: 0.8218 - val_loss: 0.4098 - val_acc: 0.8284\n",
      "Epoch 1183/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3875 - acc: 0.8315 - val_loss: 0.4043 - val_acc: 0.8321\n",
      "Epoch 1184/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3873 - acc: 0.8218 - val_loss: 0.4101 - val_acc: 0.8284\n",
      "Epoch 1185/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3874 - acc: 0.8315 - val_loss: 0.4042 - val_acc: 0.8321\n",
      "Epoch 1186/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3873 - acc: 0.8218 - val_loss: 0.4101 - val_acc: 0.8284\n",
      "Epoch 1187/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3873 - acc: 0.8315 - val_loss: 0.4045 - val_acc: 0.8321\n",
      "Epoch 1188/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3872 - acc: 0.8218 - val_loss: 0.4102 - val_acc: 0.8284\n",
      "Epoch 1189/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3873 - acc: 0.8315 - val_loss: 0.4045 - val_acc: 0.8321\n",
      "Epoch 1190/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3872 - acc: 0.8218 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1191/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3873 - acc: 0.8315 - val_loss: 0.4044 - val_acc: 0.8321\n",
      "Epoch 1192/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3871 - acc: 0.8218 - val_loss: 0.4104 - val_acc: 0.8321\n",
      "Epoch 1193/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3872 - acc: 0.8347 - val_loss: 0.4044 - val_acc: 0.8321\n",
      "Epoch 1194/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3870 - acc: 0.8218 - val_loss: 0.4103 - val_acc: 0.8284\n",
      "Epoch 1195/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3871 - acc: 0.8315 - val_loss: 0.4044 - val_acc: 0.8321\n",
      "Epoch 1196/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3869 - acc: 0.8218 - val_loss: 0.4104 - val_acc: 0.8284\n",
      "Epoch 1197/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3870 - acc: 0.8315 - val_loss: 0.4048 - val_acc: 0.8321\n",
      "Epoch 1198/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3869 - acc: 0.8218 - val_loss: 0.4103 - val_acc: 0.8284\n",
      "Epoch 1199/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3869 - acc: 0.8315 - val_loss: 0.4047 - val_acc: 0.8321\n",
      "Epoch 1200/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3868 - acc: 0.8218 - val_loss: 0.4104 - val_acc: 0.8321\n",
      "Epoch 1201/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3869 - acc: 0.8347 - val_loss: 0.4049 - val_acc: 0.8284\n",
      "Epoch 1202/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3868 - acc: 0.8218 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1203/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3868 - acc: 0.8315 - val_loss: 0.4049 - val_acc: 0.8284\n",
      "Epoch 1204/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3867 - acc: 0.8218 - val_loss: 0.4105 - val_acc: 0.8321\n",
      "Epoch 1205/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3868 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1206/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3867 - acc: 0.8218 - val_loss: 0.4110 - val_acc: 0.8321\n",
      "Epoch 1207/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3867 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1208/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3866 - acc: 0.8202 - val_loss: 0.4109 - val_acc: 0.8321\n",
      "Epoch 1209/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3867 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1210/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3865 - acc: 0.8202 - val_loss: 0.4109 - val_acc: 0.8321\n",
      "Epoch 1211/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3866 - acc: 0.8347 - val_loss: 0.4048 - val_acc: 0.8284\n",
      "Epoch 1212/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3865 - acc: 0.8202 - val_loss: 0.4111 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1213/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3865 - acc: 0.8347 - val_loss: 0.4051 - val_acc: 0.8284\n",
      "Epoch 1214/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3864 - acc: 0.8202 - val_loss: 0.4112 - val_acc: 0.8321\n",
      "Epoch 1215/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3865 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1216/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3863 - acc: 0.8202 - val_loss: 0.4112 - val_acc: 0.8321\n",
      "Epoch 1217/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3864 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1218/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3863 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1219/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3864 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1220/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3862 - acc: 0.8202 - val_loss: 0.4109 - val_acc: 0.8321\n",
      "Epoch 1221/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3863 - acc: 0.8347 - val_loss: 0.4054 - val_acc: 0.8284\n",
      "Epoch 1222/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3861 - acc: 0.8202 - val_loss: 0.4110 - val_acc: 0.8321\n",
      "Epoch 1223/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3862 - acc: 0.8347 - val_loss: 0.4051 - val_acc: 0.8284\n",
      "Epoch 1224/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3860 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1225/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3861 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1226/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3860 - acc: 0.8202 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1227/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3861 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1228/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3860 - acc: 0.8202 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1229/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3861 - acc: 0.8347 - val_loss: 0.4054 - val_acc: 0.8284\n",
      "Epoch 1230/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3859 - acc: 0.8202 - val_loss: 0.4111 - val_acc: 0.8321\n",
      "Epoch 1231/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3860 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8284\n",
      "Epoch 1232/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3859 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1233/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3859 - acc: 0.8347 - val_loss: 0.4054 - val_acc: 0.8284\n",
      "Epoch 1234/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3858 - acc: 0.8202 - val_loss: 0.4111 - val_acc: 0.8321\n",
      "Epoch 1235/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3859 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8284\n",
      "Epoch 1236/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3858 - acc: 0.8202 - val_loss: 0.4112 - val_acc: 0.8321\n",
      "Epoch 1237/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3858 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1238/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3857 - acc: 0.8202 - val_loss: 0.4115 - val_acc: 0.8321\n",
      "Epoch 1239/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3858 - acc: 0.8347 - val_loss: 0.4054 - val_acc: 0.8284\n",
      "Epoch 1240/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3857 - acc: 0.8202 - val_loss: 0.4111 - val_acc: 0.8321\n",
      "Epoch 1241/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3858 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1242/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3856 - acc: 0.8202 - val_loss: 0.4110 - val_acc: 0.8321\n",
      "Epoch 1243/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3857 - acc: 0.8347 - val_loss: 0.4055 - val_acc: 0.8284\n",
      "Epoch 1244/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3856 - acc: 0.8202 - val_loss: 0.4111 - val_acc: 0.8321\n",
      "Epoch 1245/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3857 - acc: 0.8347 - val_loss: 0.4055 - val_acc: 0.8284\n",
      "Epoch 1246/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3855 - acc: 0.8202 - val_loss: 0.4116 - val_acc: 0.8321\n",
      "Epoch 1247/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3856 - acc: 0.8347 - val_loss: 0.4055 - val_acc: 0.8284\n",
      "Epoch 1248/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3855 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1249/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3856 - acc: 0.8347 - val_loss: 0.4054 - val_acc: 0.8284\n",
      "Epoch 1250/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3855 - acc: 0.8202 - val_loss: 0.4116 - val_acc: 0.8321\n",
      "Epoch 1251/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3856 - acc: 0.8347 - val_loss: 0.4054 - val_acc: 0.8284\n",
      "Epoch 1252/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3854 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1253/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3855 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1254/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3854 - acc: 0.8202 - val_loss: 0.4112 - val_acc: 0.8321\n",
      "Epoch 1255/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3855 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8284\n",
      "Epoch 1256/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3854 - acc: 0.8186 - val_loss: 0.4112 - val_acc: 0.8321\n",
      "Epoch 1257/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3854 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1258/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3853 - acc: 0.8186 - val_loss: 0.4112 - val_acc: 0.8321\n",
      "Epoch 1259/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3853 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1260/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3852 - acc: 0.8186 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1261/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3853 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1262/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3852 - acc: 0.8186 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1263/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3853 - acc: 0.8347 - val_loss: 0.4052 - val_acc: 0.8284\n",
      "Epoch 1264/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3852 - acc: 0.8186 - val_loss: 0.4111 - val_acc: 0.8321\n",
      "Epoch 1265/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3853 - acc: 0.8347 - val_loss: 0.4057 - val_acc: 0.8284\n",
      "Epoch 1266/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3852 - acc: 0.8186 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1267/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3852 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1268/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3851 - acc: 0.8186 - val_loss: 0.4116 - val_acc: 0.8321\n",
      "Epoch 1269/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3852 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8284\n",
      "Epoch 1270/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3850 - acc: 0.8186 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1271/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3851 - acc: 0.8347 - val_loss: 0.4058 - val_acc: 0.8284\n",
      "Epoch 1272/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3850 - acc: 0.8186 - val_loss: 0.4112 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1273/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3850 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8284\n",
      "Epoch 1274/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3849 - acc: 0.8186 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1275/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3850 - acc: 0.8347 - val_loss: 0.4055 - val_acc: 0.8284\n",
      "Epoch 1276/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3850 - acc: 0.8186 - val_loss: 0.4113 - val_acc: 0.8321\n",
      "Epoch 1277/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3850 - acc: 0.8347 - val_loss: 0.4053 - val_acc: 0.8246\n",
      "Epoch 1278/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3849 - acc: 0.8186 - val_loss: 0.4122 - val_acc: 0.8321\n",
      "Epoch 1279/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3851 - acc: 0.8347 - val_loss: 0.4061 - val_acc: 0.8284\n",
      "Epoch 1280/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3849 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8321\n",
      "Epoch 1281/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3850 - acc: 0.8347 - val_loss: 0.4057 - val_acc: 0.8246\n",
      "Epoch 1282/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3848 - acc: 0.8186 - val_loss: 0.4115 - val_acc: 0.8321\n",
      "Epoch 1283/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3849 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8246\n",
      "Epoch 1284/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3848 - acc: 0.8186 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1285/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3849 - acc: 0.8347 - val_loss: 0.4058 - val_acc: 0.8246\n",
      "Epoch 1286/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3847 - acc: 0.8186 - val_loss: 0.4116 - val_acc: 0.8321\n",
      "Epoch 1287/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3848 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8246\n",
      "Epoch 1288/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3847 - acc: 0.8186 - val_loss: 0.4122 - val_acc: 0.8321\n",
      "Epoch 1289/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3849 - acc: 0.8347 - val_loss: 0.4060 - val_acc: 0.8246\n",
      "Epoch 1290/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3847 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8321\n",
      "Epoch 1291/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3848 - acc: 0.8347 - val_loss: 0.4057 - val_acc: 0.8246\n",
      "Epoch 1292/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3847 - acc: 0.8186 - val_loss: 0.4114 - val_acc: 0.8321\n",
      "Epoch 1293/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3847 - acc: 0.8347 - val_loss: 0.4059 - val_acc: 0.8246\n",
      "Epoch 1294/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3846 - acc: 0.8186 - val_loss: 0.4115 - val_acc: 0.8321\n",
      "Epoch 1295/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3847 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8246\n",
      "Epoch 1296/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3846 - acc: 0.8186 - val_loss: 0.4119 - val_acc: 0.8321\n",
      "Epoch 1297/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3847 - acc: 0.8347 - val_loss: 0.4059 - val_acc: 0.8246\n",
      "Epoch 1298/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3846 - acc: 0.8186 - val_loss: 0.4116 - val_acc: 0.8321\n",
      "Epoch 1299/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3846 - acc: 0.8347 - val_loss: 0.4059 - val_acc: 0.8246\n",
      "Epoch 1300/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3845 - acc: 0.8186 - val_loss: 0.4116 - val_acc: 0.8321\n",
      "Epoch 1301/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3846 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8246\n",
      "Epoch 1302/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3844 - acc: 0.8186 - val_loss: 0.4120 - val_acc: 0.8321\n",
      "Epoch 1303/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3846 - acc: 0.8347 - val_loss: 0.4059 - val_acc: 0.8246\n",
      "Epoch 1304/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3844 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8321\n",
      "Epoch 1305/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3845 - acc: 0.8347 - val_loss: 0.4060 - val_acc: 0.8246\n",
      "Epoch 1306/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3844 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8321\n",
      "Epoch 1307/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3845 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8246\n",
      "Epoch 1308/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3843 - acc: 0.8186 - val_loss: 0.4122 - val_acc: 0.8321\n",
      "Epoch 1309/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3845 - acc: 0.8347 - val_loss: 0.4061 - val_acc: 0.8246\n",
      "Epoch 1310/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3843 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8284\n",
      "Epoch 1311/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3844 - acc: 0.8347 - val_loss: 0.4057 - val_acc: 0.8246\n",
      "Epoch 1312/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3842 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8321\n",
      "Epoch 1313/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3843 - acc: 0.8347 - val_loss: 0.4061 - val_acc: 0.8246\n",
      "Epoch 1314/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3843 - acc: 0.8186 - val_loss: 0.4118 - val_acc: 0.8321\n",
      "Epoch 1315/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3844 - acc: 0.8347 - val_loss: 0.4057 - val_acc: 0.8246\n",
      "Epoch 1316/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3842 - acc: 0.8186 - val_loss: 0.4122 - val_acc: 0.8321\n",
      "Epoch 1317/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3844 - acc: 0.8347 - val_loss: 0.4060 - val_acc: 0.8246\n",
      "Epoch 1318/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3842 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8321\n",
      "Epoch 1319/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3843 - acc: 0.8347 - val_loss: 0.4061 - val_acc: 0.8246\n",
      "Epoch 1320/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3842 - acc: 0.8186 - val_loss: 0.4117 - val_acc: 0.8284\n",
      "Epoch 1321/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3842 - acc: 0.8347 - val_loss: 0.4056 - val_acc: 0.8246\n",
      "Epoch 1322/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3840 - acc: 0.8186 - val_loss: 0.4124 - val_acc: 0.8284\n",
      "Epoch 1323/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3842 - acc: 0.8347 - val_loss: 0.4064 - val_acc: 0.8246\n",
      "Epoch 1324/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3840 - acc: 0.8186 - val_loss: 0.4119 - val_acc: 0.8284\n",
      "Epoch 1325/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3841 - acc: 0.8347 - val_loss: 0.4059 - val_acc: 0.8246\n",
      "Epoch 1326/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3841 - acc: 0.8186 - val_loss: 0.4119 - val_acc: 0.8284\n",
      "Epoch 1327/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3842 - acc: 0.8347 - val_loss: 0.4058 - val_acc: 0.8246\n",
      "Epoch 1328/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3840 - acc: 0.8186 - val_loss: 0.4126 - val_acc: 0.8284\n",
      "Epoch 1329/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3841 - acc: 0.8347 - val_loss: 0.4064 - val_acc: 0.8246\n",
      "Epoch 1330/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3839 - acc: 0.8186 - val_loss: 0.4120 - val_acc: 0.8284\n",
      "Epoch 1331/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3840 - acc: 0.8347 - val_loss: 0.4063 - val_acc: 0.8246\n",
      "Epoch 1332/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3836 - acc: 0.8186 - val_loss: 0.4129 - val_acc: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1333/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3839 - acc: 0.8347 - val_loss: 0.4071 - val_acc: 0.8246\n",
      "Epoch 1334/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3838 - acc: 0.8186 - val_loss: 0.4133 - val_acc: 0.8284\n",
      "Epoch 1335/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3839 - acc: 0.8379 - val_loss: 0.4067 - val_acc: 0.8246\n",
      "Epoch 1336/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3835 - acc: 0.8186 - val_loss: 0.4126 - val_acc: 0.8284\n",
      "Epoch 1337/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3834 - acc: 0.8347 - val_loss: 0.4063 - val_acc: 0.8246\n",
      "Epoch 1338/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3831 - acc: 0.8186 - val_loss: 0.4120 - val_acc: 0.8284\n",
      "Epoch 1339/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3831 - acc: 0.8347 - val_loss: 0.4062 - val_acc: 0.8284\n",
      "Epoch 1340/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3829 - acc: 0.8186 - val_loss: 0.4125 - val_acc: 0.8284\n",
      "Epoch 1341/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3830 - acc: 0.8347 - val_loss: 0.4067 - val_acc: 0.8284\n",
      "Epoch 1342/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3829 - acc: 0.8186 - val_loss: 0.4123 - val_acc: 0.8284\n",
      "Epoch 1343/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3831 - acc: 0.8347 - val_loss: 0.4064 - val_acc: 0.8246\n",
      "Epoch 1344/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3832 - acc: 0.8186 - val_loss: 0.4127 - val_acc: 0.8284\n",
      "Epoch 1345/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3834 - acc: 0.8347 - val_loss: 0.4063 - val_acc: 0.8246\n",
      "Epoch 1346/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3833 - acc: 0.8186 - val_loss: 0.4132 - val_acc: 0.8284\n",
      "Epoch 1347/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3834 - acc: 0.8347 - val_loss: 0.4066 - val_acc: 0.8246\n",
      "Epoch 1348/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3834 - acc: 0.8186 - val_loss: 0.4127 - val_acc: 0.8284\n",
      "Epoch 1349/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3833 - acc: 0.8347 - val_loss: 0.4065 - val_acc: 0.8246\n",
      "Epoch 1350/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3830 - acc: 0.8186 - val_loss: 0.4122 - val_acc: 0.8246\n",
      "Epoch 1351/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3830 - acc: 0.8347 - val_loss: 0.4063 - val_acc: 0.8246\n",
      "Epoch 1352/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3828 - acc: 0.8186 - val_loss: 0.4126 - val_acc: 0.8284\n",
      "Epoch 1353/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3828 - acc: 0.8347 - val_loss: 0.4067 - val_acc: 0.8246\n",
      "Epoch 1354/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3829 - acc: 0.8186 - val_loss: 0.4126 - val_acc: 0.8246\n",
      "Epoch 1355/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3829 - acc: 0.8379 - val_loss: 0.4066 - val_acc: 0.8246\n",
      "Epoch 1356/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3829 - acc: 0.8186 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1357/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3830 - acc: 0.8395 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 1358/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3830 - acc: 0.8170 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1359/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3831 - acc: 0.8395 - val_loss: 0.4068 - val_acc: 0.8246\n",
      "Epoch 1360/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3831 - acc: 0.8170 - val_loss: 0.4137 - val_acc: 0.8246\n",
      "Epoch 1361/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3831 - acc: 0.8395 - val_loss: 0.4073 - val_acc: 0.8246\n",
      "Epoch 1362/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3828 - acc: 0.8170 - val_loss: 0.4128 - val_acc: 0.8246\n",
      "Epoch 1363/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3827 - acc: 0.8379 - val_loss: 0.4068 - val_acc: 0.8246\n",
      "Epoch 1364/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3825 - acc: 0.8202 - val_loss: 0.4123 - val_acc: 0.8284\n",
      "Epoch 1365/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3825 - acc: 0.8363 - val_loss: 0.4066 - val_acc: 0.8246\n",
      "Epoch 1366/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3825 - acc: 0.8202 - val_loss: 0.4129 - val_acc: 0.8284\n",
      "Epoch 1367/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3826 - acc: 0.8379 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 1368/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3825 - acc: 0.8186 - val_loss: 0.4129 - val_acc: 0.8246\n",
      "Epoch 1369/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3827 - acc: 0.8379 - val_loss: 0.4069 - val_acc: 0.8246\n",
      "Epoch 1370/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3827 - acc: 0.8170 - val_loss: 0.4134 - val_acc: 0.8246\n",
      "Epoch 1371/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3828 - acc: 0.8395 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 1372/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3827 - acc: 0.8186 - val_loss: 0.4130 - val_acc: 0.8246\n",
      "Epoch 1373/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3827 - acc: 0.8395 - val_loss: 0.4068 - val_acc: 0.8246\n",
      "Epoch 1374/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3825 - acc: 0.8186 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1375/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3825 - acc: 0.8379 - val_loss: 0.4069 - val_acc: 0.8246\n",
      "Epoch 1376/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3823 - acc: 0.8186 - val_loss: 0.4126 - val_acc: 0.8284\n",
      "Epoch 1377/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3823 - acc: 0.8379 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 1378/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3823 - acc: 0.8186 - val_loss: 0.4132 - val_acc: 0.8246\n",
      "Epoch 1379/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3825 - acc: 0.8379 - val_loss: 0.4071 - val_acc: 0.8246\n",
      "Epoch 1380/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3823 - acc: 0.8186 - val_loss: 0.4127 - val_acc: 0.8246\n",
      "Epoch 1381/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3824 - acc: 0.8379 - val_loss: 0.4069 - val_acc: 0.8246\n",
      "Epoch 1382/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3824 - acc: 0.8202 - val_loss: 0.4132 - val_acc: 0.8246\n",
      "Epoch 1383/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3825 - acc: 0.8379 - val_loss: 0.4071 - val_acc: 0.8246\n",
      "Epoch 1384/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3823 - acc: 0.8202 - val_loss: 0.4135 - val_acc: 0.8246\n",
      "Epoch 1385/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3824 - acc: 0.8379 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1386/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3824 - acc: 0.8202 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1387/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3824 - acc: 0.8379 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 1388/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3822 - acc: 0.8186 - val_loss: 0.4133 - val_acc: 0.8246\n",
      "Epoch 1389/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3822 - acc: 0.8379 - val_loss: 0.4073 - val_acc: 0.8246\n",
      "Epoch 1390/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3821 - acc: 0.8202 - val_loss: 0.4129 - val_acc: 0.8246\n",
      "Epoch 1391/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3821 - acc: 0.8379 - val_loss: 0.4071 - val_acc: 0.8246\n",
      "Epoch 1392/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3820 - acc: 0.8186 - val_loss: 0.4133 - val_acc: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1393/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3821 - acc: 0.8379 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1394/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3821 - acc: 0.8202 - val_loss: 0.4132 - val_acc: 0.8246\n",
      "Epoch 1395/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3822 - acc: 0.8395 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 1396/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3822 - acc: 0.8202 - val_loss: 0.4136 - val_acc: 0.8246\n",
      "Epoch 1397/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3822 - acc: 0.8395 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1398/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3820 - acc: 0.8202 - val_loss: 0.4130 - val_acc: 0.8246\n",
      "Epoch 1399/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3820 - acc: 0.8379 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 1400/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3820 - acc: 0.8202 - val_loss: 0.4133 - val_acc: 0.8246\n",
      "Epoch 1401/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3820 - acc: 0.8379 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1402/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3819 - acc: 0.8202 - val_loss: 0.4129 - val_acc: 0.8246\n",
      "Epoch 1403/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3819 - acc: 0.8379 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 1404/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3819 - acc: 0.8202 - val_loss: 0.4136 - val_acc: 0.8246\n",
      "Epoch 1405/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3820 - acc: 0.8379 - val_loss: 0.4075 - val_acc: 0.8246\n",
      "Epoch 1406/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3818 - acc: 0.8202 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1407/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3819 - acc: 0.8379 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 1408/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3819 - acc: 0.8202 - val_loss: 0.4136 - val_acc: 0.8246\n",
      "Epoch 1409/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3820 - acc: 0.8395 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1410/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3818 - acc: 0.8202 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1411/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3819 - acc: 0.8379 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 1412/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3819 - acc: 0.8202 - val_loss: 0.4137 - val_acc: 0.8246\n",
      "Epoch 1413/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3819 - acc: 0.8395 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1414/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3817 - acc: 0.8186 - val_loss: 0.4130 - val_acc: 0.8246\n",
      "Epoch 1415/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3817 - acc: 0.8379 - val_loss: 0.4071 - val_acc: 0.8246\n",
      "Epoch 1416/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3816 - acc: 0.8186 - val_loss: 0.4132 - val_acc: 0.8246\n",
      "Epoch 1417/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3816 - acc: 0.8379 - val_loss: 0.4075 - val_acc: 0.8246\n",
      "Epoch 1418/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3816 - acc: 0.8186 - val_loss: 0.4131 - val_acc: 0.8246\n",
      "Epoch 1419/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3817 - acc: 0.8379 - val_loss: 0.4072 - val_acc: 0.8246\n",
      "Epoch 1420/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3816 - acc: 0.8186 - val_loss: 0.4135 - val_acc: 0.8246\n",
      "Epoch 1421/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3817 - acc: 0.8379 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1422/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3817 - acc: 0.8186 - val_loss: 0.4137 - val_acc: 0.8284\n",
      "Epoch 1423/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3818 - acc: 0.8395 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1424/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3816 - acc: 0.8186 - val_loss: 0.4137 - val_acc: 0.8284\n",
      "Epoch 1425/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3816 - acc: 0.8379 - val_loss: 0.4077 - val_acc: 0.8246\n",
      "Epoch 1426/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3816 - acc: 0.8186 - val_loss: 0.4133 - val_acc: 0.8246\n",
      "Epoch 1427/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3815 - acc: 0.8379 - val_loss: 0.4074 - val_acc: 0.8246\n",
      "Epoch 1428/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3814 - acc: 0.8202 - val_loss: 0.4136 - val_acc: 0.8246\n",
      "Epoch 1429/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3815 - acc: 0.8379 - val_loss: 0.4078 - val_acc: 0.8246\n",
      "Epoch 1430/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3814 - acc: 0.8186 - val_loss: 0.4135 - val_acc: 0.8246\n",
      "Epoch 1431/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3815 - acc: 0.8395 - val_loss: 0.4076 - val_acc: 0.8246\n",
      "Epoch 1432/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3813 - acc: 0.8186 - val_loss: 0.4139 - val_acc: 0.8246\n",
      "Epoch 1433/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3815 - acc: 0.8395 - val_loss: 0.4078 - val_acc: 0.8246\n",
      "Epoch 1434/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3815 - acc: 0.8186 - val_loss: 0.4138 - val_acc: 0.8284\n",
      "Epoch 1435/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3815 - acc: 0.8395 - val_loss: 0.4076 - val_acc: 0.8246\n",
      "Epoch 1436/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3814 - acc: 0.8186 - val_loss: 0.4140 - val_acc: 0.8246\n",
      "Epoch 1437/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3814 - acc: 0.8395 - val_loss: 0.4079 - val_acc: 0.8246\n",
      "Epoch 1438/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3814 - acc: 0.8186 - val_loss: 0.4136 - val_acc: 0.8284\n",
      "Epoch 1439/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3814 - acc: 0.8395 - val_loss: 0.4076 - val_acc: 0.8246\n",
      "Epoch 1440/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3812 - acc: 0.8202 - val_loss: 0.4138 - val_acc: 0.8246\n",
      "Epoch 1441/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3812 - acc: 0.8395 - val_loss: 0.4079 - val_acc: 0.8246\n",
      "Epoch 1442/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3812 - acc: 0.8202 - val_loss: 0.4137 - val_acc: 0.8246\n",
      "Epoch 1443/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3813 - acc: 0.8395 - val_loss: 0.4077 - val_acc: 0.8246\n",
      "Epoch 1444/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3811 - acc: 0.8202 - val_loss: 0.4141 - val_acc: 0.8246\n",
      "Epoch 1445/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3812 - acc: 0.8395 - val_loss: 0.4080 - val_acc: 0.8246\n",
      "Epoch 1446/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3812 - acc: 0.8202 - val_loss: 0.4139 - val_acc: 0.8284\n",
      "Epoch 1447/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3812 - acc: 0.8395 - val_loss: 0.4078 - val_acc: 0.8246\n",
      "Epoch 1448/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3810 - acc: 0.8202 - val_loss: 0.4141 - val_acc: 0.8246\n",
      "Epoch 1449/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3811 - acc: 0.8395 - val_loss: 0.4081 - val_acc: 0.8246\n",
      "Epoch 1450/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3811 - acc: 0.8202 - val_loss: 0.4139 - val_acc: 0.8246\n",
      "Epoch 1451/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3811 - acc: 0.8395 - val_loss: 0.4079 - val_acc: 0.8246\n",
      "Epoch 1452/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3809 - acc: 0.8218 - val_loss: 0.4142 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1453/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3810 - acc: 0.8395 - val_loss: 0.4081 - val_acc: 0.8246\n",
      "Epoch 1454/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3810 - acc: 0.8202 - val_loss: 0.4141 - val_acc: 0.8284\n",
      "Epoch 1455/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3811 - acc: 0.8395 - val_loss: 0.4080 - val_acc: 0.8246\n",
      "Epoch 1456/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3809 - acc: 0.8218 - val_loss: 0.4144 - val_acc: 0.8246\n",
      "Epoch 1457/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3810 - acc: 0.8395 - val_loss: 0.4082 - val_acc: 0.8246\n",
      "Epoch 1458/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3810 - acc: 0.8202 - val_loss: 0.4140 - val_acc: 0.8284\n",
      "Epoch 1459/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3810 - acc: 0.8395 - val_loss: 0.4080 - val_acc: 0.8246\n",
      "Epoch 1460/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3808 - acc: 0.8218 - val_loss: 0.4144 - val_acc: 0.8246\n",
      "Epoch 1461/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3809 - acc: 0.8395 - val_loss: 0.4082 - val_acc: 0.8246\n",
      "Epoch 1462/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3808 - acc: 0.8218 - val_loss: 0.4139 - val_acc: 0.8246\n",
      "Epoch 1463/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3808 - acc: 0.8395 - val_loss: 0.4079 - val_acc: 0.8246\n",
      "Epoch 1464/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3808 - acc: 0.8202 - val_loss: 0.4148 - val_acc: 0.8284\n",
      "Epoch 1465/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3809 - acc: 0.8379 - val_loss: 0.4085 - val_acc: 0.8246\n",
      "Epoch 1466/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3807 - acc: 0.8202 - val_loss: 0.4142 - val_acc: 0.8246\n",
      "Epoch 1467/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3808 - acc: 0.8395 - val_loss: 0.4083 - val_acc: 0.8246\n",
      "Epoch 1468/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3807 - acc: 0.8202 - val_loss: 0.4147 - val_acc: 0.8284\n",
      "Epoch 1469/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3808 - acc: 0.8379 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 1470/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3806 - acc: 0.8218 - val_loss: 0.4142 - val_acc: 0.8246\n",
      "Epoch 1471/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3807 - acc: 0.8395 - val_loss: 0.4083 - val_acc: 0.8246\n",
      "Epoch 1472/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3806 - acc: 0.8218 - val_loss: 0.4146 - val_acc: 0.8284\n",
      "Epoch 1473/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3807 - acc: 0.8395 - val_loss: 0.4085 - val_acc: 0.8246\n",
      "Epoch 1474/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3807 - acc: 0.8202 - val_loss: 0.4144 - val_acc: 0.8321\n",
      "Epoch 1475/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3808 - acc: 0.8379 - val_loss: 0.4083 - val_acc: 0.8246\n",
      "Epoch 1476/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3806 - acc: 0.8202 - val_loss: 0.4147 - val_acc: 0.8321\n",
      "Epoch 1477/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3807 - acc: 0.8379 - val_loss: 0.4086 - val_acc: 0.8246\n",
      "Epoch 1478/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3805 - acc: 0.8202 - val_loss: 0.4143 - val_acc: 0.8321\n",
      "Epoch 1479/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3806 - acc: 0.8379 - val_loss: 0.4083 - val_acc: 0.8246\n",
      "Epoch 1480/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3806 - acc: 0.8202 - val_loss: 0.4148 - val_acc: 0.8284\n",
      "Epoch 1481/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3806 - acc: 0.8379 - val_loss: 0.4086 - val_acc: 0.8246\n",
      "Epoch 1482/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3804 - acc: 0.8202 - val_loss: 0.4143 - val_acc: 0.8321\n",
      "Epoch 1483/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3805 - acc: 0.8363 - val_loss: 0.4083 - val_acc: 0.8246\n",
      "Epoch 1484/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3803 - acc: 0.8202 - val_loss: 0.4147 - val_acc: 0.8284\n",
      "Epoch 1485/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3805 - acc: 0.8363 - val_loss: 0.4087 - val_acc: 0.8246\n",
      "Epoch 1486/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3805 - acc: 0.8202 - val_loss: 0.4146 - val_acc: 0.8321\n",
      "Epoch 1487/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3805 - acc: 0.8379 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 1488/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3804 - acc: 0.8202 - val_loss: 0.4145 - val_acc: 0.8321\n",
      "Epoch 1489/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3805 - acc: 0.8395 - val_loss: 0.4083 - val_acc: 0.8246\n",
      "Epoch 1490/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3803 - acc: 0.8202 - val_loss: 0.4149 - val_acc: 0.8284\n",
      "Epoch 1491/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3804 - acc: 0.8379 - val_loss: 0.4085 - val_acc: 0.8246\n",
      "Epoch 1492/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3804 - acc: 0.8202 - val_loss: 0.4145 - val_acc: 0.8321\n",
      "Epoch 1493/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3804 - acc: 0.8379 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 1494/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3803 - acc: 0.8202 - val_loss: 0.4149 - val_acc: 0.8284\n",
      "Epoch 1495/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3803 - acc: 0.8379 - val_loss: 0.4086 - val_acc: 0.8246\n",
      "Epoch 1496/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8202 - val_loss: 0.4144 - val_acc: 0.8321\n",
      "Epoch 1497/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8379 - val_loss: 0.4085 - val_acc: 0.8246\n",
      "Epoch 1498/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3801 - acc: 0.8218 - val_loss: 0.4149 - val_acc: 0.8284\n",
      "Epoch 1499/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8379 - val_loss: 0.4087 - val_acc: 0.8246\n",
      "Epoch 1500/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3803 - acc: 0.8202 - val_loss: 0.4146 - val_acc: 0.8321\n",
      "Epoch 1501/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3803 - acc: 0.8379 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 1502/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3801 - acc: 0.8202 - val_loss: 0.4150 - val_acc: 0.8284\n",
      "Epoch 1503/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3803 - acc: 0.8379 - val_loss: 0.4086 - val_acc: 0.8246\n",
      "Epoch 1504/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3801 - acc: 0.8202 - val_loss: 0.4145 - val_acc: 0.8321\n",
      "Epoch 1505/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8379 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 1506/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8202 - val_loss: 0.4150 - val_acc: 0.8284\n",
      "Epoch 1507/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3803 - acc: 0.8379 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1508/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3800 - acc: 0.8202 - val_loss: 0.4146 - val_acc: 0.8321\n",
      "Epoch 1509/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3801 - acc: 0.8379 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 1510/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3800 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1511/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3801 - acc: 0.8379 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1512/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3801 - acc: 0.8186 - val_loss: 0.4149 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1513/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8379 - val_loss: 0.4087 - val_acc: 0.8246\n",
      "Epoch 1514/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3800 - acc: 0.8186 - val_loss: 0.4147 - val_acc: 0.8321\n",
      "Epoch 1515/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3800 - acc: 0.8379 - val_loss: 0.4086 - val_acc: 0.8246\n",
      "Epoch 1516/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3799 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1517/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3800 - acc: 0.8379 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1518/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3800 - acc: 0.8186 - val_loss: 0.4149 - val_acc: 0.8321\n",
      "Epoch 1519/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3801 - acc: 0.8379 - val_loss: 0.4086 - val_acc: 0.8246\n",
      "Epoch 1520/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3799 - acc: 0.8186 - val_loss: 0.4152 - val_acc: 0.8284\n",
      "Epoch 1521/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3800 - acc: 0.8379 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1522/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3798 - acc: 0.8202 - val_loss: 0.4148 - val_acc: 0.8321\n",
      "Epoch 1523/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3799 - acc: 0.8379 - val_loss: 0.4087 - val_acc: 0.8246\n",
      "Epoch 1524/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3799 - acc: 0.8186 - val_loss: 0.4153 - val_acc: 0.8284\n",
      "Epoch 1525/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3800 - acc: 0.8379 - val_loss: 0.4090 - val_acc: 0.8246\n",
      "Epoch 1526/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3798 - acc: 0.8202 - val_loss: 0.4149 - val_acc: 0.8321\n",
      "Epoch 1527/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3799 - acc: 0.8379 - val_loss: 0.4087 - val_acc: 0.8246\n",
      "Epoch 1528/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3797 - acc: 0.8202 - val_loss: 0.4153 - val_acc: 0.8284\n",
      "Epoch 1529/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3799 - acc: 0.8379 - val_loss: 0.4090 - val_acc: 0.8246\n",
      "Epoch 1530/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3799 - acc: 0.8186 - val_loss: 0.4151 - val_acc: 0.8321\n",
      "Epoch 1531/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3799 - acc: 0.8379 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1532/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3797 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8284\n",
      "Epoch 1533/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3798 - acc: 0.8379 - val_loss: 0.4091 - val_acc: 0.8246\n",
      "Epoch 1534/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3798 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1535/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3798 - acc: 0.8379 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1536/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3796 - acc: 0.8202 - val_loss: 0.4148 - val_acc: 0.8321\n",
      "Epoch 1537/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3797 - acc: 0.8379 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1538/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3797 - acc: 0.8202 - val_loss: 0.4155 - val_acc: 0.8284\n",
      "Epoch 1539/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3798 - acc: 0.8379 - val_loss: 0.4090 - val_acc: 0.8246\n",
      "Epoch 1540/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3796 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8321\n",
      "Epoch 1541/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3797 - acc: 0.8379 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1542/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3796 - acc: 0.8202 - val_loss: 0.4156 - val_acc: 0.8284\n",
      "Epoch 1543/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3798 - acc: 0.8379 - val_loss: 0.4092 - val_acc: 0.8246\n",
      "Epoch 1544/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3795 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8284\n",
      "Epoch 1545/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3796 - acc: 0.8379 - val_loss: 0.4090 - val_acc: 0.8246\n",
      "Epoch 1546/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3796 - acc: 0.8202 - val_loss: 0.4157 - val_acc: 0.8284\n",
      "Epoch 1547/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3797 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8246\n",
      "Epoch 1548/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3795 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1549/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3796 - acc: 0.8395 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1550/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3795 - acc: 0.8202 - val_loss: 0.4156 - val_acc: 0.8284\n",
      "Epoch 1551/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3796 - acc: 0.8379 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1552/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3794 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1553/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3795 - acc: 0.8379 - val_loss: 0.4090 - val_acc: 0.8246\n",
      "Epoch 1554/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8202 - val_loss: 0.4149 - val_acc: 0.8321\n",
      "Epoch 1555/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3795 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1556/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3795 - acc: 0.8202 - val_loss: 0.4157 - val_acc: 0.8284\n",
      "Epoch 1557/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3796 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8246\n",
      "Epoch 1558/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3794 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8284\n",
      "Epoch 1559/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3795 - acc: 0.8395 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1560/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3794 - acc: 0.8186 - val_loss: 0.4158 - val_acc: 0.8284\n",
      "Epoch 1561/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3795 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8246\n",
      "Epoch 1562/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8202 - val_loss: 0.4150 - val_acc: 0.8284\n",
      "Epoch 1563/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3795 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1564/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3792 - acc: 0.8202 - val_loss: 0.4156 - val_acc: 0.8284\n",
      "Epoch 1565/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3792 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1566/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3793 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1567/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3795 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1568/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3792 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8284\n",
      "Epoch 1569/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1570/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8202 - val_loss: 0.4153 - val_acc: 0.8284\n",
      "Epoch 1571/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3795 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1572/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3792 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1573/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3793 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1574/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3792 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8284\n",
      "Epoch 1575/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3794 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1576/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3791 - acc: 0.8202 - val_loss: 0.4157 - val_acc: 0.8284\n",
      "Epoch 1577/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3792 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1578/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8284\n",
      "Epoch 1579/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1580/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8246\n",
      "Epoch 1581/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1582/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8202 - val_loss: 0.4153 - val_acc: 0.8284\n",
      "Epoch 1583/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8395 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1584/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3790 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8246\n",
      "Epoch 1585/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8246\n",
      "Epoch 1586/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8202 - val_loss: 0.4153 - val_acc: 0.8246\n",
      "Epoch 1587/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3793 - acc: 0.8395 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 1588/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3791 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1589/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3791 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1590/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3789 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1591/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3791 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1592/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3790 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8284\n",
      "Epoch 1593/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3790 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1594/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3788 - acc: 0.8202 - val_loss: 0.4151 - val_acc: 0.8284\n",
      "Epoch 1595/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3791 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1596/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3790 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1597/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3790 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1598/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3789 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8246\n",
      "Epoch 1599/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3791 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8246\n",
      "Epoch 1600/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3789 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1601/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3790 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8284\n",
      "Epoch 1602/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3788 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8246\n",
      "Epoch 1603/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4089 - val_acc: 0.8284\n",
      "Epoch 1604/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3789 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1605/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1606/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3787 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8246\n",
      "Epoch 1607/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4089 - val_acc: 0.8284\n",
      "Epoch 1608/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3788 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1609/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8284\n",
      "Epoch 1610/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3787 - acc: 0.8202 - val_loss: 0.4153 - val_acc: 0.8246\n",
      "Epoch 1611/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4090 - val_acc: 0.8284\n",
      "Epoch 1612/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3788 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1613/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1614/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3787 - acc: 0.8202 - val_loss: 0.4152 - val_acc: 0.8246\n",
      "Epoch 1615/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3789 - acc: 0.8395 - val_loss: 0.4088 - val_acc: 0.8284\n",
      "Epoch 1616/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3787 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1617/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3788 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1618/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3786 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 1619/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3788 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1620/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3787 - acc: 0.8202 - val_loss: 0.4161 - val_acc: 0.8246\n",
      "Epoch 1621/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3788 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1622/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3787 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 1623/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3788 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1624/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3785 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1625/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3786 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1626/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3785 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 1627/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3787 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1628/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3785 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1629/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3786 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1630/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3786 - acc: 0.8202 - val_loss: 0.4155 - val_acc: 0.8246\n",
      "Epoch 1631/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3787 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1632/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3786 - acc: 0.8202 - val_loss: 0.4161 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1633/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3787 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1634/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3785 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 1635/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3786 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1636/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3785 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1637/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3785 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1638/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.3784 - acc: 0.8202 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 1639/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3786 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1640/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1641/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3784 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1642/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3784 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1643/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3786 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8284\n",
      "Epoch 1644/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3785 - acc: 0.8202 - val_loss: 0.4157 - val_acc: 0.8246\n",
      "Epoch 1645/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3785 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1646/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3784 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1647/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3786 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8284\n",
      "Epoch 1648/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3782 - acc: 0.8202 - val_loss: 0.4155 - val_acc: 0.8246\n",
      "Epoch 1649/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8395 - val_loss: 0.4093 - val_acc: 0.8284\n",
      "Epoch 1650/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3783 - acc: 0.8202 - val_loss: 0.4158 - val_acc: 0.8246\n",
      "Epoch 1651/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3785 - acc: 0.8395 - val_loss: 0.4092 - val_acc: 0.8284\n",
      "Epoch 1652/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3782 - acc: 0.8202 - val_loss: 0.4157 - val_acc: 0.8246\n",
      "Epoch 1653/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8395 - val_loss: 0.4094 - val_acc: 0.8284\n",
      "Epoch 1654/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8202 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1655/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3785 - acc: 0.8395 - val_loss: 0.4092 - val_acc: 0.8284\n",
      "Epoch 1656/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8202 - val_loss: 0.4162 - val_acc: 0.8246\n",
      "Epoch 1657/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3784 - acc: 0.8395 - val_loss: 0.4096 - val_acc: 0.8284\n",
      "Epoch 1658/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3783 - acc: 0.8202 - val_loss: 0.4155 - val_acc: 0.8246\n",
      "Epoch 1659/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3784 - acc: 0.8395 - val_loss: 0.4092 - val_acc: 0.8284\n",
      "Epoch 1660/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3780 - acc: 0.8218 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1661/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3781 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1662/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3781 - acc: 0.8218 - val_loss: 0.4154 - val_acc: 0.8246\n",
      "Epoch 1663/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8395 - val_loss: 0.4091 - val_acc: 0.8284\n",
      "Epoch 1664/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3782 - acc: 0.8202 - val_loss: 0.4162 - val_acc: 0.8246\n",
      "Epoch 1665/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3783 - acc: 0.8395 - val_loss: 0.4096 - val_acc: 0.8284\n",
      "Epoch 1666/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3782 - acc: 0.8202 - val_loss: 0.4156 - val_acc: 0.8246\n",
      "Epoch 1667/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3783 - acc: 0.8395 - val_loss: 0.4092 - val_acc: 0.8284\n",
      "Epoch 1668/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3780 - acc: 0.8202 - val_loss: 0.4162 - val_acc: 0.8246\n",
      "Epoch 1669/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3781 - acc: 0.8395 - val_loss: 0.4097 - val_acc: 0.8284\n",
      "Epoch 1670/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3781 - acc: 0.8218 - val_loss: 0.4162 - val_acc: 0.8246\n",
      "Epoch 1671/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3783 - acc: 0.8395 - val_loss: 0.4095 - val_acc: 0.8284\n",
      "Epoch 1672/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3781 - acc: 0.8202 - val_loss: 0.4159 - val_acc: 0.8246\n",
      "Epoch 1673/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3781 - acc: 0.8411 - val_loss: 0.4096 - val_acc: 0.8284\n",
      "Epoch 1674/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3780 - acc: 0.8218 - val_loss: 0.4162 - val_acc: 0.8246\n",
      "Epoch 1675/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3782 - acc: 0.8411 - val_loss: 0.4097 - val_acc: 0.8284\n",
      "Epoch 1676/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3779 - acc: 0.8186 - val_loss: 0.4160 - val_acc: 0.8246\n",
      "Epoch 1677/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3780 - acc: 0.8411 - val_loss: 0.4099 - val_acc: 0.8284\n",
      "Epoch 1678/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3779 - acc: 0.8202 - val_loss: 0.4164 - val_acc: 0.8246\n",
      "Epoch 1679/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3782 - acc: 0.8411 - val_loss: 0.4097 - val_acc: 0.8284\n",
      "Epoch 1680/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3780 - acc: 0.8202 - val_loss: 0.4163 - val_acc: 0.8246\n",
      "Epoch 1681/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3780 - acc: 0.8427 - val_loss: 0.4100 - val_acc: 0.8284\n",
      "Epoch 1682/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3780 - acc: 0.8186 - val_loss: 0.4166 - val_acc: 0.8246\n",
      "Epoch 1683/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3782 - acc: 0.8427 - val_loss: 0.4098 - val_acc: 0.8284\n",
      "Epoch 1684/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3779 - acc: 0.8186 - val_loss: 0.4161 - val_acc: 0.8246\n",
      "Epoch 1685/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3778 - acc: 0.8411 - val_loss: 0.4100 - val_acc: 0.8284\n",
      "Epoch 1686/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3779 - acc: 0.8202 - val_loss: 0.4168 - val_acc: 0.8246\n",
      "Epoch 1687/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3781 - acc: 0.8443 - val_loss: 0.4100 - val_acc: 0.8284\n",
      "Epoch 1688/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3779 - acc: 0.8186 - val_loss: 0.4168 - val_acc: 0.8246\n",
      "Epoch 1689/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3780 - acc: 0.8459 - val_loss: 0.4103 - val_acc: 0.8284\n",
      "Epoch 1690/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3779 - acc: 0.8186 - val_loss: 0.4171 - val_acc: 0.8246\n",
      "Epoch 1691/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3781 - acc: 0.8459 - val_loss: 0.4102 - val_acc: 0.8284\n",
      "Epoch 1692/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3778 - acc: 0.8186 - val_loss: 0.4167 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1693/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3778 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1694/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3776 - acc: 0.8202 - val_loss: 0.4167 - val_acc: 0.8246\n",
      "Epoch 1695/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3778 - acc: 0.8443 - val_loss: 0.4102 - val_acc: 0.8284\n",
      "Epoch 1696/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3776 - acc: 0.8186 - val_loss: 0.4167 - val_acc: 0.8246\n",
      "Epoch 1697/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3777 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1698/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3777 - acc: 0.8186 - val_loss: 0.4171 - val_acc: 0.8246\n",
      "Epoch 1699/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3779 - acc: 0.8443 - val_loss: 0.4103 - val_acc: 0.8284\n",
      "Epoch 1700/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3776 - acc: 0.8186 - val_loss: 0.4167 - val_acc: 0.8246\n",
      "Epoch 1701/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3776 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1702/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3776 - acc: 0.8202 - val_loss: 0.4173 - val_acc: 0.8246\n",
      "Epoch 1703/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3779 - acc: 0.8443 - val_loss: 0.4104 - val_acc: 0.8246\n",
      "Epoch 1704/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3777 - acc: 0.8186 - val_loss: 0.4172 - val_acc: 0.8246\n",
      "Epoch 1705/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3778 - acc: 0.8459 - val_loss: 0.4107 - val_acc: 0.8284\n",
      "Epoch 1706/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3776 - acc: 0.8186 - val_loss: 0.4173 - val_acc: 0.8246\n",
      "Epoch 1707/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3778 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8246\n",
      "Epoch 1708/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3774 - acc: 0.8186 - val_loss: 0.4167 - val_acc: 0.8246\n",
      "Epoch 1709/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3774 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1710/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3774 - acc: 0.8250 - val_loss: 0.4171 - val_acc: 0.8246\n",
      "Epoch 1711/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3776 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1712/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3775 - acc: 0.8186 - val_loss: 0.4170 - val_acc: 0.8246\n",
      "Epoch 1713/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3775 - acc: 0.8443 - val_loss: 0.4106 - val_acc: 0.8284\n",
      "Epoch 1714/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3774 - acc: 0.8202 - val_loss: 0.4172 - val_acc: 0.8246\n",
      "Epoch 1715/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3777 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1716/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3775 - acc: 0.8186 - val_loss: 0.4173 - val_acc: 0.8246\n",
      "Epoch 1717/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3776 - acc: 0.8459 - val_loss: 0.4108 - val_acc: 0.8284\n",
      "Epoch 1718/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3775 - acc: 0.8186 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1719/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3777 - acc: 0.8459 - val_loss: 0.4106 - val_acc: 0.8246\n",
      "Epoch 1720/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3774 - acc: 0.8186 - val_loss: 0.4170 - val_acc: 0.8246\n",
      "Epoch 1721/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3774 - acc: 0.8443 - val_loss: 0.4108 - val_acc: 0.8284\n",
      "Epoch 1722/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3773 - acc: 0.8250 - val_loss: 0.4167 - val_acc: 0.8246\n",
      "Epoch 1723/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3774 - acc: 0.8427 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1724/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3773 - acc: 0.8186 - val_loss: 0.4176 - val_acc: 0.8246\n",
      "Epoch 1725/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3774 - acc: 0.8443 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1726/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3772 - acc: 0.8250 - val_loss: 0.4169 - val_acc: 0.8246\n",
      "Epoch 1727/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3774 - acc: 0.8427 - val_loss: 0.4104 - val_acc: 0.8284\n",
      "Epoch 1728/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3773 - acc: 0.8186 - val_loss: 0.4176 - val_acc: 0.8246\n",
      "Epoch 1729/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3774 - acc: 0.8459 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1730/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3773 - acc: 0.8202 - val_loss: 0.4171 - val_acc: 0.8246\n",
      "Epoch 1731/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3775 - acc: 0.8443 - val_loss: 0.4104 - val_acc: 0.8284\n",
      "Epoch 1732/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3772 - acc: 0.8202 - val_loss: 0.4176 - val_acc: 0.8246\n",
      "Epoch 1733/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3773 - acc: 0.8427 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1734/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3772 - acc: 0.8250 - val_loss: 0.4171 - val_acc: 0.8246\n",
      "Epoch 1735/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3773 - acc: 0.8427 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1736/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3772 - acc: 0.8186 - val_loss: 0.4177 - val_acc: 0.8246\n",
      "Epoch 1737/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3773 - acc: 0.8459 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1738/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3772 - acc: 0.8250 - val_loss: 0.4171 - val_acc: 0.8246\n",
      "Epoch 1739/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3773 - acc: 0.8427 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1740/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3770 - acc: 0.8250 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1741/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3771 - acc: 0.8427 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1742/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3771 - acc: 0.8283 - val_loss: 0.4174 - val_acc: 0.8246\n",
      "Epoch 1743/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3773 - acc: 0.8459 - val_loss: 0.4108 - val_acc: 0.8246\n",
      "Epoch 1744/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3772 - acc: 0.8186 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1745/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3771 - acc: 0.8443 - val_loss: 0.4108 - val_acc: 0.8284\n",
      "Epoch 1746/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3770 - acc: 0.8283 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1747/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3772 - acc: 0.8427 - val_loss: 0.4108 - val_acc: 0.8246\n",
      "Epoch 1748/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3770 - acc: 0.8250 - val_loss: 0.4174 - val_acc: 0.8246\n",
      "Epoch 1749/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3771 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1750/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3770 - acc: 0.8266 - val_loss: 0.4172 - val_acc: 0.8246\n",
      "Epoch 1751/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3772 - acc: 0.8427 - val_loss: 0.4106 - val_acc: 0.8284\n",
      "Epoch 1752/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3769 - acc: 0.8283 - val_loss: 0.4177 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1753/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3770 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1754/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3770 - acc: 0.8283 - val_loss: 0.4173 - val_acc: 0.8246\n",
      "Epoch 1755/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3771 - acc: 0.8443 - val_loss: 0.4105 - val_acc: 0.8284\n",
      "Epoch 1756/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3770 - acc: 0.8250 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1757/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3771 - acc: 0.8459 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1758/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3769 - acc: 0.8283 - val_loss: 0.4172 - val_acc: 0.8246\n",
      "Epoch 1759/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3770 - acc: 0.8443 - val_loss: 0.4107 - val_acc: 0.8284\n",
      "Epoch 1760/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3769 - acc: 0.8283 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1761/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3769 - acc: 0.8443 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 1762/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3768 - acc: 0.8299 - val_loss: 0.4173 - val_acc: 0.8246\n",
      "Epoch 1763/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3770 - acc: 0.8443 - val_loss: 0.4108 - val_acc: 0.8284\n",
      "Epoch 1764/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3768 - acc: 0.8283 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1765/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3769 - acc: 0.8443 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1766/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3769 - acc: 0.8283 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1767/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3770 - acc: 0.8443 - val_loss: 0.4107 - val_acc: 0.8284\n",
      "Epoch 1768/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3768 - acc: 0.8283 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1769/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3768 - acc: 0.8443 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 1770/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8299 - val_loss: 0.4173 - val_acc: 0.8246\n",
      "Epoch 1771/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3768 - acc: 0.8443 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1772/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3767 - acc: 0.8283 - val_loss: 0.4176 - val_acc: 0.8246\n",
      "Epoch 1773/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3768 - acc: 0.8443 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1774/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3767 - acc: 0.8299 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1775/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3769 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1776/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3768 - acc: 0.8202 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1777/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3769 - acc: 0.8459 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1778/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3767 - acc: 0.8299 - val_loss: 0.4176 - val_acc: 0.8246\n",
      "Epoch 1779/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3768 - acc: 0.8443 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1780/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3765 - acc: 0.8299 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1781/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8443 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 1782/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8299 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1783/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3767 - acc: 0.8443 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1784/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3765 - acc: 0.8299 - val_loss: 0.4181 - val_acc: 0.8246\n",
      "Epoch 1785/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3766 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1786/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3765 - acc: 0.8299 - val_loss: 0.4177 - val_acc: 0.8246\n",
      "Epoch 1787/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3767 - acc: 0.8443 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1788/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8299 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1789/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3768 - acc: 0.8459 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1790/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8299 - val_loss: 0.4176 - val_acc: 0.8246\n",
      "Epoch 1791/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3767 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1792/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3764 - acc: 0.8299 - val_loss: 0.4181 - val_acc: 0.8246\n",
      "Epoch 1793/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3765 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1794/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3765 - acc: 0.8299 - val_loss: 0.4177 - val_acc: 0.8246\n",
      "Epoch 1795/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3766 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1796/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3764 - acc: 0.8299 - val_loss: 0.4181 - val_acc: 0.8246\n",
      "Epoch 1797/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3765 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1798/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3763 - acc: 0.8299 - val_loss: 0.4175 - val_acc: 0.8246\n",
      "Epoch 1799/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3765 - acc: 0.8443 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 1800/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3765 - acc: 0.8299 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1801/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1802/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3764 - acc: 0.8299 - val_loss: 0.4177 - val_acc: 0.8246\n",
      "Epoch 1803/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8443 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1804/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3763 - acc: 0.8299 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1805/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3764 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1806/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3764 - acc: 0.8299 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1807/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3766 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1808/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3763 - acc: 0.8299 - val_loss: 0.4182 - val_acc: 0.8246\n",
      "Epoch 1809/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3764 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1810/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3763 - acc: 0.8299 - val_loss: 0.4177 - val_acc: 0.8246\n",
      "Epoch 1811/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3765 - acc: 0.8443 - val_loss: 0.4111 - val_acc: 0.8246\n",
      "Epoch 1812/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.4181 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1813/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3763 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1814/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.4178 - val_acc: 0.8246\n",
      "Epoch 1815/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3764 - acc: 0.8443 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1816/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.4185 - val_acc: 0.8246\n",
      "Epoch 1817/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3763 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1818/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.4180 - val_acc: 0.8246\n",
      "Epoch 1819/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3764 - acc: 0.8443 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 1820/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.4186 - val_acc: 0.8246\n",
      "Epoch 1821/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3763 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1822/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3763 - acc: 0.8299 - val_loss: 0.4181 - val_acc: 0.8246\n",
      "Epoch 1823/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3764 - acc: 0.8443 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1824/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3761 - acc: 0.8299 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1825/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3762 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1826/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.4177 - val_acc: 0.8246\n",
      "Epoch 1827/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3762 - acc: 0.8443 - val_loss: 0.4112 - val_acc: 0.8246\n",
      "Epoch 1828/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1829/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3761 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1830/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1831/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3763 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1832/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3761 - acc: 0.8299 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1833/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3762 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1834/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.4188 - val_acc: 0.8246\n",
      "Epoch 1835/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3764 - acc: 0.8459 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1836/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.4182 - val_acc: 0.8246\n",
      "Epoch 1837/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3760 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1838/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3758 - acc: 0.8299 - val_loss: 0.4181 - val_acc: 0.8246\n",
      "Epoch 1839/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3760 - acc: 0.8443 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 1840/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3758 - acc: 0.8299 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1841/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3758 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1842/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3758 - acc: 0.8299 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1843/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3761 - acc: 0.8443 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 1844/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3759 - acc: 0.8299 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1845/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3760 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1846/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3761 - acc: 0.8299 - val_loss: 0.4190 - val_acc: 0.8246\n",
      "Epoch 1847/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3764 - acc: 0.8475 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1848/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1849/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3760 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1850/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3758 - acc: 0.8299 - val_loss: 0.4182 - val_acc: 0.8246\n",
      "Epoch 1851/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3759 - acc: 0.8443 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 1852/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3756 - acc: 0.8299 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1853/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3757 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1854/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3757 - acc: 0.8315 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1855/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3759 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1856/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3757 - acc: 0.8299 - val_loss: 0.4188 - val_acc: 0.8246\n",
      "Epoch 1857/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3759 - acc: 0.8443 - val_loss: 0.4119 - val_acc: 0.8246\n",
      "Epoch 1858/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1859/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3762 - acc: 0.8475 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 1860/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3759 - acc: 0.8299 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1861/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3759 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1862/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3757 - acc: 0.8315 - val_loss: 0.4179 - val_acc: 0.8246\n",
      "Epoch 1863/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3757 - acc: 0.8443 - val_loss: 0.4114 - val_acc: 0.8246\n",
      "Epoch 1864/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3755 - acc: 0.8315 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1865/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3756 - acc: 0.8443 - val_loss: 0.4119 - val_acc: 0.8246\n",
      "Epoch 1866/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3755 - acc: 0.8315 - val_loss: 0.4180 - val_acc: 0.8246\n",
      "Epoch 1867/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3758 - acc: 0.8443 - val_loss: 0.4113 - val_acc: 0.8246\n",
      "Epoch 1868/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3756 - acc: 0.8299 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1869/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3758 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1870/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3758 - acc: 0.8283 - val_loss: 0.4191 - val_acc: 0.8246\n",
      "Epoch 1871/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3761 - acc: 0.8475 - val_loss: 0.4116 - val_acc: 0.8209\n",
      "Epoch 1872/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3758 - acc: 0.8299 - val_loss: 0.4185 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1873/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3758 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1874/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3756 - acc: 0.8315 - val_loss: 0.4182 - val_acc: 0.8246\n",
      "Epoch 1875/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3757 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1876/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3754 - acc: 0.8315 - val_loss: 0.4181 - val_acc: 0.8246\n",
      "Epoch 1877/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3754 - acc: 0.8443 - val_loss: 0.4119 - val_acc: 0.8246\n",
      "Epoch 1878/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3754 - acc: 0.8315 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1879/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3756 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1880/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3755 - acc: 0.8299 - val_loss: 0.4186 - val_acc: 0.8246\n",
      "Epoch 1881/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3756 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1882/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3757 - acc: 0.8299 - val_loss: 0.4189 - val_acc: 0.8246\n",
      "Epoch 1883/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3760 - acc: 0.8459 - val_loss: 0.4115 - val_acc: 0.8209\n",
      "Epoch 1884/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3756 - acc: 0.8299 - val_loss: 0.4186 - val_acc: 0.8246\n",
      "Epoch 1885/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.3756 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8246\n",
      "Epoch 1886/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3755 - acc: 0.8315 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1887/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3756 - acc: 0.8443 - val_loss: 0.4115 - val_acc: 0.8246\n",
      "Epoch 1888/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.3753 - acc: 0.8315 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1889/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3754 - acc: 0.8443 - val_loss: 0.4120 - val_acc: 0.8246\n",
      "Epoch 1890/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3753 - acc: 0.8315 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 1891/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3756 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8246\n",
      "Epoch 1892/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3754 - acc: 0.8299 - val_loss: 0.4188 - val_acc: 0.8246\n",
      "Epoch 1893/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3755 - acc: 0.8443 - val_loss: 0.4119 - val_acc: 0.8246\n",
      "Epoch 1894/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3754 - acc: 0.8315 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1895/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3757 - acc: 0.8443 - val_loss: 0.4116 - val_acc: 0.8209\n",
      "Epoch 1896/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3755 - acc: 0.8299 - val_loss: 0.4191 - val_acc: 0.8246\n",
      "Epoch 1897/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3756 - acc: 0.8475 - val_loss: 0.4121 - val_acc: 0.8209\n",
      "Epoch 1898/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3755 - acc: 0.8315 - val_loss: 0.4189 - val_acc: 0.8246\n",
      "Epoch 1899/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3757 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8209\n",
      "Epoch 1900/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3753 - acc: 0.8315 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1901/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3754 - acc: 0.8443 - val_loss: 0.4122 - val_acc: 0.8246\n",
      "Epoch 1902/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4186 - val_acc: 0.8246\n",
      "Epoch 1903/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3754 - acc: 0.8443 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 1904/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1905/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3753 - acc: 0.8443 - val_loss: 0.4122 - val_acc: 0.8246\n",
      "Epoch 1906/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4189 - val_acc: 0.8246\n",
      "Epoch 1907/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3755 - acc: 0.8443 - val_loss: 0.4119 - val_acc: 0.8209\n",
      "Epoch 1908/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3753 - acc: 0.8315 - val_loss: 0.4196 - val_acc: 0.8246\n",
      "Epoch 1909/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3756 - acc: 0.8475 - val_loss: 0.4124 - val_acc: 0.8209\n",
      "Epoch 1910/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3755 - acc: 0.8315 - val_loss: 0.4189 - val_acc: 0.8246\n",
      "Epoch 1911/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3756 - acc: 0.8459 - val_loss: 0.4117 - val_acc: 0.8209\n",
      "Epoch 1912/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3753 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8246\n",
      "Epoch 1913/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3753 - acc: 0.8443 - val_loss: 0.4123 - val_acc: 0.8209\n",
      "Epoch 1914/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 1915/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3752 - acc: 0.8443 - val_loss: 0.4119 - val_acc: 0.8209\n",
      "Epoch 1916/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3750 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8246\n",
      "Epoch 1917/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3752 - acc: 0.8443 - val_loss: 0.4125 - val_acc: 0.8209\n",
      "Epoch 1918/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4187 - val_acc: 0.8246\n",
      "Epoch 1919/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3754 - acc: 0.8427 - val_loss: 0.4118 - val_acc: 0.8209\n",
      "Epoch 1920/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4195 - val_acc: 0.8246\n",
      "Epoch 1921/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3754 - acc: 0.8475 - val_loss: 0.4125 - val_acc: 0.8209\n",
      "Epoch 1922/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3754 - acc: 0.8315 - val_loss: 0.4189 - val_acc: 0.8246\n",
      "Epoch 1923/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3755 - acc: 0.8459 - val_loss: 0.4118 - val_acc: 0.8209\n",
      "Epoch 1924/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4193 - val_acc: 0.8246\n",
      "Epoch 1925/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3752 - acc: 0.8443 - val_loss: 0.4125 - val_acc: 0.8209\n",
      "Epoch 1926/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3750 - acc: 0.8315 - val_loss: 0.4184 - val_acc: 0.8209\n",
      "Epoch 1927/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.3751 - acc: 0.8411 - val_loss: 0.4118 - val_acc: 0.8209\n",
      "Epoch 1928/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4191 - val_acc: 0.8246\n",
      "Epoch 1929/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3751 - acc: 0.8443 - val_loss: 0.4126 - val_acc: 0.8209\n",
      "Epoch 1930/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4193 - val_acc: 0.8246\n",
      "Epoch 1931/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3754 - acc: 0.8427 - val_loss: 0.4122 - val_acc: 0.8209\n",
      "Epoch 1932/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4194 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1933/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3752 - acc: 0.8459 - val_loss: 0.4125 - val_acc: 0.8209\n",
      "Epoch 1934/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8246\n",
      "Epoch 1935/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3753 - acc: 0.8443 - val_loss: 0.4122 - val_acc: 0.8209\n",
      "Epoch 1936/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3750 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8246\n",
      "Epoch 1937/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.3751 - acc: 0.8459 - val_loss: 0.4124 - val_acc: 0.8209\n",
      "Epoch 1938/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4191 - val_acc: 0.8246\n",
      "Epoch 1939/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3752 - acc: 0.8443 - val_loss: 0.4122 - val_acc: 0.8209\n",
      "Epoch 1940/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4191 - val_acc: 0.8246\n",
      "Epoch 1941/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3750 - acc: 0.8459 - val_loss: 0.4126 - val_acc: 0.8209\n",
      "Epoch 1942/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8246\n",
      "Epoch 1943/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3751 - acc: 0.8443 - val_loss: 0.4124 - val_acc: 0.8209\n",
      "Epoch 1944/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4194 - val_acc: 0.8209\n",
      "Epoch 1945/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3751 - acc: 0.8427 - val_loss: 0.4125 - val_acc: 0.8209\n",
      "Epoch 1946/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.4198 - val_acc: 0.8209\n",
      "Epoch 1947/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3754 - acc: 0.8443 - val_loss: 0.4124 - val_acc: 0.8209\n",
      "Epoch 1948/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3750 - acc: 0.8315 - val_loss: 0.4197 - val_acc: 0.8246\n",
      "Epoch 1949/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3750 - acc: 0.8443 - val_loss: 0.4128 - val_acc: 0.8209\n",
      "Epoch 1950/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3748 - acc: 0.8315 - val_loss: 0.4191 - val_acc: 0.8246\n",
      "Epoch 1951/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3750 - acc: 0.8443 - val_loss: 0.4123 - val_acc: 0.8209\n",
      "Epoch 1952/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3748 - acc: 0.8315 - val_loss: 0.4193 - val_acc: 0.8209\n",
      "Epoch 1953/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3748 - acc: 0.8411 - val_loss: 0.4126 - val_acc: 0.8209\n",
      "Epoch 1954/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8209\n",
      "Epoch 1955/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3751 - acc: 0.8427 - val_loss: 0.4123 - val_acc: 0.8209\n",
      "Epoch 1956/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4200 - val_acc: 0.8209\n",
      "Epoch 1957/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3751 - acc: 0.8443 - val_loss: 0.4129 - val_acc: 0.8209\n",
      "Epoch 1958/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3750 - acc: 0.8315 - val_loss: 0.4201 - val_acc: 0.8209\n",
      "Epoch 1959/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3752 - acc: 0.8443 - val_loss: 0.4129 - val_acc: 0.8209\n",
      "Epoch 1960/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4191 - val_acc: 0.8209\n",
      "Epoch 1961/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3749 - acc: 0.8411 - val_loss: 0.4124 - val_acc: 0.8209\n",
      "Epoch 1962/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3746 - acc: 0.8315 - val_loss: 0.4194 - val_acc: 0.8209\n",
      "Epoch 1963/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3748 - acc: 0.8411 - val_loss: 0.4127 - val_acc: 0.8209\n",
      "Epoch 1964/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3747 - acc: 0.8315 - val_loss: 0.4189 - val_acc: 0.8209\n",
      "Epoch 1965/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3748 - acc: 0.8411 - val_loss: 0.4123 - val_acc: 0.8209\n",
      "Epoch 1966/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3747 - acc: 0.8315 - val_loss: 0.4196 - val_acc: 0.8209\n",
      "Epoch 1967/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3749 - acc: 0.8427 - val_loss: 0.4126 - val_acc: 0.8209\n",
      "Epoch 1968/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3750 - acc: 0.8315 - val_loss: 0.4200 - val_acc: 0.8209\n",
      "Epoch 1969/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3752 - acc: 0.8443 - val_loss: 0.4126 - val_acc: 0.8209\n",
      "Epoch 1970/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4202 - val_acc: 0.8209\n",
      "Epoch 1971/2000\n",
      "623/623 [==============================] - 0s 11us/step - loss: 0.3751 - acc: 0.8443 - val_loss: 0.4129 - val_acc: 0.8209\n",
      "Epoch 1972/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4198 - val_acc: 0.8209\n",
      "Epoch 1973/2000\n",
      "623/623 [==============================] - 0s 18us/step - loss: 0.3749 - acc: 0.8427 - val_loss: 0.4128 - val_acc: 0.8209\n",
      "Epoch 1974/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3746 - acc: 0.8315 - val_loss: 0.4193 - val_acc: 0.8209\n",
      "Epoch 1975/2000\n",
      "623/623 [==============================] - 0s 10us/step - loss: 0.3747 - acc: 0.8411 - val_loss: 0.4127 - val_acc: 0.8209\n",
      "Epoch 1976/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3745 - acc: 0.8315 - val_loss: 0.4193 - val_acc: 0.8209\n",
      "Epoch 1977/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3746 - acc: 0.8411 - val_loss: 0.4128 - val_acc: 0.8209\n",
      "Epoch 1978/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3744 - acc: 0.8315 - val_loss: 0.4194 - val_acc: 0.8209\n",
      "Epoch 1979/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3747 - acc: 0.8427 - val_loss: 0.4126 - val_acc: 0.8209\n",
      "Epoch 1980/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3748 - acc: 0.8315 - val_loss: 0.4199 - val_acc: 0.8209\n",
      "Epoch 1981/2000\n",
      "623/623 [==============================] - 0s 16us/step - loss: 0.3750 - acc: 0.8427 - val_loss: 0.4127 - val_acc: 0.8209\n",
      "Epoch 1982/2000\n",
      "623/623 [==============================] - 0s 13us/step - loss: 0.3748 - acc: 0.8315 - val_loss: 0.4201 - val_acc: 0.8209\n",
      "Epoch 1983/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3750 - acc: 0.8443 - val_loss: 0.4129 - val_acc: 0.8209\n",
      "Epoch 1984/2000\n",
      "623/623 [==============================] - 0s 8us/step - loss: 0.3749 - acc: 0.8315 - val_loss: 0.4205 - val_acc: 0.8209\n",
      "Epoch 1985/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3750 - acc: 0.8427 - val_loss: 0.4131 - val_acc: 0.8209\n",
      "Epoch 1986/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3746 - acc: 0.8315 - val_loss: 0.4191 - val_acc: 0.8172\n",
      "Epoch 1987/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3746 - acc: 0.8379 - val_loss: 0.4132 - val_acc: 0.8209\n",
      "Epoch 1988/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3743 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8172\n",
      "Epoch 1989/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3745 - acc: 0.8379 - val_loss: 0.4130 - val_acc: 0.8209\n",
      "Epoch 1990/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3743 - acc: 0.8315 - val_loss: 0.4197 - val_acc: 0.8172\n",
      "Epoch 1991/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3746 - acc: 0.8363 - val_loss: 0.4130 - val_acc: 0.8209\n",
      "Epoch 1992/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3746 - acc: 0.8315 - val_loss: 0.4200 - val_acc: 0.8209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1993/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3749 - acc: 0.8427 - val_loss: 0.4128 - val_acc: 0.8209\n",
      "Epoch 1994/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3747 - acc: 0.8315 - val_loss: 0.4206 - val_acc: 0.8209\n",
      "Epoch 1995/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3750 - acc: 0.8443 - val_loss: 0.4131 - val_acc: 0.8209\n",
      "Epoch 1996/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3748 - acc: 0.8315 - val_loss: 0.4199 - val_acc: 0.8209\n",
      "Epoch 1997/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3748 - acc: 0.8427 - val_loss: 0.4127 - val_acc: 0.8209\n",
      "Epoch 1998/2000\n",
      "623/623 [==============================] - 0s 5us/step - loss: 0.3745 - acc: 0.8315 - val_loss: 0.4199 - val_acc: 0.8172\n",
      "Epoch 1999/2000\n",
      "623/623 [==============================] - 0s 3us/step - loss: 0.3746 - acc: 0.8395 - val_loss: 0.4130 - val_acc: 0.8209\n",
      "Epoch 2000/2000\n",
      "623/623 [==============================] - 0s 6us/step - loss: 0.3743 - acc: 0.8315 - val_loss: 0.4192 - val_acc: 0.8172\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model_dnn = models.Sequential()\n",
    "model_dnn.add(layers.Dense(10, activation='relu', input_shape=(11,)))\n",
    "model_dnn.add(layers.Dense(10, activation='relu'))\n",
    "model_dnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_dnn.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model_dnn.fit(train_X,train_Y,\n",
    "                   epochs=2000,\n",
    "                   batch_size=1024,\n",
    "                   validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEXCAYAAAD82wBdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcFNW9///XZ4ZlUGBYryKgaDIGcVdUNpHEDRdEo+PV+HMX4sOFoGbRmBADiUYToxcV0QSvIblxIeBXcIlREzGIuCNIBAc1CAgBRIZtBhjm8/ujaoaeZpbumV6q7ffz8egHXUtXfaq6qc+cU6fOMXdHREQkqgqyHYCIiEhjlKhERCTSlKhERCTSlKhERCTSlKhERCTSlKhERCTSlKgko8ysr5m5mfVP8nOrzez76YorUzJxHGZWFJ7j85LZr5k9bmbPpGD/w8P9d2vpthLYV0pilmhrle0AJFrMrKkH65a5e58W7KIM6AGsS/JzhwJbWrDffJfy82dmrYAdwIXu/njMor8TfMdfpHJ/kr+UqCRej5j3xwJPh/8uD+ftrO9DZtbG3bc3tXF33wmsTjYod1+b7Gdkl0yev/B3kPR3LNIQVf1JHe6+uuYFrA9nr42ZvxZqq5J+ZmYPm9l64OVw/vfNbIGZbTGzz83sT2b2XzXbj6/6i5n+tpk9b2ZbzWypmf13bFzxVVfh9K1m9oCZbQin7zCzgph19jSzR8xso5mtN7OJZna3mX3Q2DlI4Bhqqra+aWavmVmFmS00s2/GbedoM3vDzLaZ2WIzO7uJ/XYN1/123Pw+ZlZtZsPC6UvN7K3wuNaa2Uwz+1oT244/f93NbHp4vleb2bh6PnO6mb0anrsNZvZ3MzsqZpUV4b+PheejMu78dIvZ1hAzm2NmleH2pppZ15jlvzKzD8ys1Mw+MrPNZvaSme3X2HHVE7OZ2S1m9m8z2x7+lq6NW+c8M3s/PPYvzex1MzskXNY2/J2sDL+Lz83sD8nEIKmnRCUtcROwDDgOGB3OqwbGAocApcCBwB8T2NadwO+Aw4BZwNQELlI3AZ8AxwA/AH4IxCa4e4BTgQuAQQTVVFclEEuix/Ab4DbgcGARMM3M2gOYWQfgeWBVGN9VwE+BTg3t1N2/AJ4DLo1b9P8BnwGzw+k2wM+AI4HhQGtgZlgVl6ipwMHAacBJ4bGeHrfOnsC9BN/vEILE9FczKw6XHxn+ezVBSbze78vMegMvAEuB/sA5BOfk8bhV9wMuI/gOhwJ7Aw8ncUwANwI/AX4eHt+9wD1mdlEYy77hfh8Jlw8GJrGrpuAmYARwIVACnA28nWQMkmrurpde9b4ILk4O9Kln2Wrg2QS2MTDcRtdwum843T9u+pqYz7QBtgGXxu3v+3HTT8bt6xXgf8P3nQkS00Vx67wHfJDkeYg/huHh9Okx6/QJ550QTl8HbAA6xKzTP1zn+43s62xgO9AtZt4SYEIjn+kRbvfocLoonD6vvvNHkJQcOD5meTtgDfBMI/tpRXCf69yYaQcuiFuv5vx0C6d/TfAHRauYdY4L1zk2nP5V+J13jlnnsvA7LGwkpsdjYwbWAuPj1nkQ+FfMd1kN9Ghgew8R/IFhmf7/plfDL5WopCXejJ9hZieZ2YtmttzMNgEvhYuaKh3Nr3njwT2OdcBeiX4mtDLmMwcSXEjnxa0TP72bJI4hdv8rw39r9t8PWOjum2pWcPe3gYomdv8ssJHgL3rM7LjwWKbGxHe0mT0dVm9tImigUl98DelHcLGuPRfuXgG8G7uSmZWY2Z/N7GMz20iQeNslsZ8aBwNz3b0qZt6bQGW4rMYyd/8yZnolwXfYlQSE1bPdgFfjFs0GSsysNfBWOL0krPq83sx6xqz7e4J7sh+Z2SQzOyf8nGSREpW0RJ1WZGb2deAZghLAfxOUIErDxW2a2FZ8Qwyn6d9nIp9JaniAJI8hdv81+6nZvzWwb2ts/+6+A3gMuCScdQnwuruXhfEVAy8SXOQvJahCG9RAfA1pNIYYzxMk3quBAcARQHkS+4nV0PcQO7++7xOSv07F76v2eMNk+S3gFILS9QVAmZmdHC5/i6B0fDNBMn8AeNvM9kwyBkkhJSpJpeMI7peMdfe57r6E4D5DNnwEVBFU9cQa0MTnUnUMi4DDau5ZQVASIqiWa8pUoL+ZHUaQLGNv5h9CUK15s7vPdvfFBKWIZGMrIOZcmFkRcFTMdE/ga8Av3P1Fd/8XwYU79h7bzvBVmMD+BsfdQzuW4FwsSjL2Brn7GoKqvxPiFg0FPgr/CMAD89z9F+4+mKB0d1nMdja5+3R3v47gj4DD2PXHgGSBEpWk0kcEv6kbzGx/MzsXuCUbgYRVSP8L3Glmp5nZN8zs18D+NF7KStUx/IHg/spUMzvUzAYDkwnuwzQV+1vAv8JttAeeiFn8abjdMWZ2gJmdQnAPKGHu/gHwN+AhMxtqZgcDj1I3ia4hqOr7blgFOJigQUllzHacoDHNt8ysR2wrvjj/Q1Ay+72ZHWxmJxB8Ny+Fx5pKvwJuMrPLw7ivA64Ebgcws2Fm9mMzO9bM9g3PXz+C803YYvBCM+tnZgcAlxOc76UpjlOSoEQlKRNedG4EvkfwH/964IYshnQDQTXZkwT3Y9oCfybmYhsvVccQ3ps6HehF0GrsUeAOgot/IqYSVLXNcvfaz7j75wRVfmeF8d3enPiAi4HFwF8JHtBdQtDisGY/OwiqPA8BFhK0yLyT3R/iHUvQ6GYZu+7T1eHuKwhaX5YA7wBPEZyTC5oRd1PuAX5J0CpyURjfDe7+f+HyLwlKWLMI7u09DEwhODaAzQStR98A3idoGHK2u3+ahlglQRb8USSSH8xsLvCpu1+U7VhEJDHqmUK+sszsSIJWZW8QVGtdQXDP6tZsxiUiyVGikq+6MQTPagF8CJzh7v/IYjwikiRV/YmISKSpMYWIiERaTlX9lZeXq/gnIvIVV1xcXOehdJWoREQk0pSoREQk0vIyUZWVlTW9UgTkSpygWNMlV2LNlThBsaZDuuPMy0QlIiK5Q4lKREQiLSOt/sIRPqcS9EJdDTzs7v8Tt44RdF55OrAVuMzd343flohIPHdn8+bNVFdXN7luUVER5eXlGYiq5XIl1mTjLCgooH379gSX/aZlqnl6FXCTu78bDtH9jpnVDB1Q4zSCTitLCIZaeDD8V0SkUZs3b6Zt27a0adP0UFlt27alqCiR0VayL1diTTbO7du3s3nzZjp06JDQ+hmp+nP3VTWlo7BX6Q+BnnGrjQSm1owVA3Qysx6pjGPatNYcemgHjj32aA49tAPTpmngTpGvgurq6oSSlERDmzZtEir91sj4A79m1gc4kqCj0Fg9geUx0yvCeatSsd9p01ozZkw7KiqCouby5caYMe0AKC3dkYpdiIhIGmS0r79wtNPZwC/dfUbcsmeBO9x9Tjj9MvBDd3+nZp3YnimSbQ45YsShrF7ddrf5e++9jVmzFia1LRGJlqKiIrp37561/a9fv57S0lIA1qxZQ2FhIV27BuNIPv/88wmV9r73ve9x/fXX8/Wvf73BdR555BGKi4s599xzWxzzWWedxe23384hhxzS4m01x9q1a6ms3DU0XElJSe37+J4pMpaozKw18Azwgrv/tp7lDwGvuPtj4fQSYJi715aoWtKFUufOHXHf/cadmfPllxubu9m0Kisrq/PlRZliTY9ciTXbcZaXl1NcXJzQupWVlcya1YHx44tYscLo1csZN64yZTUrd9xxB+3bt+f666+vM9/dcXcKChK/41JZWZm2e1TDhw/nrrvu4rDDDmvxtpoTZ2PfWVa6UApb9E0BPqwvSYVmApdYYABQHpukWqpXr/pzXEPzReSrafr0IsaMacfy5QW4G8uXFzBmTLu03LP+5JNPGDhwIDfccANDhw5l9erVfO9732PYsGEMGDCAO++8s3bd4cOHs2DBAqqqqth333257bbb+Na3vsXJJ5/M2rVrAfjFL37BpEmTatevWad///688UZwN2XLli1cfPHFDB48mCuvvJJhw4axYMGCRuN84oknGDRoEAMHDmT8+PEAVFVVMXr06Nr5kydPBuCBBx7guOOOY/DgwYwePTrl56w+mbpHNZhg6OuFZjY/nPdjYF8Ad59MMAz26cBSgubpl6cygHHjKuvcowJo1y74S0pE8scdd7Svcx0AqKgwxo8vSsv96sWLF/PAAw9wzz33AHDbbbfRuXNnqqqqGDFiBCNHjqRv3751PrNx40YGDx7MzTffzPjx4/nTn/7EDTfcsNu23Z2///3vPPfcc9x1111Mnz6dhx9+mL322os//vGPLFy4kBNOOKHR+FauXMkvfvELXnnlFTp27MjIkSP561//Srdu3Vi/fj1z584FYMOGDQBMnDiRhQsX0qZNm9p56ZapVn9z3N3c/TB3PyJ8Pefuk8MkRdja71p3/5q7H+rub6cyhtLSHUycWEHv3tWYOb17VzNxYoUaUojkmZUr67/srViR2DM9ydp///056qijaqf/8pe/MHToUIYOHcqSJUtYsmTJbp9p164dJ598MgBHHHEEn332Wb3bHjFixG7rzJs3j29/+9sAHHroobslwXhvv/02Q4cOpWvXrrRu3ZrS0lLmzp3LAQccQFlZGT/60Y94+eWXa6vp+vbty+jRo3nyySdp3TozLafzqmeK0tIdLFy4iTfffIeFCzcpSYnkoZ49628Wna7bAHvssUft+48//pjJkyczc+ZM5s6dy0knnVSnQUGN2ARQWFhIVVVVvduuaaQRu06q2h106dKF1157jYEDB/LQQw8xduxYAGbMmMHll1/OO++8wze/+U127tyZkv01Jq8SlYjILbdspl27uhfzTN0G2LRpE+3bt6djx46sXr2al19+OeX7GDBgAE899RQAixYtqrfEFqt///7885//ZP369VRVVTF9+nQGDx7MunXrcHfOPvtsbrnlFt5//3127tzJypUrOeGEE5gwYQLr1q1j69atKT+GeDk1cKKISEude24lbdq0Tlurv8YcfvjhfOMb32DgwIH06dOH445Lfec7o0eP5uqrr2bQoEEcfvjhHHTQQXTs2LHB9Xv27MmPf/xjzjzzTNyd4cOHc+qppzJ//nyuv/563B0z4+c//zlVVVWMGjWKTZs24e6MHTuWDh061FsqTKWMPkfVUqka4TfbTWkTlStxgmJNl1yJNdtxJts8PRe6JYLmxVpVVUVVVRVFRUV8/PHHnHPOObz77ru0apW+ckm6m6erRCUi8hWyefNmRo4cSVVVFe7Ovffem9YklQm5Hb2IiNTRqVMnZs+ene0wUkqNKUREJNKUqEREJNKUqEREJNKUqEREJNKUqEREWuiMM87Y7eHdSZMmcdNNNzX6uZ49g/FjV61axSWXXNLgtt97771GtzNp0qQ6D96WlpampB++O+64g/vuu6/F22kpJSoRkRY677zzmD59ep15M2bMSHjcqB49ejB16tRm7//BBx+koqKidnratGl06tSp2duLGiUqEfnK6dSpuMHX3nvv1ejy+l5NGTlyJC+88ALbtm0DYNmyZaxevZqBAweyefNmzjrrLIYOHcqgQYN49tlnd/v8smXLGDhwIAAVFRVcccUVDBo0iNGjR9fp9eHGG2+sHSLk9ttvB2Dy5MmsXr2aESNGcOaZZwJBZ7RffPEFAPfffz8DBw5k4MCBtUOELFu2jGOPPZYxY8YwYMAAzjnnnDqJrj4LFizgpJNOYtCgQVx00UW1JbbJkydz/PHHM2jQIK644goA5syZw5AhQxgyZAjHH388mzZtavIcNkaJSkSkhbp06cLRRx/NSy+9BASlqXPOOQczo6ioiD/96U+8+uqrzJo1i5/85CeNdhw7ZcoU2rVrx9y5cxk7dizz58+vXfbTn/6UV155hddee43XXnuNDz74gKuvvpq9996bWbNm8cwzz9TZ1vz58/nzn//MSy+9xIsvvsjUqVN5//33gaCD3Kuuuop58+ZRXFzMzJkzGz3Gq6++mttuu425c+fSr18/fvWrXwFw77338tJLLzF37lx++9tguMH77ruP3/zmN8yZM4fnn3+edu3aJX9SYyhRiYikwLnnnsuMGTMAmD59em21n7szYcIEBg0axMiRI1m1ahVr1qxpcDtz587l/PPPB6Bfv34cfPDBtcueeuophg4dyvHHH8/ixYub7HD29ddf54wzzmDPPfekffv2nHnmmbz++usA7LfffrWj+zY2lAgE3R1t3LiRIUOGAPCd73yndpyqgw8+mGuuuYYnnniitgeMAQMGcOuttzJ58mTKy8tb3DOGEpWISAqcccYZzJ49m/nz51NZWckRRxwBwJNPPsm6deuYPXs2c+bMoXv37k124hoMil7Xv//9b+67777aIUJOOeWUJrfTWMmtbdu2te8bG0qkKU8++SSXX3458+fPZ9iwYVRVVXHDDTcwceJEKisrOfnkk/noo4+ate0amRqK/hEzW2NmHzSwvNjMZpnZ+2a2yMxSOrqviOSXDRvKG3ytXv2fRpfX90pE+/btGTJkCNddd12dRhQbN26kW7dutG7dmldffZXly5c3up1BgwYxbdo0AD788EMWLVoEBEOE7LHHHnTs2JE1a9bUVjMCdOjQod77QDX3xLZu3cqWLVt49tlna++FJaO4uJji4uLaUtTjjz/O4MGDqa6uZsWKFQwZMoTx48dTXl7O5s2b+fTTTzn44IMZO3YsRxxxRIsTVab6+nsUuB9oqFnLtcC/3H2EmXUHlpjZ/7n79gzFJyLSYueeey4XX3wxjzzySO28888/nwsuuIBhw4Zx6KGHcuCBBza6jSuvvJJrr72WQYMG0a9fP44++mggaCBx2GGHMWDAgN2GCLn00kspLS1lr732qnOf6ogjjuA73/kOJ554IgAXX3wxhx9+OMuWLUv62B588EFuvPFGtm7dSp8+fZg0aRI7d+7ku9/9Lhs2bMDMuOaaa+jUqRO//OUvmTNnDgUFBfTt27d2tOLmytgwH2bWB3jG3Q+pZ9ktQG+ChNUHeBE40N3rDMWpYT6iS7GmR67Emu04NcxHdqV7mI+oJKoOwEygL9AB+G93360NZ2yiKisrS1usIpJbioqK6N69e7bDkCSsXbu2zj222D90ojoe1anAfOBbwNeAF83sn+6+saEPtOSvt2z/9ZeoXIkTFGu65Eqs2Y6zvLw84b/oc6WUArkTa3Pi7NixI717905o3ai0+rscmOGBpcCnBKUrERHJc1FJVJ8BJwKY2V7AN4BPshqRiIhEQkaq/szsMWAY0M3MVgA/A1oDuPtkYALwqJktBAz4kbuvy0RsIpL7CgoK2L59O23atMl2KJKA7du3U1CQeDkpI4nK3S9sYvnnwCmZiEVEvnrat2/P5s2bm+yvDoLnmjp27JiBqFouV2JNNs6CggLat2+f8PpRaUwhItJsZkaHDh0SWnfNmjUJ38TPtlyJNd1xRuUelYiISL2UqEREJNKUqEREJNKUqEREJNLyJlFVVsL997ehb98OHHPM0Rx0UAemTWud7bBERKQJedPqb+LEttx++64uPlatMsaMCUadLC3dka2wRESkCXlTopoyZfcHASsqjPHjo9+PlohIPsubRPWf/+w+YibAihX1zxcRkWjIm0S11171D2fSq1dmhjkREZHmyZtEdfXV23ab166dM25cZT1ri4hIVORNojr11Ko6061aORMnVqghhYhIxOVNoiosrDt9wAHVSlIiIjkgbxJVfI/y1dXZiUNERJKjRCUiIpGWkURlZo+Y2Roz+6CRdYaZ2XwzW2Rms1MdgxKViEhuylSJ6lFgeEMLzawTMAk4y90PBkpTHYBZ3Wbo1dV6fkpEJBdkJFG5+6vA+kZW+Q4ww90/C9dfk+oYVKISEclNUblHdSDQ2cxeMbN3zOySVO8gPlG5nvMVEckJ5hm6YptZH+AZdz+knmX3A/2BE4F2wOvAGe7+Uex65eXltcGWlZUltf81a1pzxhmH105367ad559fkNQ2REQkPUpKSmrfFxcX17k3E5Xe01cA69x9C7DFzF4FDgc+augDsQeViA4d6t6TKiholfQ2Mq2srCzyMdZQrOmRK7HmSpygWNMh3XFGpervaeB4M2tlZnsAxwEfpnIH8Q/86h6ViEhuyEiJysweA4YB3cxsBfAzoDWAu0929w/N7K/AAqAa+L27N9iUvTnUmEJEJDdlJFG5+4UJrPNr4NfpikGJSkQkN0Wl6i/t9ByViEhuyptEpebpIiK5KW8Tlar+RERyQ94mqp07sxOHiIgkJ28TlUpUIiK5IW8SlZ6jEhHJTXmTqOJLVFVVMG1a6+wEIyIiCcubRDV9enxSMsaMaadkJSIScXmTqCZMKNptXkWFMX787vNFRCQ68iZRrVhR/wO+Dc0XEZFoyJtE1atX/U/4NjRfRESiIW8S1bhxlUDdpFRU5OF8ERGJqrxJVKWlO2gd127iN7+poLR0R3YCEhGRhORNogJ2S1Rnn60kJSISdXmVqPTQr4hI7slIojKzR8xsjZk1OhiimR1jZjvN7Lz0xFF3WolKRCT6MlWiehQY3tgKZlYI3Am8kK4gCgrqNqZwV9N0EZGoy0iicvdXgfVNrHY9MB1Yk6441DGtiEjuicQ9KjPrCZwDTE7nfpSoRERyj3mGhro1sz7AM+5+SD3LpgF3u/s8M3s0XO8v8euVl5fXBltWVpZ0DKeeejjr1+9q+vf88/Pp1q0q6e2IiEhqlZSU1L4vLi6uc1+mVcajqV9/4HELWjt0A043syp3/38NfSD2oBLVpk3dZn/77XcA++wT3Z4pysrKmnWc2aBY0yNXYs2VOEGxpkO644xEonL3/Wvex5SoGkxSzaWqPxGR3JORRGVmjwHDgG5mtgL4GdAawN3Tel8qlhKViEjuyUiicvcLk1j3snTFoUQlIpJ7ItHqL1P0HJWISO7Jq0S1dWvdxPTss5G4RSciIo3Im0Q1bVpr1q6tm6gmTCjSUPQiIhGXN4lq/Pii3ar6tm3TUPQiIlGXN4lKQ9GLiOSmvElUGopeRCQ35U2iGjeuErO6SaltWw1FLyISdXmTqEpLd9C7d91E9YMfVGooehGRiMubRAXQpUvdJ3xPPHFnliIREZFE5VWiUs8UIiK5R4lKREQiTYlKREQiLeFEZWY3mtkR4fsBZvaZmX1iZgPTF15qKVGJiOSeZEpUNwCfhu/vAH4L/BK4N9VBpYvFPdu7U20pREQiL5leWYvdvdzMOgCHAye5+04zuztNsaWcSlQiIrknmUS13MwGAQcDr4ZJqiOQM+WSwroj0ePqlEJEJPKSqfr7AfAX4FZgQjjvTODNpj5oZo+Y2Roz+6CB5ReZ2YLwNdfMDk8iroTF957+yisa5kNEJOoSTlTu/py77+Pufdz9nXD2NOCsBD7+KDC8keWfAie4+2EESfDhRONK1LRprVmypO7hPvBAWw3zISISccm0+utnZnuF79ub2c+BW4Amr/Tu/iqwvpHlc939y3ByHtAr0bgSNX58EdXVdUtU27drmA8RkahLpurvz0Cn8P1vgKHAQOChFMd0JfB8irepYT5ERHKUeYItCsxsg7t3MjMDVhM0qqgAPnX3/0rg832AZ9z9kEbW+SYwCRji7l/ELy8vL68NtqysLKG4a4wYcSirV7fdbf7ee29j1qyFSW1LRERSq6SkpPZ9cXFxnRJEMq0JtoVN0/sBy919nZm1AlJSd2ZmhwG/B06rL0nFiz2oREyYsJPvftfrVP+1aeNMmLAz6W1lSllZWWRji6dY0yNXYs2VOEGxpkO640y26u/vwB8IGkcAHMWuh4Cbzcz2BWYAF7v7Ry3dXn1KS3dw1FF1W9Jfdtl2DfMhIhJxCZeo3P0GMzsF2OHu/whnVxP0WNEoM3sMGAZ0M7MVwM8IG2G4+2RgHNAVmBTULFLl7v2TOI6E7L9/NW+/vWu6f/+ceQRMRCRvJfUgkbv/zcz2Dfv3W+nubzf5oeBzFzax/CrgqmRiaY74B353qDAlIhJ5yTRP72Fms4Eygmq6pWY228z2SVt0KdYqLi2rrz8RkehL5h7Vg8D7QBd37wF0BuYDk9MRWDq0alW3hWNVlZqmi4hEXTJVf0OAHu6+A8Ddt5jZD4GVaYksDVrHPZpcVZWdOEREJHHJlKi+JGiaHusbwIbUhZNe8feolKhERKIvmRLVXcBLZjYFWAbsB1wO/DQdgaVD/D2qO+9sS/furibqIiIRlkyntL8D/hvoBowI/72YNPTLly5Ll9Y93PLyAsaMaaeOaUVEIizZ5ul/J3joFwAza0vQL9+4FMeVFnPn7n64FRVBx7QqVYmIRFMy96gakjNN5zZurH++OqYVEYmuVCSqnBknt2PH+kPt1StnDkFEJO80WfVnZt9qZHGbFMaSdiedVMWMGXVDbtfOGTeuMksRiYhIUxK5RzWlieWfpSKQTDjyyJ3MmLFrun175557KnR/SkQkwppMVO6+fyYCyYT456guuki9p4uIRF0q7lHljPieKdTXn4hI9OVVoop/4Fc9U4iIRF9eJarCwrqt+6ZNa6OHfUVEIi4jicrMHjGzNWb2QQPLzcwmmtlSM1tgZkelI4733qt7k2rLFlPPFCIiEZepEtWjwPBGlp8GlISv0QRDiqTc00/vnpBqeqYQEZFoykiicvdXgfWNrDISmOqBeUAnM+uR6jjWr6+/Bwr1TCEiEl1RuUfVE1geM70inJdSXbuqZwoRkVyTVKe0aVRfkabR7FFWVpb0Tk45pRePPbZ3nXlFRTsZNWoZZWWNFfiypznHmS2KNT1yJdZciRMUazq0NM6SkpIGl0UlUa0AesdM9wI+b+wDjR1UQ84+uxWPPbZruqjIue++bZSWdgW6Jr29dCsrK2vWcWaDYk2PXIk1V+IExZoO6Y4zKlV/M4FLwtZ/A4Byd1+V6p3EP0c1cGCVeqYQEYm4TDVPfwx4HfiGma0wsyvN7Gozuzpc5TngE2Ap8DvgmnTE0apV3drEuXNbqWm6iEjEZaTqz90vbGK5A9emO445c+oe7rZtwXNUgEpWIiIRFZWqv4z4wx92H5VEz1GJiERbXiV6CMq5AAASD0lEQVSqNWv0HJWISK7Jq0S11156jkpEJNfkVaK65pptu83TCL8iItGWV4lq5Mi6DSYKC52JEzXCr4hIlOVVomrbtu60q8ZPRCTy8ipRvfBC3ebp1dUa5kNEJOryKlH9+te7N0NX83QRkWjLq0S1cqWap4uI5Jq8SlS9e6t5uohIrsmrRBU0Q6+blFq1UvN0EZEoy6tEVR9TrZ+ISKTlVaIKGk3UzUw7dqgxhYhIlOVVomqo0YQaU4iIRFdeJarOnetvNNHQfBERyb68SlQiIpJ7MpaozGy4mS0xs6VmdnM9y/c1s3+Y2XtmtsDMTk91DF9+WX8V3/r1qvoTEYmqTA1FXwg8AJwG9AMuNLN+cav9BHjS3Y8ELgAmpTqOhp6XMkPdKImIRFSmSlTHAkvd/RN33w48DoyMW8eBjuH7YuDzVAdR33NUAO5q+SciElXmGehC3MzOA4a7+1Xh9MXAce5+Xcw6PYC/AZ2BPYGT3P2d2O2Ul5fXBltWVtasWI455mjim6gH+3fefPOd3T8gIiJpV1JSUvu+uLi4zkW61W5rp0d9N4HiM+SFwKPufreZDQT+aGaHuHt1fRuMPahkFBVBZT0dUXTu7M3eZrqUlZVFLqaGKNb0yJVYcyVOUKzpkO44M1X1twLoHTPdi92r9q4EngRw99eBIqBbqgPZubP+EuS23Qf/FRGRCMhUonoLKDGz/c2sDUFjiZlx63wGnAhgZgcRJKq1qQ5kx476W/ht2aKWfyIiUZSRROXuVcB1wAvAhwSt+xaZ2XgzOytc7SZglJm9DzwGXOaZuIEmIiKRlql7VLj7c8BzcfPGxbz/FzA4U/HUZ9q01pSW7shmCCIiEkc9U9Qyrr1WTdRFRKIm7xJVQSNHvH276cFfEZGIybtEdfnl26nvod+AMWqUSlUiIlGSd4nq7rubGs3X6NKlQ0ZiERGRpuVdomqaUV1t9OihZCUiEgV5maiOOmojDVf/ARgVFcZBB7XPVEgiItKAvExUDz1URmFhU49oGatWFTBy5B4ZiUlEROqXl4kK4IsvNtF4qQrAmD27lVoCiohkUd4mKoCHH64gkWSlloAiItmT14nq/PN3MHRoFYkkK92vEhHJjrxOVAAzZ25l772raapxxapVBdx0k0pWIiKZlveJCmDx4s107Og0laymTGmj+1UiIhmmRBX67LNNCaxljBrVTslKRCSDlKhi/O53alwhIhI1SlQxSkt30LfvThJJVt27q+cKEZFMyFiiMrPhZrbEzJaa2c0NrHO+mf3LzBaZ2Z8zFVusefO20K5d0/erduxQshIRyYSMJCozKwQeAE4D+gEXmlm/uHVKgFuAwe5+MDA2E7HVZ9WqmoeBlaxERLItUyWqY4Gl7v6Ju28HHgdGxq0zCnjA3b8EcPc1GYqtXhs2JNa4QslKRCS9MpWoegLLY6ZXhPNiHQgcaGavmdk8MxueodgadOWVjY1dVUPJSkQkncy9qQtxCnZiVgqc6u5XhdMXA8e6+/Ux6zwD7ADOB3oB/wQOcfcNNeuUl5fXBltWVpb2uAHOP78fn37aDrAm1nQKC6uZN++9TIQlIvKVUlJSUvu+uLi4zgW3VYZiWAH0jpnuBXxezzrz3H0H8KmZLQFKgLfq22DsQSWrrKws4c+/994ORo5szezZrWg8WRk7dxYwdOhR4T2ulksmzmxTrOmRK7HmSpygWNMh3XFmqurvLaDEzPY3szbABcDMuHX+H/BNADPrRlAV+EmG4mvU009v5YQTEusTsKLCGDBgz0yEJSKSFzKSqNy9CrgOeAH4EHjS3ReZ2XgzOytc7QXgCzP7F/AP4Afu/kUm4kvE009vTfgZq8WLCzWOlYhIimSq6g93fw54Lm7euJj3DtwYviJp3rwtDBiwJ4sXF9JUNeDs2a046KD2fPjh5kyFJyLylaSeKZI0b96WhEtWq1YVqDWgiEgLKVE1QzLJascOo1OnjurIVkSkmZSommnevC306NHUOFYQVBEGva5r8EURkeQpUbXAhx9uTqBfwBpBVWCnTh3V0EJEJAlKVC20atUmWrdOPFnVNLTo1KmjRgwWEUmAElUKrF27KYmSFdQkrClT2ihhiYg0QYkqRVat2pRgA4tYdROWHhQWEdmdElUKzZu3JRwlOJFGFrGChLV4cSGdOnVUKUtEJIYSVYqVlu5gw4ZkqwJrGLGlrGOOOVqNL0Qk7ylRpcmqVZtihglpTg/1u5JWTeOLmpeauYtIPlGiSqO7765kw4aNMR3aNndIFavzqmnmXt9LVYYi8lWTsb7+8tnTT28FiOknEJoe36oxDX92ypQ2TJnSpskt9O27k3nztrQgBhGRzFCiyqCaxJC6hFWfxLa3eHErOnUqJtFSXkEBPPRQBaWlO1oQm4hI8pSosqAmYd10U1Fc6SfVSSsRie2zuhpGjdqDUaPqW+rA0Q1+VqU3EWkJJaosuvvuSu6+uxKIL2VBdpJWczUe667SW3M4nTo5t966jZKSneyzj9O9u9OundO2LVgunSaRLPCYSpPY/y+x8ysqdi0zg+3bobAQKiuNigqoqoKKCqNtW1izxujRo5rFiwvZa69qVq8uoGvX2GtX6ilRRURsiWP3khbkVuJKJWPDBuMHP2iXwm32b3RpUZFTUlLN1762k169nH32qaZHD6dr12q6dHE6dw6S5B57OK1bB9WiBQVfvaRZcyEzg507obIStm0zCgu99qJVXR1c1NasaU2XLkZ1NeGFzdi4Mfh8q1a7LnTV1cH7ykrjk08KWLAguNh9/nkBRUXw9tuFFBU57sG+Kivhiy8K2L4dtm2D6upUnOTGv/9oyZVYj+Scc7bzv/9bkZatm3tzW6IluSOz4cD/AIXA7939Vw2sdx4wDTjG3d+OXVZeXp6SYMvKyigpKUnFptKqJs5p01ozalQRDSerr9gVUkRy0scfb6Rr15ZfpouLi+tc1DLSPN3MCoEHgNOAfsCFZtavnvU6AGOANzIRV66oeYh4w4aNu712dduUyEtEJH3eeCM9VYCZqvo7Fljq7p8AmNnjwEjgX3HrTQDuAr6fobhyXqKNFOqvTkyESmsikpjjjtuZlu1mpOovrM4b7u5XhdMXA8e5+3Ux6xwJ/MTdzzWzV4DvN1b1V1ZWlva4891ppx3KunXNSW6gBCeSb5z27av4xz/eb9anY2/HxFf9ZapEVd9VqzbpmFkBcA9wWaIbbMk9ply7R5UtS5dWApUJrRsba/NLb7GU6ERyi7F5cytOOukoli3blNItZypRrQB6x0z3Aj6Pme4AHAK8YkHTqb2BmWZ2VnypSqIvttl9c6Qm0cVT4hNJP6O8PPVbzVSiegsoMbP9gZXABcB3aha6eznQrWa6oao/yQ8tTXTxRo7cg9mzs1l5ICItkZH/ve5eZWbXAS8QNE9/xN0Xmdl44G13n5mJOCQ/1fS1WCNdVapNP0aQLVGLRyQ5GXvg192fA56LmzeugXWHZSImkVQqLd2R8r4QW5pUM1uazBQl3uhyiotT30Dvq/YLFpEY8aXJdMlUw5/03L+UVCku9pQ3pAAlKhHJIam4f5nt1rTJyJVY0x2nBk4UEZFIU6ISEZFIU6ISEZFIU6ISEZFIy9gwH6mQqmE+REQkurIyzIeIiEhzKVGJiEik5VTVn4iI5B+VqEREJNLyKlGZ2XAzW2JmS83s5gjE09vM/mFmH5rZIjP7Xjj/NjNbaWbzw9fpMZ+5JYx/iZmdmsFY/21mC8N43g7ndTGzF82sLPy3czjfzGxiGOcCMzsqg3F+I+a8zTezjWY2Nirn1MweMbM1ZvZBzLykz6OZXRquX2Zml2Yw1l+b2eIwnqfMrFM4v4+ZVcSc38kxnzk6/O0sDY8npZ31NRBn0t93Jq4PDcT6REyc/zaz+eH8rJ3TcB8NXZ8y/3t197x4EfTa/jFwANAGeB/ol+WYegBHhe87AB8B/YDbCIY5iV+/Xxh3W2D/8HgKMxTrv4FucfPuAm4O398M3Bm+Px14nqD30AHAG1n8zlcD+0XlnAJDgaOAD5p7HoEuwCfhv53D950zFOspQKvw/Z0xsfaJXS9uO28CA8PjeB44LQNxJvV9Z+r6UF+sccvvBsZl+5yG+2jo+pTx32s+laiOBZa6+yfuvh14HBiZzYDcfZW7vxu+3wR8CPRs5CMjgcfdfZu7fwosJTiubBkJ/CF8/wfg7Jj5Uz0wD+hkZj2yEN+JwMfuvqyRdTJ6Tt39VWB9PTEkcx5PBV509/Xu/iXwIjA8E7G6+9/cvSqcnEcwCGqDwng7uvvrHly1prLr+NIWZyMa+r4zcn1oLNawVHQ+8Fhj28jEOQ1jbej6lPHfaz4lqp7A8pjpFTSeFDLKzPoARwJvhLOuC4vPj9QUrcnuMTjwNzN7x8xGh/P2cvdVEPyogf+KQJyxLqDuf/qondMayZ7HKMQMcAXBX9A19jez98xstpkdH87rSRBfjUzGmsz3HYVzejzwH3cvi5kXiXMad33K+O81nxJVfXW4kWjyaGbtgenAWHffCDwIfA04AlhFUB0A2T2Gwe5+FHAacK2ZDW1k3ayfazNrA5wFTAtnRfGcNqWh2LIes5ndClQB/xfOWgXs6+5HAjcCfzazjmQv1mS/76yfU+BC6v5hFYlzWs/1qcFV65mXknObT4lqBdA7ZroX8HmWYqllZq0JfgT/5+4zANz9P+6+092rgd+xqyoqa8fg7p+H/64Bngpj+k9NlV7475psxxnjNOBdd/8PRPOcxkj2PGY15vBm+JnARWHVE2FV2hfh+3cI7vccGMYaWz2YkVib8X1n+5y2Ar4NPFEzLwrntL7rE1n4veZTonoLKDGz/cO/ti8AZmYzoLBOegrwobv/NmZ+7P2cc4CaFkIzgQvMrK2Z7Q+UENxUTXece5pZh5r3BDfUPwjjqWnBcynwdEycl4StgAYA5TVVBRlU56/TqJ3TOMmexxeAU8ysc1ildUo4L+3MbDjwI+Asd98aM7+7mRWG7w8gOI+fhPFuMrMB4e/9kpjjS2ecyX7f2b4+nAQsdvfaKr1sn9OGrk9k4/ea6pYiUX4RtEr5iOAvk1sjEM8QgiLwAmB++Dod+COwMJw/E+gR85lbw/iXkIaWPg3EeQBBK6j3gUU15w7oCrwMlIX/dgnnG/BAGOdCoH+Gz+sewBdAccy8SJxTguS5CthB8Jfmlc05jwT3h5aGr8szGOtSgvsNNb/XyeG654a/jfeBd4ERMdvpT5AoPgbuJ+xoIM1xJv19Z+L6UF+s4fxHgavj1s3aOQ330dD1KeO/V/VMISIikZZPVX8iIpKDlKhERCTSlKhERCTSlKhERCTSlKhERCTSlKhEcpSZuZl9PdtxiKSbEpVIilgwREOFmW2Oed2f7bhEcl2rbAcg8hUzwt1fynYQIl8lKlGJpJmZXWZmr5nZfWZWbsHAgyfGLN/HzGaa2fpw0LlRMcsKzezHZvaxmW0Ke6+P7TftJAsGo/vSzB4Iu73BzL4e9rhdbmbrzOwJRHKUSlQimXEc8BegG0HnozPMbH93X0/Qrc4iYB+gL/CimX3i7i8T9Jp9Ibu69zkM2Bqz3TOBY4COwDvALOCvwATgb8A3CQYC7J/uAxRJF3WhJJIiZvZvgkRUFTP7BwT9ut0O9PSaTtHM3gTuA14hGD25kweD02FmdxD0TXeZmS0Bfujuu3U6amYOHO/uc8LpJwl6jP+VmU0FKoHxHtPRqUguUtWfSGqd7e6dYl6/C+ev9Lp/FS4jKEHtA6yvSVIxy2oGlutN0MlnQ1bHvN8KtA/f/5Cgk9A3zWyRmV3RzOMRyTolKpHM6Flz/yi0L8GYPJ8DXWqGUYlZtjJ8v5xgAMCkuPtqdx/l7vsA3wUmqSm75ColKpHM+C9gjJm1NrNS4CDgOXdfDswF7jCzIjM7jGCYipqRc38PTDCzknCcn8PMrGtTOzOzUjOrGVzvS4LhGnam+qBEMkGNKURSa5aZxSaEFwkGlnuDYOC7dcB/gPM8HL2VoLHEZILS1ZfAz9z9xXDZb4G2BA0jugGLCQYCbMoxwL1mVhzu73vu/mlLDkwkW9SYQiTNzOwy4Cp3H5LtWERykar+REQk0pSoREQk0lT1JyIikaYSlYiIRJoSlYiIRJoSlYiIRJoSlYiIRJoSlYiIRJoSlYiIRNr/D8ydVz0ZDBboAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values=history_dict['loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "\n",
    "epochs=range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo' , label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo' , label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04147565]\n",
      " [0.32228094]\n",
      " [0.07412118]\n",
      " [0.09810862]\n",
      " [0.4495818 ]\n",
      " [0.10209438]\n",
      " [0.71494246]\n",
      " [0.17137262]\n",
      " [0.7477031 ]\n",
      " [0.02404469]\n",
      " [0.04771531]\n",
      " [0.28589904]\n",
      " [0.95928264]\n",
      " [0.06129485]\n",
      " [0.95790374]\n",
      " [0.8821076 ]\n",
      " [0.11703157]\n",
      " [0.08772311]\n",
      " [0.21644196]\n",
      " [0.67725396]\n",
      " [0.17381084]\n",
      " [0.9704449 ]\n",
      " [0.97237307]\n",
      " [0.3601847 ]\n",
      " [0.85397744]\n",
      " [0.03566769]\n",
      " [0.97215545]\n",
      " [0.08612928]\n",
      " [0.2997593 ]\n",
      " [0.04283145]\n",
      " [0.07210776]\n",
      " [0.13148922]\n",
      " [0.5993421 ]\n",
      " [0.6068061 ]\n",
      " [0.4712394 ]\n",
      " [0.09043902]\n",
      " [0.5026326 ]\n",
      " [0.5000341 ]\n",
      " [0.09628466]\n",
      " [0.1367554 ]\n",
      " [0.02602524]\n",
      " [0.32271183]\n",
      " [0.04307759]\n",
      " [0.9143938 ]\n",
      " [0.9589703 ]\n",
      " [0.09628466]\n",
      " [0.27581912]\n",
      " [0.04228145]\n",
      " [0.9322542 ]\n",
      " [0.597793  ]\n",
      " [0.49257928]\n",
      " [0.2865399 ]\n",
      " [0.5350893 ]\n",
      " [0.84859174]\n",
      " [0.1755099 ]\n",
      " [0.07708648]\n",
      " [0.04651326]\n",
      " [0.06491601]\n",
      " [0.0379881 ]\n",
      " [0.97539115]\n",
      " [0.06004784]\n",
      " [0.21423301]\n",
      " [0.06063715]\n",
      " [0.6976993 ]\n",
      " [0.70914245]\n",
      " [0.91944385]\n",
      " [0.68885934]\n",
      " [0.3670085 ]\n",
      " [0.44438905]\n",
      " [0.66529316]\n",
      " [0.7020649 ]\n",
      " [0.06243774]\n",
      " [0.5208087 ]\n",
      " [0.45266777]\n",
      " [0.9757105 ]\n",
      " [0.39789623]\n",
      " [0.06850332]\n",
      " [0.90309155]\n",
      " [0.21877506]\n",
      " [0.7020649 ]\n",
      " [0.99755305]\n",
      " [0.09879282]\n",
      " [0.18093291]\n",
      " [0.04771531]\n",
      " [0.11982697]\n",
      " [0.06883845]\n",
      " [0.7085457 ]\n",
      " [0.49224007]\n",
      " [0.6976993 ]\n",
      " [0.9979664 ]\n",
      " [0.39656574]\n",
      " [0.04771531]\n",
      " [0.9565784 ]\n",
      " [0.06850332]\n",
      " [0.46430162]\n",
      " [0.06491601]\n",
      " [0.8358327 ]\n",
      " [0.09996319]\n",
      " [0.39207673]\n",
      " [0.06850332]\n",
      " [0.957509  ]\n",
      " [0.1439366 ]\n",
      " [0.04228145]\n",
      " [0.06554979]\n",
      " [0.6265336 ]\n",
      " [0.14434141]\n",
      " [0.08278805]\n",
      " [0.04228145]\n",
      " [0.06850332]\n",
      " [0.24622431]\n",
      " [0.16054517]\n",
      " [0.6976993 ]\n",
      " [0.97539115]\n",
      " [0.6899719 ]\n",
      " [0.9134167 ]\n",
      " [0.06878167]\n",
      " [0.04492009]\n",
      " [0.9970153 ]\n",
      " [0.3867252 ]\n",
      " [0.80805546]\n",
      " [0.9264822 ]\n",
      " [0.03201231]\n",
      " [0.96165943]\n",
      " [0.06683457]\n",
      " [0.04228145]\n",
      " [0.4396342 ]\n",
      " [0.06304887]\n",
      " [0.46057642]\n",
      " [0.12047163]\n",
      " [0.09538409]\n",
      " [0.10280371]\n",
      " [0.10291001]\n",
      " [0.387375  ]\n",
      " [0.03043246]\n",
      " [0.04198721]\n",
      " [0.06428805]\n",
      " [0.08200631]\n",
      " [0.22806555]\n",
      " [0.50523084]\n",
      " [0.01334107]\n",
      " [0.0640893 ]\n",
      " [0.9717713 ]\n",
      " [0.05111825]\n",
      " [0.29685068]\n",
      " [0.29695642]\n",
      " [0.01627681]\n",
      " [0.41153216]\n",
      " [0.09360552]\n",
      " [0.32271183]\n",
      " [0.00543666]\n",
      " [0.96634674]\n",
      " [0.04492009]\n",
      " [0.03763363]\n",
      " [0.50314367]\n",
      " [0.00730807]\n",
      " [0.06428805]\n",
      " [0.97472197]\n",
      " [0.3995329 ]\n",
      " [0.29695642]\n",
      " [0.63614833]\n",
      " [0.6976993 ]\n",
      " [0.99655485]\n",
      " [0.8034874 ]\n",
      " [0.04771531]\n",
      " [0.01049232]\n",
      " [0.5664909 ]\n",
      " [0.34938204]\n",
      " [0.06539786]\n",
      " [0.9567905 ]\n",
      " [0.5026326 ]\n",
      " [0.04771531]\n",
      " [0.08150372]\n",
      " [0.02636468]\n",
      " [0.04492009]\n",
      " [0.01610899]\n",
      " [0.87656975]\n",
      " [0.90047807]\n",
      " [0.17574185]\n",
      " [0.7493403 ]\n",
      " [0.7811171 ]\n",
      " [0.21877506]\n",
      " [0.23313424]\n",
      " [0.95720375]\n",
      " [0.04228145]\n",
      " [0.9694223 ]\n",
      " [0.17115107]\n",
      " [0.7604335 ]\n",
      " [0.02031907]\n",
      " [0.02297851]\n",
      " [0.12333792]\n",
      " [0.13409469]\n",
      " [0.32271183]\n",
      " [0.8501158 ]\n",
      " [0.0695866 ]\n",
      " [0.9989275 ]\n",
      " [0.04771531]\n",
      " [0.99983406]\n",
      " [0.38713348]\n",
      " [0.2352142 ]\n",
      " [0.714985  ]\n",
      " [0.8446232 ]\n",
      " [0.9999997 ]\n",
      " [0.04772779]\n",
      " [0.640864  ]\n",
      " [0.23043144]\n",
      " [0.30903512]\n",
      " [0.69348603]\n",
      " [0.23281425]\n",
      " [0.96564996]\n",
      " [0.06491601]\n",
      " [0.14955238]\n",
      " [0.04771531]\n",
      " [0.41790888]\n",
      " [0.7807618 ]\n",
      " [0.05589372]\n",
      " [0.38269383]\n",
      " [0.6976993 ]\n",
      " [0.12459072]\n",
      " [0.88488406]\n",
      " [0.06850332]\n",
      " [0.6743384 ]\n",
      " [0.09272751]\n",
      " [0.9076569 ]\n",
      " [0.06243774]\n",
      " [0.9114815 ]\n",
      " [0.5824845 ]\n",
      " [0.06366566]\n",
      " [0.6976993 ]\n",
      " [0.08894232]\n",
      " [0.1292463 ]\n",
      " [0.5373786 ]\n",
      " [0.9585421 ]\n",
      " [0.01698765]\n",
      " [0.04228145]\n",
      " [0.31213546]\n",
      " [0.06183198]\n",
      " [0.1571813 ]\n",
      " [0.08880055]\n",
      " [0.5482254 ]\n",
      " [0.95470047]\n",
      " [0.909297  ]\n",
      " [0.734625  ]\n",
      " [0.214535  ]\n",
      " [0.04771531]\n",
      " [0.8322785 ]\n",
      " [0.3200298 ]\n",
      " [0.93782973]\n",
      " [0.12600219]\n",
      " [0.80805546]\n",
      " [0.6516092 ]\n",
      " [0.7541775 ]\n",
      " [0.09185684]\n",
      " [0.48125762]\n",
      " [0.09538409]\n",
      " [0.06893179]\n",
      " [0.04771531]\n",
      " [0.04228145]\n",
      " [0.09903204]\n",
      " [0.7917459 ]\n",
      " [0.06243774]\n",
      " [0.03934005]\n",
      " [0.06243774]\n",
      " [0.85654926]\n",
      " [0.5510006 ]\n",
      " [0.2081494 ]\n",
      " [0.04771531]\n",
      " [0.18112525]\n",
      " [0.04771531]\n",
      " [0.5026326 ]\n",
      " [0.08928865]\n",
      " [0.355493  ]\n",
      " [0.04228145]\n",
      " [0.9784964 ]\n",
      " [0.5851658 ]\n",
      " [0.04492009]\n",
      " [0.6047247 ]\n",
      " [0.22338599]\n",
      " [0.13396072]\n",
      " [0.14782152]\n",
      " [0.23763111]\n",
      " [0.50523084]\n",
      " [0.9999142 ]\n",
      " [0.6976993 ]\n",
      " [0.47506636]\n",
      " [0.5481593 ]\n",
      " [0.04592302]\n",
      " [0.04771531]\n",
      " [0.49257928]\n",
      " [0.04492009]\n",
      " [0.06850332]\n",
      " [0.41153216]\n",
      " [0.71494246]\n",
      " [0.04492009]\n",
      " [0.1305502 ]\n",
      " [0.06598449]\n",
      " [0.06554979]\n",
      " [0.9999782 ]\n",
      " [0.04283145]\n",
      " [0.5589792 ]\n",
      " [0.06748563]\n",
      " [0.06947464]\n",
      " [0.1755099 ]\n",
      " [0.07681453]\n",
      " [0.09538409]\n",
      " [0.6976993 ]\n",
      " [0.8222507 ]\n",
      " [0.2877143 ]\n",
      " [1.        ]\n",
      " [0.12754086]\n",
      " [0.41683978]\n",
      " [0.09013751]\n",
      " [0.08665767]\n",
      " [0.04771531]\n",
      " [0.69788647]\n",
      " [0.93636173]\n",
      " [0.6866272 ]\n",
      " [0.169999  ]\n",
      " [0.24498394]\n",
      " [0.06618929]\n",
      " [0.12913373]\n",
      " [0.06554979]\n",
      " [0.08353093]\n",
      " [0.22806555]\n",
      " [0.32271183]\n",
      " [0.97343254]\n",
      " [0.06366566]\n",
      " [0.63141453]\n",
      " [0.355493  ]\n",
      " [0.14651686]\n",
      " [0.24006498]\n",
      " [0.79604465]\n",
      " [0.29214996]\n",
      " [0.04492009]\n",
      " [0.69463503]\n",
      " [0.06618929]\n",
      " [0.46339524]\n",
      " [0.21423301]\n",
      " [0.01173538]\n",
      " [0.39210507]\n",
      " [0.999977  ]\n",
      " [0.24746886]\n",
      " [0.06947464]\n",
      " [0.01040238]\n",
      " [0.85567665]\n",
      " [0.99270034]\n",
      " [0.4194199 ]\n",
      " [0.22806555]\n",
      " [0.69739014]\n",
      " [0.23281425]\n",
      " [0.8685887 ]\n",
      " [0.92472696]\n",
      " [0.23043144]\n",
      " [0.4146557 ]\n",
      " [0.04687324]\n",
      " [0.99949306]\n",
      " [0.17895722]\n",
      " [0.92838943]\n",
      " [0.04771531]\n",
      " [0.04228145]\n",
      " [0.52290523]\n",
      " [0.00333586]\n",
      " [0.93452156]\n",
      " [0.9430654 ]\n",
      " [0.09810862]\n",
      " [0.9782766 ]\n",
      " [0.2315425 ]\n",
      " [0.06883845]\n",
      " [0.7041634 ]\n",
      " [0.92472696]\n",
      " [0.21036461]\n",
      " [0.09332737]\n",
      " [0.98568153]\n",
      " [0.15241626]\n",
      " [0.11766317]\n",
      " [0.8858727 ]\n",
      " [0.9723271 ]\n",
      " [0.13698894]\n",
      " [0.24006498]\n",
      " [0.23029155]\n",
      " [0.04342666]\n",
      " [0.04228145]\n",
      " [0.07784471]\n",
      " [0.7938117 ]\n",
      " [0.49434024]\n",
      " [0.13383412]\n",
      " [0.79083586]\n",
      " [0.06428805]\n",
      " [0.06922984]\n",
      " [0.08278805]\n",
      " [0.08192378]\n",
      " [0.58193946]\n",
      " [0.87400603]\n",
      " [0.8511353 ]\n",
      " [0.11355683]\n",
      " [0.01974407]\n",
      " [0.95720375]\n",
      " [0.0797888 ]\n",
      " [0.9321872 ]\n",
      " [0.06304887]\n",
      " [0.07317299]\n",
      " [0.9749768 ]\n",
      " [0.13709775]\n",
      " [0.97215545]\n",
      " [0.6013445 ]\n",
      " [0.22663498]\n",
      " [0.23107836]\n",
      " [0.09510127]\n",
      " [0.12794706]\n",
      " [0.6976993 ]\n",
      " [0.21111453]\n",
      " [0.6976993 ]\n",
      " [0.95819664]\n",
      " [0.41206244]\n",
      " [0.06850332]\n",
      " [0.916126  ]\n",
      " [0.04447871]\n",
      " [0.06850338]\n",
      " [0.9982626 ]]\n"
     ]
    }
   ],
   "source": [
    "dnn_predict = model_dnn.predict(data_x)\n",
    "\n",
    "print(dnn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_final = (dnn_predict > 0.5).astype(int).ravel()\n",
    "print(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": data[\"PassengerId\"],\n",
    "        \"Survived\": y_final\n",
    "    })\n",
    "submission.to_csv('submission_dnn3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
